{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Data Extraction: Automating Invoice Processing\n",
    "\n",
    "This notebook demonstrates how to extract structured data from text documents like receipts and invoices using AI. We'll explore:\n",
    "\n",
    "1. Basic text extraction using prompts\n",
    "2. Structured output formats (JSON, XML)\n",
    "\n",
    "The techniques shown here can help automate manual data entry tasks and standardize information extraction from semi-structured documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./invoice-data-sample.txt\", \"r\") as f:\n",
    "    receipt_data = f.read()\n",
    "    \n",
    "receipt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(receipt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai_tools import ask_ai\n",
    "\n",
    "extraction_prompt = f\"\"\"\n",
    "\n",
    "You are an extraction engine for receipt data.\n",
    "Users will upload the contents of their receipts and you will extract\n",
    "the following fields:\n",
    "- Company name\n",
    "- Date of closure\n",
    "- Amount paid\n",
    "\n",
    "Extract the data from the following receipt:\n",
    "{receipt_data}\n",
    "\"\"\"\n",
    "\n",
    "structured_output = ask_ai(prompt=extraction_prompt)\n",
    "\n",
    "structured_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "This output is ok but we don't want the conversational elements of the response right?\n",
    "\n",
    "To get around that, let's improve our initial prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_prompt_json = f\"\"\"\n",
    "You are an extraction engine for receipt data.\n",
    "Users will upload the contents of their receipts and you will extract\n",
    "the following fields as JSON OBJECTS:\n",
    "- Company name\n",
    "- Date of closure\n",
    "- Amount paid\n",
    "\n",
    "Extract the data from the following receipt:\n",
    "{receipt_data}\n",
    "\n",
    "Your OUTPUT SHOULD ONLY BE A JSON OBJECT WITH THE FOLLOWING FIELDS:\n",
    "- company_name\n",
    "- date_of_closure\n",
    "- amount_paid\n",
    "\"\"\"\n",
    "\n",
    "structured_output_json = ask_ai(prompt=extraction_prompt_json)\n",
    "\n",
    "structured_output_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to import the json library to parse the JSON output\n",
    "import json\n",
    "\n",
    "def parse_json_output(json_str):\n",
    "    \"\"\"\n",
    "    This function parses the JSON output from the AI and removes the markdown code block markers if present.\n",
    "    \"\"\"\n",
    "    # Remove markdown code block markers if present\n",
    "    json_str = json_str.replace('```json', '').replace('```', '').strip()\n",
    "    \n",
    "    # Parse the JSON string into a Python dictionary\n",
    "    try:\n",
    "        return json.loads(json_str)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error: Could not parse JSON string\")\n",
    "        return None\n",
    "\n",
    "parsed_json = parse_json_output(structured_output_json)\n",
    "\n",
    "\n",
    "parsed_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Company Name: {parsed_json['company_name']}\")\n",
    "print(f\"Date of Closure: {parsed_json['date_of_closure']}\")\n",
    "print(f\"Amount Paid: {parsed_json['amount_paid']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "In Claude we can also do this quite easily using `xml` tags: `<output>{\"company_name\":....etc....} </output>`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai_tools import ask_ai\n",
    "\n",
    "ask_ai(prompt=\"Hi! Which model are you?\", model_name=\"claude-3-5-sonnet-20240620\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_prompt_claude = f\"\"\"\n",
    "You are an extraction engine for receipt data.\n",
    "Users will upload the contents of their receipts and you will extract key fields.\n",
    "\n",
    "Extract the following fields from this receipt:\n",
    "{receipt_data}\n",
    "\n",
    "Format your response using XML tags like this:\n",
    "<output>\n",
    "  <company_name>The company name</company_name>\n",
    "  <date_of_closure>The date of closure</date_of_closure>\n",
    "  <amount_paid>The amount paid</amount_paid>\n",
    "</output>\n",
    "\n",
    "Only include the XML tags and JSON object in your response, nothing else.\n",
    "\"\"\"\n",
    "output = ask_ai(prompt=extraction_prompt_claude, model_name=\"claude-3-5-sonnet-20240620\")\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "Now, let's write a function that properly parses this output from Claude:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_claude_output(output):\n",
    "    \"\"\"\n",
    "    This function parses the output from Claude and removes the XML tags.\n",
    "    \"\"\"\n",
    "    # Remove XML tags if present\n",
    "    output = output.replace('<output>', '').replace('</output>', '').strip()\n",
    "    return output\n",
    "\n",
    "output_parsed = parse_claude_output(output)\n",
    "\n",
    "output_parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "Now we can access each individual attribute easily by simply parsing the tags:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_field(output, field_name):\n",
    "    \"\"\"Extract value between XML tags for a given field.\"\"\"\n",
    "    pattern = f\"<{field_name}>(.*?)</{field_name}>\"\n",
    "    match = re.search(pattern, output)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "# Extract each field\n",
    "company_name = extract_field(output_parsed, \"company_name\")\n",
    "date_of_closure = extract_field(output_parsed, \"date_of_closure\") \n",
    "amount_paid = extract_field(output_parsed, \"amount_paid\")\n",
    "\n",
    "print(f\"Company Name: {company_name}\")\n",
    "print(f\"Date of Closure: {date_of_closure}\")\n",
    "print(f\"Amount Paid: {amount_paid}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "But what if you don't want to send your private data to some cloud provider?\n",
    "\n",
    "In that case, we use local models! After a lot of advancements, we can now easily use local models to extract structured outputs similar to what we have been doing before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai_tools import ask_local_ai\n",
    "import json\n",
    "\n",
    "extraction_prompt_json = f\"\"\"\n",
    "You are an extraction engine for receipt data.\n",
    "Users will upload the contents of their receipts and you will extract\n",
    "the following fields as JSON OBJECTS:\n",
    "- Company name\n",
    "- Date of closure\n",
    "- Amount paid\n",
    "\n",
    "Extract the data from the following receipt:\n",
    "{receipt_data}\n",
    "\n",
    "Your OUTPUT SHOULD ONLY BE A JSON OBJECT WITH THE FOLLOWING FIELDS:\n",
    "- company_name\n",
    "- date_of_closure\n",
    "- amount_paid\n",
    "\"\"\"\n",
    "\n",
    "output_string = ask_local_ai(extraction_prompt_json, structured=True)\n",
    "\n",
    "output_json = json.loads(output_string)\n",
    "\n",
    "print(f\"Company Name: {output_json['company_name']}\")\n",
    "print(f\"Date of Closure: {output_json['date_of_closure']}\")\n",
    "print(f\"Amount Paid: {output_json['amount_paid']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "The fancier way of doing this for those interested in exploring more about structured extractions is using something called `pydantic` a data validation library that perfectly integrates with LLM APIs like openai's and anthropics to create these structured outputs in a more programatic and organized fashion.\n",
    "See an example in: `./structured_output_with_pydantic.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "# Extracting Insights from Technology Trends Reports from OReilly Media\n",
    "\n",
    "Radar Trends website:\n",
    "- https://www.oreilly.com/radar/trends/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_contents_oreilly_tech_trends_january_2025 = \"\"\"\n",
    "\n",
    "Skip to main content\n",
    "O'Reilly home\n",
    "Sign In\n",
    "Try Now\n",
    "Teams\n",
    "For business\n",
    "For government\n",
    "For higher ed\n",
    "Individuals\n",
    "Features\n",
    "All features\n",
    "Courses\n",
    "Certifications\n",
    "Interactive learning\n",
    "Live events\n",
    "Answers\n",
    "Insights reporting\n",
    "Plans\n",
    "Blog\n",
    "Content sponsorship\n",
    "Search\n",
    "Radar / Radar Trends\n",
    "Radar Trends to Watch: January 2025\n",
    "Developments in Security, Programming, AI, and More\n",
    "\n",
    "By Mike Loukides\n",
    "January 7, 2025\n",
    "\n",
    "Learn faster. Dig deeper. See farther.\n",
    "Join the O'Reilly online learning platform. Get a free trial today and find answers on the fly, or master something new and useful.\n",
    "\n",
    "Learn more\n",
    "Despite its 31 days, December is a short month. It's hard for announcements and happenings other than office parties to get attention. Fighting this trend, OpenAI made a series of announcements: their \"12 Days of OpenAI.\" Not to be upstaged, Google responded with a flurry of announcements, including their Gemini 2.0 Flash Thinking model. Models appeared that could use streaming audio and video for both input and output. But perhaps the most important announcement was DeepSeek-V3, a very large mixture-of-experts model (671B parameters) that has performance on a par with the other top models—but cost roughly 1/10th as much to train.\n",
    "\n",
    "AI\n",
    "DeepSeek-V3 is another LLM to watch. Its performance is on a par with Llama 3.1, GPT-4o, and Claude Sonnet. While training was not inexpensive, the cost of training was estimated to be roughly 10% of the bigger models.\n",
    "Not to be outdone by Google, OpenAI previewed its next models: o3 and o3-mini. These are both \"reasoning models\" that have been trained to solve logical problems. They may be released in late January; OpenAI is looking for safety and security researchers for testing.\n",
    "Not to be outdone by 12 Days of OpenAI, Google has released a new experimental model that has been trained to solve logical problems: Gemini 2.0 Flash Thinking. Unlike OpenAI's GPT models that support reasoning, Flash Thinking shows its chain of thought explicitly.\n",
    "Jeremy Howard and his team have released ModernBERT, a major upgrade to the BERT model they released six years ago. It comes in two sizes: 139M and 395M parameters. It's ideal for retrieval, classification, and entity extraction, and other components of a data pipeline.\n",
    "AWS's Bedrock service has the ability to check the output of other models for hallucinations.\n",
    "To make sure they aren't outdone by 12 Days of OpenAI, Google has announced Android XR, an operating system for extended reality headsets and glasses. Google doesn't plan to build their own hardware; they're partnering with Samsung, Qualcomm, and other manufacturers.\n",
    "Also not to be outdone by 12 Days of OpenAI, Anthropic has announced Clio, a privacy- preserving approach to finding out how people use their models. That information will be used to improve Anthropic's understanding of safety issues and to build more helpful models.\n",
    "Not to be outdone by 12 Days of OpenAI, Google has announced Gemini 2.0 Flash, a multimodal model that supports streaming for both input and output. The announcement also showcased Astra, an AI agent for smartphones. Neither is generally available yet.\n",
    "OpenAI has released canvas, a new feature that combines programming with writing. Changes to the canvas (code or text) immediately become part of the context. Python code is executed in the browser using Pyodide (Wasm), rather than in a container (as with Code Interpreter).\n",
    "Stripe has announced an agent toolkit that lets you build payments into agentic workflows. Stripe recommends using the toolkit in test mode until the application has been thoroughly validated.\n",
    "Simon Willison shows how to run a GPT-4 class model (Llama 3.3 70B) on a reasonably well-equipped laptop (64GB MacBook Pro M2).\n",
    "As part of their 12 Days of OpenAI series, OpenAI finally released their video generation model, Sora. It's free to ChatGPT Plus subscribers, though limited to 50 five-second video clips per month; a ChatGPT Pro account relaxes many of the limitations.\n",
    "Researchers have shown that advanced AI models, including Claude 3 Opus and OpenAI o1, are capable of \"scheming\": working against the interests of their users to achieve their goals. Scheming includes subverting oversight mechanisms, intentionally delivering subpar results, and even taking steps to prevent shutdown or replacement. Hello, HAL?\n",
    "Roaming RAG is a new technique for retrieval augmented generation that finds relevant content by searching through headings to navigate documents—like a human might. It requires well-structured documents. A surprisingly simple idea, really.\n",
    "Google has announced PaliGemma 2, a new version of its Gemma models that incorporates vision.\n",
    "GPT-4-o1-preview is no more; the preview is now the real thing, OpenAI o1. In addition to advanced reasoning skills, the production release claims to be faster and to deliver more consistent results.\n",
    "A group of AI agents in Minecraft behaved surprisingly like humans—even developing jobs and religions. Is this a way to model how human groups collaborate?\n",
    "One thing the AI industry needs desperately (aside from more power) is better benchmarks. Current benchmarks are closed, easily gamed (that's what AI does), and unreproducible, and they may not test anything meaningful. Better Bench is a framework for assessing benchmark quality.\n",
    "Palmyra Creative, a new language model from Writer, promises the ability to develop \"style\" so that all AI-generated output won't sound boringly the same.\n",
    "During training AI picks up biases from human data. When humans interact with the AI, there's a feedback loop that amplifies those biases.\n",
    "Programming\n",
    "Unicon may never become one of the top 20 (or top 100) programming languages, but it's a descendant of Icon, which was always my favorite language for string processing.\n",
    "What do CAPTCHAs mean when LLM-equipped bots can successfully complete tasks set for humans?\n",
    "egui, together with eframe, is a GUI library and framework for Rust. It's portable and runs natively (on macOS, Windows, Linux, and Android), on the web (using Wasm), and in many game engines.\n",
    "For the archivist in us: The Manx project isn't about an island in the Irish Sea or about cats. It's a catalog of manuals for old computers.\n",
    "Cerbrec is a graphical Python framework for deep learning. It's aimed at Python programmers who don't have sufficient expertise to build applications with PyTorch or other AI libraries.\n",
    "GitHub has announced free access to GitHub Copilot for all current and new users. Free access gives you 2,000 code completions and 50 chat messages per month. They've also added the ability to use Claude 3.5 Sonnet in addition to GPT-4o.\n",
    "Devin, the AI assisted coding tool that claims to support software development from beginning to end, including design and debugging, has reached general availability.\n",
    "JSON5, also known as \"JSON for humans,\" is a variant of JSON that has been designed for human readability so that it can be written and maintained by hand—for example, in configuration files.\n",
    "AWS has announced two significant new services: Aurora DSQL, which is a distributed SQL database, and S3 Tables, which supports data lakehouses through Apache Iceberg.\n",
    "AutoFlow is an open source tool for creating a knowledge graph. It's based on TiDB (a vector database), LlamaIndex, and DSPy.\n",
    "Security\n",
    "Portspoof is a security tool that causes all 65,535 TCP ports to appear open for valid services. It emulates a valid service on every port. It makes it difficult for an attacker to determine which ports are actually open without probing each port.\n",
    "Let's Encrypt, which issues the certificates that websites (and other applications) use to prove their identities, has announced short-lived certificates that expire after six days. Short-lived certificates increase security by minimizing exposure if a private key is compromised.\n",
    "Because of the continued presence of attackers within telecommunications networks, the US FBI and CISA have recommended the use of encrypted communications protocols. (Though they still want backdoors into encryption systems, which would make them vulnerable to attack.)\n",
    "A new phishing attack uses corrupted Word documents to bypass security checks. While the documents are corrupt, Word is able to recover them.\n",
    "LLM Flowbreaking is a new class of attack against language models that prevent guardrails from stopping objectionable output from reaching the user. These attacks take advantage of race conditions in the application's interaction with users.\n",
    "Bootkitty is a UEFI bootkit that targets secure boot on Ubuntu systems. It appears to have been developed by cybersecurity students in Korea, then leaked (possibly accidentally). It hasn't yet been found in the wild, but when it is, it will be a dangerous threat.\n",
    "DEF CON has started a project to improve cybersecurity for water infrastructure in the US. They're starting with six water companies serving rural communities.\n",
    "Quantum Computing\n",
    "Google has built a quantum computing chip in which an error-corrected logical qubit can remain stable for an hour. It passes the \"below threshold\": the error rate decreases as physical qubits are added for error correction. The chip was built in Google's new fabrication facility.\n",
    "Web\n",
    "Google is adding \"store reviews\" to Chrome. Reviews are AI-generated summaries of reports from well-known sources that report scams and other issues.\n",
    "Here's a how-to on building streaming text user interfaces on the web. Streaming text is almost a necessity for building AI-driven chatbots.\n",
    "Biology\n",
    "Yes, we can have virtual taste. A research group has developed a lollipop interface so that people can experience taste in virtual worlds.\n",
    "Post topics: Radar Trends\n",
    "Post tags: Signals\n",
    "Share:   Share\n",
    "About O'Reilly\n",
    "Teach/write/train\n",
    "Careers\n",
    "O'Reilly news\n",
    "Media coverage\n",
    "Community partners\n",
    "Affiliate program\n",
    "Submit an RFP\n",
    "Diversity\n",
    "O'Reilly for marketers\n",
    "Support\n",
    "Contact us\n",
    "Newsletters\n",
    "Privacy policy\n",
    " \n",
    "International\n",
    "Australia & New Zealand\n",
    "Hong Kong & Taiwan\n",
    "India\n",
    "Indonesia\n",
    "Japan\n",
    "Download the O'Reilly App\n",
    "Take O'Reilly with you and learn anywhere, anytime on your phone and tablet.\n",
    "\n",
    "Apple app store Google play store\n",
    "Watch on your big screen\n",
    "View all O'Reilly videos, Superstream events, and Meet the Expert sessions on your home TV.\n",
    "\n",
    "Roku Payers and TVs Amazon appstore\n",
    "Do not sell my personal information\n",
    "O'Reilly home\n",
    "© 2025, O'Reilly Media, Inc. All trademarks and registered trademarks appearing on oreilly.com are the property of their respective owners.\n",
    "\n",
    "Terms of service • Privacy policy • Editorial independence\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai_tools import ask_ai, parse_json_output\n",
    "\n",
    "extract_insights_prompt = f\"\"\"\n",
    "Extract from these raw contents, all the insights regarding AI and programming into the following structure format:\n",
    "\n",
    "- AI insights\n",
    "- Programming insights\n",
    "\n",
    "Here are the raw contents:\n",
    "\n",
    "{raw_contents_oreilly_tech_trends_january_2025}.\n",
    "\n",
    "Your OUTPUT SHOULD ONLY BE A JSON OBJECT WITH THE FOLLOWING FIELDS:\n",
    "\n",
    "- ai-insights\n",
    "- programming-insights\n",
    "- date\n",
    "\n",
    "Output:\n",
    "\"\"\"\n",
    "\n",
    "output = ask_ai(extract_insights_prompt)\n",
    "parsed_output_json = parse_json_output(output)\n",
    "parsed_output_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert JSON insights to markdown format\n",
    "print(\"# Tech Trends Report - \" + parsed_output_json['date'])\n",
    "print(\"\\n## AI Insights\")\n",
    "for insight in parsed_output_json['ai-insights']:\n",
    "    print(f\"- {insight}\")\n",
    "    \n",
    "print(\"\\n## Programming Insights\") \n",
    "for insight in parsed_output_json['programming-insights']:\n",
    "    print(f\"- {insight}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "We can now easily transform this into a table to store our own databaset of the recent tech trends!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create lists of insights and dates\n",
    "ai_insights = parsed_output_json['ai-insights']\n",
    "prog_insights = parsed_output_json['programming-insights']\n",
    "dates = [parsed_output_json['date']] * max(len(ai_insights), len(prog_insights))\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'AI Insights': ai_insights + [None] * (len(prog_insights) - len(ai_insights)) if len(prog_insights) > len(ai_insights) else ai_insights,\n",
    "    'Programming Insights': prog_insights + [None] * (len(ai_insights) - len(prog_insights)) if len(ai_insights) > len(prog_insights) else prog_insights,\n",
    "    'Date': dates\n",
    "})\n",
    "\n",
    "# Display the table\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_oreilly_ai_programming_news(url):\n",
    "    \"\"\"\n",
    "    Scrape AI and programming-related content from O'Reilly Radar.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Send request to the website\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Parse HTML content\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Find AI and Programming sections\n",
    "        ai_section = soup.find('h2', string=lambda text: text and 'AI' in text)\n",
    "        programming_section = soup.find('h2', string=lambda text: text and 'Programming' in text)\n",
    "        \n",
    "        news_items = []\n",
    "        \n",
    "        # Extract AI content\n",
    "        if ai_section:\n",
    "            ai_content = ai_section.find_next('ul')\n",
    "            if ai_content:\n",
    "                news_items.extend([li.text.strip() for li in ai_content.find_all('li')])\n",
    "        \n",
    "        # Extract Programming content\n",
    "        if programming_section:\n",
    "            programming_content = programming_section.find_next('ul')\n",
    "            if programming_content:\n",
    "                news_items.extend([li.text.strip() for li in programming_content.find_all('li')])\n",
    "        \n",
    "        return news_items\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error scraping website: {e}\")\n",
    "        return []\n",
    "\n",
    "# Example usage (replace with actual O'Reilly Radar URL)\n",
    "oreilly_url = \"https://www.oreilly.com/radar/radar-trends-to-watch-january-2025/\"\n",
    "ai_programming_news = scrape_oreilly_ai_programming_news(oreilly_url)\n",
    "\n",
    "if ai_programming_news:\n",
    "    print(\"\\nLatest O'Reilly AI & Programming News:\")\n",
    "    for idx, news in enumerate(ai_programming_news, 1):\n",
    "        print(f\"{idx}. {news}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
