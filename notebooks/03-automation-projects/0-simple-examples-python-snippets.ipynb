{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b946939",
   "metadata": {},
   "source": [
    "Report of several practical examples where people have automated downloads (or file retrieval) with Python. Many examples you see on Reddit, developer blogs, and tutorials show that—whether it’s downloading a report, a media file, or scraping content for later use—Python’s rich ecosystem makes it straightforward. Here are eight representative examples with concise code snippets:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Basic File Download with `urllib`\n",
    "\n",
    "A common starting point is to use Python’s built‐in `urllib.request.urlretrieve` to download a file from an HTTP URL. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b40b106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded paper\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "url = \"https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf\"\n",
    "filepath = \"../assets/paper3.pdf\"\n",
    "urllib.request.urlretrieve(url, filepath)\n",
    "print(\"Downloaded paper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fb3054b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../assets/paper1.pdf\n",
      "../assets/paper2.pdf\n",
      "../assets/paper3.pdf\n"
     ]
    }
   ],
   "source": [
    "!ls ../assets/*.pdf* | grep paper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae02a7ad",
   "metadata": {},
   "source": [
    "This can be handy when you want a one-liner that mimics the familiar Unix tool.  \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Conditional Download (Based on File Age)\n",
    "\n",
    "Sometimes you want to download a file only if it’s missing or older than a given age. For example, to download a CSV file if it’s older than one day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afa04191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.csv is up-to-date\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import os\n",
    "import time\n",
    "\n",
    "url = 'https://gist.githubusercontent.com/denandreychuk/b9aa812f10e4b60368cff69c6384a210/raw/100%20Sales%20Records.csv'\n",
    "local_file = 'data.csv'\n",
    "# Download if file doesn't exist or is older than 24 hours (86400 seconds)\n",
    "if not os.path.exists(local_file) or (os.path.getmtime(local_file) < time.time() - 86400):\n",
    "    urllib.request.urlretrieve(url, local_file)\n",
    "    print(\"Updated data.csv\")\n",
    "else:\n",
    "    print(\"data.csv is up-to-date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a33159a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading fresh copy...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "\n",
    "# fake csv file (doesn't exist online!)\n",
    "url = 'https://gist.githubusercontent.com/denandreychuk/b9aa812f10e4b60368cff69c6384a210/raw/100%20Sales%20Records.csv'\n",
    "local_file = 'data.csv'\n",
    "\n",
    "def download_if_needed(url, local_file):\n",
    "    # 24 hours in seconds\n",
    "    max_age = 24 * 60 * 60  \n",
    "\n",
    "    # Condition 1 + 2: Check if file exists AND whether it is older than 24h\n",
    "    needs_download = (\n",
    "        not os.path.exists(local_file) or\n",
    "        (time.time() - os.path.getmtime(local_file)) > max_age\n",
    "    )\n",
    "\n",
    "    if needs_download:\n",
    "        print(\"Downloading fresh copy...\")\n",
    "        resp = requests.get(url, timeout=10)\n",
    "        if resp.status_code != 200:\n",
    "            raise RuntimeError(\"Download failed.\")\n",
    "        with open(local_file, \"wb\") as f:\n",
    "            f.write(resp.content)\n",
    "    else:\n",
    "        print(\"Local file is recent; no download needed.\")\n",
    "\n",
    "# Run it\n",
    "download_if_needed(url, local_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caf9c575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.csv\n"
     ]
    }
   ],
   "source": [
    "!ls *.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435ebc81",
   "metadata": {},
   "source": [
    "This pattern is popular in automating daily report updates.  \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Downloading Large Files with `requests` and Streaming\n",
    "\n",
    "When downloading large files, it’s best to stream the response in chunks. This approach uses the `requests` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf410cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://example.com/largefile.zip\"\n",
    "local_filename = \"largefile.zip\"\n",
    "with requests.get(url, stream=True) as r:\n",
    "    r.raise_for_status()\n",
    "    with open(local_filename, 'wb') as f:\n",
    "        for chunk in r.iter_content(chunk_size=8192):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "print(\"Large file downloaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3dd9b2",
   "metadata": {},
   "source": [
    "Using streaming helps avoid high memory usage with large downloads.  \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Automating Downloads via Selenium\n",
    "\n",
    "For sites that require a login or button clicks (for instance, downloading a report from a secure portal), Selenium can be used to simulate user actions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8b142b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "driver = webdriver.Chrome()  # Assumes chromedriver is installed and in PATH\n",
    "driver.get(\"http://example.com/login\")\n",
    "# Fill in login form\n",
    "driver.find_element(By.ID, \"username\").send_keys(\"myusername\")\n",
    "driver.find_element(By.ID, \"password\").send_keys(\"mypassword\" + Keys.RETURN)\n",
    "time.sleep(3)  # Wait for login to complete\n",
    "# Navigate to download page and click the download button\n",
    "driver.get(\"http://example.com/download\")\n",
    "driver.find_element(By.ID, \"downloadButton\").click()\n",
    "time.sleep(5)  # Wait for download to start/complete\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4530c201",
   "metadata": {},
   "source": [
    "This method is frequently mentioned in discussions where users automate downloading reports or files from platforms that don’t offer direct URL-based downloads.  \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Downloading Videos Using `youtube_dl`\n",
    "\n",
    "For media files (especially videos from platforms like YouTube), many developers rely on the popular tool `youtube_dl` (which now has forks such as `yt-dlp`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6f8c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import youtube_dl\n",
    "\n",
    "ydl_opts = {}\n",
    "with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
    "    ydl.download(['https://www.youtube.com/watch?v=EXAMPLE_ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1908d72a",
   "metadata": {},
   "source": [
    "This snippet automatically downloads the video file using the robust features of the youtube_dl ecosystem.  \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Invoking the Command-line `wget` from Python\n",
    "\n",
    "Sometimes you want to leverage the battle-tested command-line utility wget (especially for features like resuming downloads). You can invoke it via Python’s subprocess module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08848b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "url = \"http://example.com/file.zip\"\n",
    "# The \"-c\" flag allows resuming an interrupted download.\n",
    "subprocess.run([\"wget\", \"-c\", url])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf7258f",
   "metadata": {},
   "source": [
    "This is useful when you’re comfortable with wget’s features and want to combine them with your Python workflow.  \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 7. Concurrent Downloads Using `aiohttp` and `asyncio`\n",
    "\n",
    "For scenarios where you need to download many files at once, asynchronous code with `aiohttp` can dramatically speed things up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b1ea44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "\n",
    "async def download_file(session, url, filename):\n",
    "    async with session.get(url) as resp:\n",
    "        with open(filename, 'wb') as f:\n",
    "            while True:\n",
    "                chunk = await resp.content.read(1024)\n",
    "                if not chunk:\n",
    "                    break\n",
    "                f.write(chunk)\n",
    "    print(f\"Downloaded {filename}\")\n",
    "\n",
    "async def main():\n",
    "    files = [\n",
    "        (\"http://example.com/file1.zip\", \"file1.zip\"),\n",
    "        (\"http://example.com/file2.zip\", \"file2.zip\"),\n",
    "        # Add more (url, filename) tuples as needed.\n",
    "    ]\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [download_file(session, url, fname) for url, fname in files]\n",
    "        await asyncio.gather(*tasks)\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aca6ff9",
   "metadata": {},
   "source": [
    "This approach uses asynchronous programming to start multiple downloads concurrently, which is ideal when processing many files in bulk.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec42cbdc",
   "metadata": {},
   "source": [
    "# Example for Organizing Downloads Folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c92d084",
   "metadata": {},
   "source": [
    "# Exercise for writing prompts to ChatGPT\n",
    "\n",
    "## Create a prompt for ChatGPT to create a script to perform something like organizing files in a folder, but adding your own twist, perspective or usecase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24f9e9c",
   "metadata": {},
   "source": [
    "**Prompt to ChatGPT (GPT-4o)**\n",
    "```\n",
    "Write a Python script that organizes files in my 'Downloads' folder by moving them into subfolders based on their file type (e.g., PDFs to a 'PDFs' folder, images to an 'Images' folder, etc.). The script should create folders if they don’t exist.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4be87676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved: how-to.md -> Other/\n",
      "Moved: certificate-dxabmgxr8p9e-1757895166.pdf -> Documents/\n",
      "Moved: Python_Automation_Ideas.pptx -> Presentations/\n",
      "Moved: ChatGPT Image Aug 17, 2025, 06_08_38 PM.png -> Images/\n",
      "Moved: llm-reasoning-cut.pdf -> Documents/\n",
      "Moved: Booking.2078035.pdf -> Documents/\n",
      "Moved: elmo-strut.mov -> Videos/\n",
      "Moved: I want to prepare a workshop on AI tools for learn.pdf -> Documents/\n",
      "Moved: PHOTO-2025-05-21-17-20-21.jpg -> Images/\n",
      "Moved: Gemini_Generated_Image_duxxvcduxxvcduxx.png -> Images/\n",
      "Moved: PHOTO-2025-05-21-17-22-18.jpg -> Images/\n",
      "Moved: 564160491.pdf -> Documents/\n",
      "Moved: The email I got_____Hi Lucas!_Hope you're well. We.pdf -> Documents/\n",
      "Moved: .DS_Store -> Other/\n",
      "Moved: olympic-office-episode2.srt -> Other/\n",
      "Moved: LLM-Reasoning-Stanford-CS-25.pdf -> Documents/\n",
      "Moved: VID_20230610_160454.mp4 -> Videos/\n",
      "Moved: PHOTO-2025-05-21-17-20-30.jpg -> Images/\n",
      "Moved: I want you to help me look it up the top 10 resour.pdf -> Documents/\n",
      "Moved: troubleshooting.md -> Other/\n",
      "Moved: cal_tasks.ics -> Other/\n",
      "Moved: PHOTO-2025-05-24-17-29-24.jpg -> Images/\n",
      "Moved: PHOTO-2025-05-21-17-21-14.jpg -> Images/\n",
      "Moved: erase-drive.md -> Other/\n",
      "Moved: Gemini_Generated_Image_ivfu32ivfu32ivfu.png -> Images/\n",
      "Moved: ai-index-int.png -> Images/\n",
      "Moved: I want to prepare a workshop on AI tools for learn.md -> Other/\n",
      "Moved: ko2-ep133-guide-docs.pdf -> Documents/\n",
      "Moved: PHOTO-2025-06-21-14-35-39.jpg -> Images/\n",
      "Moved: sample-diagram.json -> Other/\n",
      "Moved: PHOTO-2025-05-21-17-18-53.jpg -> Images/\n",
      "Moved: buttons-and-combos.md -> Other/\n",
      "Moved: Airbnb_ Vacation Rentals, Cabins, Beach Houses, Unique Homes & Experiences.pdf -> Documents/\n",
      "Moved: 16th+PyData+Lisbon+Meetup.ics -> Other/\n",
      "Moved: PROPOSTA - AI TOOLS FOR DAY TO DAY.pdf -> Documents/\n",
      "Moved: IMG_9215.MOV -> Videos/\n",
      "Moved: olympic-office-episode2.vtt -> Other/\n",
      "Moved: cheatsheet.md -> Other/\n",
      "Moved: firmware-updates.md -> Other/\n",
      "Moved: desenho-de-mandala-de-pagina-para-colorir-de-cabeca-de-gato-design-de-impressao_18866-401.jpg -> Images/\n",
      "Moved: gpt-integrate-workflows-slides.pdf -> Documents/\n",
      "Moved: workflow.md -> Other/\n",
      "Moved: olympic-office-episode2.json -> Other/\n",
      "Moved: PHOTO-2025-05-21-17-19-17.jpg -> Images/\n",
      "Moved: Bambu_Studio_mac-v02.02.02.56.dmg -> Executables/\n",
      "Moved: PHOTO-2025-05-21-17-21-39.jpg -> Images/\n",
      "Moved: IMG_9216.MOV -> Videos/\n",
      "Moved: PHOTO-2025-05-21-17-22-40.jpg -> Images/\n",
      "Moved: 16-workflow-integration-final.json -> Other/\n",
      "Moved: community-tips.md -> Other/\n",
      "Moved: IMG_9217.MOV -> Videos/\n",
      "Moved: guide-conventions.md -> Other/\n",
      "Moved: Getting Started with OpenAI Agents SDK.pdf -> Documents/\n",
      "Moved: technical-specifications.md -> Other/\n",
      "Moved: PHOTO-2025-05-21-17-19-31.jpg -> Images/\n",
      "Moved: IMG_9226.MOV -> Videos/\n",
      "Moved: IMG_6075.MOV -> Videos/\n",
      "Moved: social_enkrateialucca_a_little_elmo_animation_on_a_dark_black_backgr_3e3d9801-6c8e-47fa-a8c8-82ebc0c8fad2_0.mp4 -> Videos/\n",
      "Moved: IMG_9219.MOV -> Videos/\n",
      "Moved: IMG_9225.MOV -> Videos/\n",
      "Moved: IMG_9224.MOV -> Videos/\n",
      "Moved: hardware-overview.md -> Other/\n",
      "Moved: IMG_9218.MOV -> Videos/\n",
      "Moved: index.md -> Other/\n",
      "Moved: effects.md -> Other/\n",
      "Moved: IMG_9220.MOV -> Videos/\n",
      "Moved: 16-workflow-integration-final.vtt -> Other/\n",
      "Moved: functions.md -> Other/\n",
      "Moved: Market Validation_ Minimalist Sneakers for Yoga Moms Over 40 (US).pdf -> Documents/\n",
      "Moved: power-on.md -> Other/\n",
      "Moved: screen.md -> Other/\n",
      "Moved: IMG_9221.MOV -> Videos/\n",
      "Moved: play-and-record.md -> Other/\n",
      "Moved: Modelo-6.1-requerimento-pedido-nacionalidade.pdf -> Documents/\n",
      "Moved: IMG_9223.MOV -> Videos/\n",
      "Moved: system.md -> Other/\n",
      "Moved: IMG_9222.MOV -> Videos/\n",
      "Moved: Gemini_Generated_Image_qgzdl2qgzdl2qgzd.png -> Images/\n",
      "Moved: get-started.md -> Other/\n",
      "Moved: IMG_9214.HEIC -> Other/\n",
      "Moved: Storm MCP Gateway - sponsorship.pdf -> Documents/\n",
      "Moved: the-olympic-office-episode1.mp4 -> Videos/\n",
      "Moved: desenhos-para-colorir-e-imprimir-52.webp -> Other/\n",
      "Moved: paginas-para-colorir-para-criancas-mandalas-74781.jpg.jpeg -> Images/\n",
      "Moved: PHOTO-2025-05-21-17-23-47.jpg -> Images/\n",
      "Moved: eichhoernchen-mandala-kostenlos-ausmalbild-ausdrucken-feat.webp -> Other/\n",
      "Moved: WhatsApp Image 2025-08-15 at 14.24.54.jpeg -> Images/\n",
      "Moved: TS5Plus.3mf -> Other/\n",
      "Moved: cli_project_COMPLETE.zip -> Archives/\n",
      "Moved: Figma.dmg -> Executables/\n",
      "Moved: language_learning_schedule.ics -> Other/\n",
      "Moved: PHOTO-2025-05-21-17-19-51.jpg -> Images/\n",
      "Moved: modes.md -> Other/\n",
      "Moved: mandala-de-gatinho-para-colorir-livro-de-colorir-para-adultos-e-criancas_392816-624.jpg -> Images/\n",
      "Moved: Youtube Thumbnails.zip -> Archives/\n",
      "Moved: comet_latest.dmg -> Executables/\n",
      "Moved: PHOTO-2025-05-21-17-20-04.jpg -> Images/\n",
      "Moved: 16-workflow-integration-final.srt -> Other/\n",
      "Moved: cal.ics -> Other/\n",
      "Moved: olympic-office-episode2.mp4 -> Videos/\n",
      "Moved: [SubtitleTools.com] Extra.Ordinary.2019.BRRip.XviD.MP3-XVID.txt -> Documents/\n",
      "Moved: PHOTO-2025-05-21-17-22-02.jpg -> Images/\n",
      "Moved: preliminary-report-text-based-course-prompts-custom-gpts-linkedin.pdf -> Documents/\n",
      "Moved: PHOTO-2025-05-24-22-25-10.jpg -> Images/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from collections import defaultdict\n",
    "\n",
    "# Define the downloads directory\n",
    "DOWNLOADS_DIR = os.path.expanduser(\"~/Downloads\")\n",
    "\n",
    "# Define file type categories\n",
    "FILE_CATEGORIES = {\n",
    "    \"Images\": [\".jpg\", \".jpeg\", \".png\", \".gif\", \".bmp\", \".svg\", \".tiff\"],\n",
    "    \"Documents\": [\".pdf\", \".doc\", \".docx\", \".txt\", \".odt\", \".rtf\", \".tex\"],\n",
    "    \"Spreadsheets\": [\".xls\", \".xlsx\", \".csv\", \".ods\"],\n",
    "    \"Presentations\": [\".ppt\", \".pptx\", \".key\"],\n",
    "    \"Archives\": [\".zip\", \".rar\", \".tar\", \".gz\", \".7z\"],\n",
    "    \"Executables\": [\".exe\", \".dmg\", \".pkg\", \".app\"],\n",
    "    \"Videos\": [\".mp4\", \".mkv\", \".mov\", \".avi\", \".flv\", \".wmv\"],\n",
    "    \"Music\": [\".mp3\", \".wav\", \".flac\", \".aac\", \".ogg\", \".m4a\"],\n",
    "    \"Code\": [\".py\", \".js\", \".html\", \".css\", \".java\", \".c\", \".cpp\", \".go\", \".sh\", \".ipynb\"]\n",
    "}\n",
    "\n",
    "# Reverse the dictionary to map file extensions to their respective categories\n",
    "EXTENSION_TO_CATEGORY = {ext: category for category, exts in FILE_CATEGORIES.items() for ext in exts}\n",
    "\n",
    "# Ensure categorized folders exist\n",
    "def create_folders():\n",
    "    for folder in FILE_CATEGORIES.keys():\n",
    "        folder_path = os.path.join(DOWNLOADS_DIR, folder)\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "\n",
    "# Organize files\n",
    "def organize_downloads():\n",
    "    create_folders()\n",
    "    \n",
    "    for filename in os.listdir(DOWNLOADS_DIR):\n",
    "        file_path = os.path.join(DOWNLOADS_DIR, filename)\n",
    "        \n",
    "        # Skip directories\n",
    "        if os.path.isdir(file_path):\n",
    "            continue\n",
    "        \n",
    "        # Get the file extension\n",
    "        _, ext = os.path.splitext(filename)\n",
    "        ext = ext.lower()\n",
    "        \n",
    "        # Determine the category\n",
    "        category = EXTENSION_TO_CATEGORY.get(ext, \"Other\")\n",
    "        \n",
    "        # Create 'Other' folder if needed\n",
    "        target_folder = os.path.join(DOWNLOADS_DIR, category)\n",
    "        if not os.path.exists(target_folder):\n",
    "            os.makedirs(target_folder)\n",
    "        \n",
    "        # Move the file\n",
    "        shutil.move(file_path, os.path.join(target_folder, filename))\n",
    "        print(f\"Moved: {filename} -> {category}/\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    organize_downloads()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699430aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-automate-tasks",
   "language": "python",
   "name": "oreilly-automate-tasks"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
