{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Working with Data: Files and Tabular Data\n",
    "\n",
    "This comprehensive notebook covers working with files and CSV data in Python, including reading/writing files, data manipulation with pandas, and leveraging AI tools for data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section1",
   "metadata": {},
   "source": [
    "## Part 1: Working with Files\n",
    "\n",
    "In Python, it's extremely simple to work with files like .txt or .md files. Let's explore file operations and how to leverage them for powerful workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai_tools import ask_ai\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reading-files",
   "metadata": {},
   "source": [
    "### Reading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "read-file",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To open a file\n",
    "with open(\"./file.txt\", \"r\") as f:\n",
    "    data = f.read()\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "writing-files",
   "metadata": {},
   "source": [
    "### Creating and Writing Files\n",
    "\n",
    "We can also create files easily in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "write-file",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"This is a file\"\n",
    "with open(\"summary-notes.txt\", \"w\") as f:\n",
    "    f.write(content)\n",
    "\n",
    "# Verify the file was created\n",
    "!cat ./summary-notes.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "file-modes",
   "metadata": {},
   "source": [
    "### File Modes\n",
    "\n",
    "Below are more examples for the different modes of reading and writing files available via the built-in `open()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "append-mode",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common file modes in Python's open() function:\n",
    "\n",
    "# \"a\" - Append - Opens file for appending, creates new file if not exists\n",
    "with open(\"summary-notes.txt\", \"a\") as f:\n",
    "    f.write(\"append this\")\n",
    "\n",
    "!cat summary-notes.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exclusive-mode",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"x\" - Exclusive creation - Opens for writing, fails if file exists\n",
    "try:\n",
    "    with open(\"file.txt\", \"x\") as f:\n",
    "        f.write(\"new file content\")\n",
    "except FileExistsError:\n",
    "    print(\"File already exists!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "readwrite-mode",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"+\" - Read and write mode\n",
    "with open(\"file.txt\", \"r+\") as f:  # Open for both reading and writing\n",
    "    data = f.read()\n",
    "    f.write(\"new data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ai-integration",
   "metadata": {},
   "source": [
    "### Combining File Operations with AI\n",
    "\n",
    "The cool stuff about being able to do this is that we can connect our ability of generating summaries of information with AI, along with our ability to read and write files in Python to create super powerful workflows.\n",
    "\n",
    "For example, below we will write single sentence summaries for multiple files containing information about different papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ai-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_with_papers = \"./assets-resources/papers/\"\n",
    "file_names = [\"paper1.txt\", \"paper2.txt\", \"paper3.txt\"]\n",
    "\n",
    "def summarize_this_paper(paper_contents):\n",
    "    summary_prompt = f\"Summarize this paper\\n\\n: {paper_contents} in a couple of sentences.\"\n",
    "    output_summary = ask_ai(summary_prompt)\n",
    "    \n",
    "    return output_summary\n",
    "\n",
    "paper_summaries_list = []\n",
    "for file_name in file_names:\n",
    "    file_path = folder_with_papers + file_name\n",
    "    with open(file_path, \"r\") as f:\n",
    "        contents_of_the_paper = f.read()\n",
    "    \n",
    "    paper_summary = summarize_this_paper(contents_of_the_paper)\n",
    "    paper_summaries_list.append(paper_summary)\n",
    "\n",
    "# Display the markdown content in the notebook\n",
    "markdown_content = \"# Paper Summaries\\n\\n\"\n",
    "for i, summary in enumerate(paper_summaries_list, 1):\n",
    "    markdown_content += f\"## Paper {i}\\n\\n\"\n",
    "    markdown_content += f\"{summary}\\n\\n\"\n",
    "        \n",
    "Markdown(markdown_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extraction",
   "metadata": {},
   "source": [
    "We can do similar things to extract specific information from documents, imagine you have a bunch of differently formatted invoices from which you would like to organize the information extracting things like the amounts and dates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part2",
   "metadata": {},
   "source": [
    "## Part 2: Working with Tabular Data (CSV Files)\n",
    "\n",
    "Let's learn about CSV files that structure data into rows and columns (tabular data!). Text files are great but sometimes you need a bit more organization and structure, that's where CSV files come into play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports-csv",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Super popular library for working with tabular data\n",
    "import pandas as pd\n",
    "from ai_tools import ask_ai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reading-csv",
   "metadata": {},
   "source": [
    "### Reading CSV Files\n",
    "\n",
    "Imagine you have a bunch of information about customer tickets organized in a .csv file that you would like to understand a bit more about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-csv",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_customer_tickets = pd.read_csv(\"./extracted_ticket_issues.csv\")\n",
    "\n",
    "data_customer_tickets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-description",
   "metadata": {},
   "source": [
    "The data contains 3 columns:\n",
    "1. `customer_name` - names of the customers\n",
    "2. `issue_description` - description of the issue they had\n",
    "3. `priority` - reference to the level of priority of that task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filtering",
   "metadata": {},
   "source": [
    "### Filtering Data\n",
    "\n",
    "We could use Python to get for example only the high priority issues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filter-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == indicates equivalence!\n",
    "data_customer_tickets[\"priority\"]==\"High\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "high-priority",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_priority_issues = data_customer_tickets[data_customer_tickets[\"priority\"]==\"High\"]\n",
    "\n",
    "# Now we can take a look at the issues themselves:\n",
    "high_priority_issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ai-categorization",
   "metadata": {},
   "source": [
    "### Using AI for Data Categorization\n",
    "\n",
    "Awesome! What we could do now is for example use our `ask_ai` tool to categorize the issues for us to help organizing the information, and then feed that back into the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "categorize",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_list = []\n",
    "for issue in high_priority_issues[\"issue_description\"]:\n",
    "    print(f\"Categorizing issue: {issue}\")\n",
    "    category = ask_ai(f\"Categorize this issue in just one single word and OUTPUT ONLY THAT WORD:\\n\\n issue: {issue}\\n category: \\n\")\n",
    "    print(f\"Category: {category}\")\n",
    "    categories_list.append(category)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "updating-df",
   "metadata": {},
   "source": [
    "Notice we use concepts we've learned before by looping over the issues, saving them to a list.\n",
    "\n",
    "Now with that information in hand we can actually update the dataframe accordingly, first we create a new column in the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add-column",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_customer_tickets[\"issue_category\"] = None\n",
    "\n",
    "# Update categories for high priority issues using the index from high_priority_issues\n",
    "for idx, category in zip(high_priority_issues.index, categories_list):\n",
    "    data_customer_tickets.loc[idx, \"issue_category\"] = category\n",
    "\n",
    "data_customer_tickets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "note-none",
   "metadata": {},
   "source": [
    "Notice that the issues for which we did not analyse still contain a `None` indicating they haven't been categorized yet!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "creating-data",
   "metadata": {},
   "source": [
    "## Creating and Managing Structured Data\n",
    "\n",
    "Besides analysing data, we can also create our own tables with information we care about.\n",
    "\n",
    "Let's start with a practical example - creating a camping trip gear checklist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "camping-gear",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a camping gear checklist\n",
    "camping_gear = {\n",
    "    \"item\": [\n",
    "        \"Tent\", \"Sleeping Bag\", \"Backpack\", \"Hiking Boots\",\n",
    "        \"Water Filter\", \"First Aid Kit\", \"Headlamp\", \"Camp Stove\"\n",
    "    ],\n",
    "    \"priority\": [\n",
    "        \"Essential\", \"Essential\", \"Essential\", \"Essential\",\n",
    "        \"High\", \"Essential\", \"High\", \"Medium\"\n",
    "    ],\n",
    "    \"estimated_cost\": [\n",
    "        299.99, 149.99, 199.99, 159.99,\n",
    "        89.99, 49.99, 39.99, 79.99\n",
    "    ],\n",
    "    \"packed\": [\n",
    "        False, False, False, False,\n",
    "        False, False, False, False\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "gear_df = pd.DataFrame(camping_gear)\n",
    "print(\"Camping Gear Checklist:\")\n",
    "display(gear_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-filters",
   "metadata": {},
   "source": [
    "### Working with Data Filters\n",
    "\n",
    "Let's demonstrate how to filter and analyze our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyze-gear",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_gear_requirements():\n",
    "    # Filter essential items\n",
    "    essential_gear = gear_df[gear_df['priority'] == 'Essential']\n",
    "    \n",
    "    # Calculate total cost of essential items\n",
    "    essential_cost = essential_gear['estimated_cost'].sum()\n",
    "    \n",
    "    # Get unpacked essential items\n",
    "    unpacked_essential = essential_gear[~essential_gear['packed']]\n",
    "    \n",
    "    print(f\"Total cost of essential gear: ${essential_cost:.2f}\")\n",
    "    print(\"\\nUnpacked essential items:\")\n",
    "    display(unpacked_essential[['item', 'estimated_cost']])\n",
    "\n",
    "analyze_gear_requirements()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "itinerary",
   "metadata": {},
   "source": [
    "### Creating a Trip Itinerary\n",
    "\n",
    "Let's create a more complex example with a detailed trip itinerary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-itinerary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trip_itinerary():\n",
    "    itinerary_data = {\n",
    "        'day': range(1, 6),\n",
    "        'date': pd.date_range('2024-06-01', periods=5),\n",
    "        'activity': [\n",
    "            'Arrival and Camp Setup',\n",
    "            'Mountain Trail Hike',\n",
    "            'Lake Exploration',\n",
    "            'Forest Adventure',\n",
    "            'Pack and Departure'\n",
    "        ],\n",
    "        'location': [\n",
    "            'Basecamp Area',\n",
    "            'Mountain Ridge Trail',\n",
    "            'Crystal Lake',\n",
    "            'Ancient Forest',\n",
    "            'Basecamp Area'\n",
    "        ],\n",
    "        'distance_km': [2, 8, 5, 6, 2],\n",
    "        'difficulty': [\n",
    "            'Easy',\n",
    "            'Hard',\n",
    "            'Moderate',\n",
    "            'Moderate',\n",
    "            'Easy'\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    itinerary_df = pd.DataFrame(itinerary_data)\n",
    "    return itinerary_df\n",
    "\n",
    "# Create and display the itinerary\n",
    "trip_itinerary = create_trip_itinerary()\n",
    "print(\"Trip Itinerary:\")\n",
    "display(trip_itinerary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trip-stats",
   "metadata": {},
   "source": [
    "### Analyzing Trip Statistics\n",
    "\n",
    "Let's add some analysis to our trip planning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyze-trip",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_trip_metrics(itinerary_df):\n",
    "    # Calculate total distance\n",
    "    total_distance = itinerary_df['distance_km'].sum()\n",
    "    \n",
    "    # Get difficulty breakdown\n",
    "    difficulty_counts = itinerary_df['difficulty'].value_counts()\n",
    "    \n",
    "    # Find longest day\n",
    "    longest_day = itinerary_df.loc[itinerary_df['distance_km'].idxmax()]\n",
    "    \n",
    "    print(f\"Trip Analysis:\")\n",
    "    print(f\"Total distance: {total_distance} km\")\n",
    "    print(\"\\nDifficulty breakdown:\")\n",
    "    display(difficulty_counts)\n",
    "    print(f\"\\nLongest day: Day {longest_day['day']} - {longest_day['activity']}\")\n",
    "    print(f\"Distance: {longest_day['distance_km']} km\")\n",
    "\n",
    "analyze_trip_metrics(trip_itinerary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "export-data",
   "metadata": {},
   "source": [
    "### Exporting and Saving Data\n",
    "\n",
    "Let's see how to save our data for later use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "export-csv",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_trip_data(gear_df, itinerary_df, filename_prefix):\n",
    "    # Export to CSV\n",
    "    gear_df.to_csv(f\"{filename_prefix}_gear.csv\", index=False)\n",
    "    itinerary_df.to_csv(f\"{filename_prefix}_itinerary.csv\", index=False)\n",
    "    print(f\"Data exported to {filename_prefix}_gear.csv and {filename_prefix}_itinerary.csv\")\n",
    "\n",
    "# Export our data\n",
    "export_trip_data(gear_df, trip_itinerary, \"camping_trip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "budget-calc",
   "metadata": {},
   "source": [
    "### Practical Exercise: Trip Budget Calculator\n",
    "\n",
    "Let's create a budget calculator for our trip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "budget-calculator",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_trip_budget(gear_df, itinerary_df):\n",
    "    # Equipment costs\n",
    "    total_gear_cost = gear_df['estimated_cost'].sum()\n",
    "    \n",
    "    # Daily expenses (example values)\n",
    "    daily_expenses = {\n",
    "        'food': 30,\n",
    "        'fuel': 10,\n",
    "        'miscellaneous': 15\n",
    "    }\n",
    "    \n",
    "    num_days = len(itinerary_df)\n",
    "    daily_total = sum(daily_expenses.values())\n",
    "    total_daily_costs = daily_total * num_days\n",
    "    \n",
    "    # Create budget summary\n",
    "    budget_summary = pd.DataFrame({\n",
    "        'Category': ['Gear', 'Food', 'Fuel', 'Miscellaneous'],\n",
    "        'Cost': [\n",
    "            total_gear_cost,\n",
    "            daily_expenses['food'] * num_days,\n",
    "            daily_expenses['fuel'] * num_days,\n",
    "            daily_expenses['miscellaneous'] * num_days\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    budget_summary['Percentage'] = (\n",
    "        budget_summary['Cost'] / budget_summary['Cost'].sum() * 100\n",
    "    ).round(1)\n",
    "    \n",
    "    return budget_summary\n",
    "\n",
    "# Calculate and display budget\n",
    "budget = calculate_trip_budget(gear_df, trip_itinerary)\n",
    "print(\"Trip Budget Summary:\")\n",
    "display(budget)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### Working with Files\n",
    "- Always use `with` statements when working with files to ensure proper closure\n",
    "- Different file modes serve different purposes:\n",
    "  - `\"r\"` for reading\n",
    "  - `\"w\"` for writing (creates new/overwrites)\n",
    "  - `\"a\"` for appending\n",
    "  - `\"r+\"` for reading and writing\n",
    "- Always handle potential file-related exceptions\n",
    "- File operations can be combined with data processing for powerful automation\n",
    "- Consider creating helper functions for common file operations\n",
    "\n",
    "### Working with CSV and Tabular Data\n",
    "- Pandas provides powerful tools for working with tabular data\n",
    "- DataFrames can be filtered and analyzed in various ways\n",
    "- Data can be exported to different formats (CSV, Excel)\n",
    "- Structured data makes analysis and planning easier\n",
    "- Always consider data types when creating DataFrames\n",
    "- Use appropriate column names and data organization\n",
    "- Remember to handle missing data appropriately\n",
    "\n",
    "### Combining AI with Data Processing\n",
    "- AI tools can be integrated with file and data operations for enhanced automation\n",
    "- Use AI for tasks like summarization, categorization, and information extraction\n",
    "- Combine traditional data processing with AI capabilities for powerful workflows\n",
    "\n",
    "In the next lesson, we'll explore Python packages, APIs, and more advanced data processing techniques!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}