./README.md
---
# O'Reilly Live Training - Automate Tasks with Python + AI 

## Quick Setup

### 1. Install UV
**Linux/macOS:**
```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

**Windows (PowerShell):**
```powershell
powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"
```

### 2. Clone and Setup Project

**Linux/macOS:**
```bash
git clone https://github.com/EnkrateiaLucca/oreilly-python-course
cd oreilly-python-course
uv venv
source .venv/bin/activate
uv pip install jupyterlab ipykernel openai pandas anthropic ollama requests beautifulsoup4 matplotlib ipywidgets playwright
python -m ipykernel install --user --name=oreilly-python-ai --display-name "O'Reilly Python AI"
playwright install
echo "‚úÖ Setup complete! Run: jupyter lab"
```

**Windows (PowerShell):**
```powershell
git clone https://github.com/EnkrateiaLucca/oreilly-python-course
cd oreilly-python-course
uv venv
.venv\Scripts\activate
uv pip install jupyterlab ipykernel openai pandas anthropic ollama requests beautifulsoup4 matplotlib ipywidgets playwright
python -m ipykernel install --user --name=oreilly-python-ai --display-name "O'Reilly Python AI"
playwright install
Write-Output "‚úÖ Setup complete! Run: jupyter lab"
```

### 3. Start Jupyter Lab
```bash
# Make sure you're in the project directory
jupyter lab
```

## API Setup

### Get your API keys:
1. OpenAI [API key](https://platform.openai.com/)
2. Anthropic [API key](https://docs.anthropic.com/en/docs/get-started)

### Setup your .env file
Change the `.env.example` file to `.env` and add your API keys:

```bash
OPENAI_API_KEY=<your openai api key>
ANTHROPIC_API_KEY=<your claude api key>
```

## What's Included
Dependencies installed:
- **AI Libraries:** openai, anthropic, ollama
- **Data Science:** pandas, matplotlib
- **Web Scraping:** requests, beautifulsoup4, playwright
- **Jupyter:** jupyterlab, ipykernel, ipywidgets


---
./oreilly-python-course-llms.txt
---
./README.md
---
# O'Reilly Live Training - Automate Tasks with Python + AI 

## Quick Setup

### 1. Install UV
**Linux/macOS:**
```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

**Windows (PowerShell):**
```powershell
powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"
```

### 2. Clone and Setup Project

**Linux/macOS:**
```bash
git clone https://github.com/EnkrateiaLucca/oreilly-python-course
cd oreilly-python-course
uv venv
source .venv/bin/activate
uv pip install jupyterlab ipykernel openai pandas anthropic ollama requests beautifulsoup4 matplotlib ipywidgets playwright
python -m ipykernel install --user --name=oreilly-python-ai --display-name "O'Reilly Python AI"
playwright install
echo "‚úÖ Setup complete! Run: jupyter lab"
```

**Windows (PowerShell):**
```powershell
git clone https://github.com/EnkrateiaLucca/oreilly-python-course
cd oreilly-python-course
uv venv
.venv\Scripts\activate
uv pip install jupyterlab ipykernel openai pandas anthropic ollama requests beautifulsoup4 matplotlib ipywidgets playwright
python -m ipykernel install --user --name=oreilly-python-ai --display-name "O'Reilly Python AI"
playwright install
Write-Output "‚úÖ Setup complete! Run: jupyter lab"
```

### 3. Start Jupyter Lab
```bash
# Make sure you're in the project directory
jupyter lab
```

## API Setup

### Get your API keys:
1. OpenAI [API key](https://platform.openai.com/)
2. Anthropic [API key](https://docs.anthropic.com/en/docs/get-started)

### Setup your .env file
Change the `.env.example` file to `.env` and add your API keys:

```bash
OPENAI_API_KEY=<your openai api key>
ANTHROPIC_API_KEY=<your claude api key>
```

## What's Included
Dependencies installed:
- **AI Libraries:** openai, anthropic, ollama
- **Data Science:** pandas, matplotlib
- **Web Scraping:** requests, beautifulsoup4, playwright
- **Jupyter:** jupyterlab, ipykernel, ipywidgets


---


---
./setup.ps1
---
# Set project name (adjust as needed)
$projectName = "my-uv-project"
$kernelDisplayName = "My UV Project"

Write-Output "üîß Initializing project..."
uv init --bare

Write-Output "üì¶ Installing JupyterLab and ipykernel..."
uv add --dev jupyterlab ipykernel

Write-Output "üß† Registering Jupyter kernel..."
uv run python -m ipykernel install --user --name=$projectName --display-name "$kernelDisplayName"

Write-Output "‚úÖ Setup complete. Run with:"
Write-Output "uv run jupyter lab"


---
./setup.sh
---
#!/bin/bash

# Set project name (adjust as needed)
PROJECT_NAME="my-uv-project"
KERNEL_NAME="My UV Project"

# Exit if any command fails
set -e

echo "üîß Initializing project..."
uv init --bare

echo "üì¶ Installing JupyterLab and ipykernel..."
uv add --dev jupyterlab ipykernel pandas matplotlib numpy openai anthropic

echo "üß† Registering Jupyter kernel..."
uv run python -m ipykernel install --user --name="$PROJECT_NAME" --display-name "$KERNEL_NAME"

echo "‚úÖ Setup complete. Run with:"
echo "uv run jupyter lab"


---
./trouble_shooting_setups.md
---
# Complete Beginner Setup Guide

## üçé Mac Setup (Complete from scratch)

**Step 1: Install Homebrew (package manager)**
```bash
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
```

**Step 2: Install Git**
```bash
brew install git
```

**Step 3: Fix permissions and install UV**
```bash
chmod +w ~/.bash_profile ~/.zshrc
curl -LsSf https://astral.sh/uv/install.sh | sh
source ~/.zshrc
```

**Step 4: Setup the course**
```bash
git clone https://github.com/EnkrateiaLucca/oreilly-python-course
cd oreilly-python-course
uv venv
source .venv/bin/activate
uv pip install jupyterlab ipykernel openai pandas anthropic ollama requests beautifulsoup4 matplotlib ipywidgets playwright
python -m ipykernel install --user --name=oreilly-python-ai --display-name "O'Reilly Python AI"
playwright install
echo "‚úÖ Setup complete! Run: jupyter lab"
```

---

## ü™ü Windows Setup (Complete from scratch)

**Step 1: Install Git (Download and run installer)**
- Go to: https://git-scm.com/download/win
- Download and install with default settings

**Step 2: Open PowerShell as Administrator and install UV**
```powershell
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"
```

**Step 3: Close and reopen PowerShell (normal user), then setup course**
```powershell
git clone https://github.com/EnkrateiaLucca/oreilly-python-course
cd oreilly-python-course
uv venv
.venv\Scripts\activate
uv pip install jupyterlab ipykernel openai pandas anthropic ollama requests beautifulsoup4 matplotlib ipywidgets playwright
python -m ipykernel install --user --name=oreilly-python-ai --display-name "O'Reilly Python AI"
playwright install
Write-Output "‚úÖ Setup complete! Run: jupyter lab"
```

---

## üöÄ Start Working
After setup, always run:

**Mac/Linux:**
```bash
cd oreilly-python-course
source .venv/bin/activate
jupyter lab
```

**Windows:**
```powershell
cd oreilly-python-course
.venv\Scripts\activate
jupyter lab
```

---

## üîß Troubleshooting

### Mac Issues:
- If Homebrew install fails: Try running `xcode-select --install` first
- If permission denied: Run `chmod +w ~/.bash_profile ~/.zshrc`
- If uv not found: Restart terminal or run `source ~/.zshrc`

### Windows Issues:
- If PowerShell blocked: Run as Administrator and set execution policy
- If Git not found: Restart PowerShell after Git installation
- If uv not found: Close and reopen PowerShell

### Common Issues:
- If packages fail to install: Make sure virtual environment is activated
- If Jupyter won't start: Run `jupyter lab --generate-config` then try again
- If kernel not found in Jupyter: Re-run the `python -m ipykernel install` command

---

## üìö What You'll Have After Setup

‚úÖ **Python Environment**: Isolated virtual environment with UV  
‚úÖ **Jupyter Lab**: Interactive notebook environment  
‚úÖ **AI Libraries**: OpenAI, Anthropic, Ollama for AI integration  
‚úÖ **Data Science**: Pandas, Matplotlib for data analysis  
‚úÖ **Web Automation**: Playwright, BeautifulSoup for web scraping  
‚úÖ **Course Materials**: All notebooks organized and ready to use

---

## üéØ Next Steps

1. **Open Jupyter Lab**: Run `jupyter lab` in your activated environment
2. **Navigate to**: `notebooks/01-python-fundamentals/` to start learning
3. **Follow the progression**: Fundamentals ‚Üí AI APIs ‚Üí Automation Projects ‚Üí Exercises
4. **Practice**: Work through exercises to solidify your learning

Happy coding! üöÄ

---
./automation_recipes_prompts/financial-analysis-prompt.md
---
2Ô∏è‚É£ Financial & Data Analysis Automation
‚ÄúGenerate a Python script that performs financial analysis on a CSV file containing stock trading data. The dataset includes columns: Date, Stock Symbol, Open Price, Close Price, Volume, Moving Average (50-day), and RSI (Relative Strength Index). The script should:‚Äù

Detailed Steps in the Prompt:
	1.	Load & Clean Data: Use pandas to load the CSV, handle missing values, and ensure data types are correct.
	2.	Key Financial Metrics Calculation:
	‚Ä¢	Compute daily returns and rolling volatility.
	‚Ä¢	Calculate a simple moving average (SMA) and exponential moving average (EMA) for each stock.
	‚Ä¢	Generate Bollinger Bands for price movement analysis.
	‚Ä¢	Compute Relative Strength Index (RSI) and MACD for trend analysis.
	3.	Visualization & Reporting:
	‚Ä¢	Use matplotlib and seaborn to generate:
	‚Ä¢	Line charts for stock prices over time.
	‚Ä¢	A candlestick chart using mplfinance.
	‚Ä¢	A heatmap of correlations between different stock metrics.
	‚Ä¢	Save these charts as PNG images.
	4.	Export Analysis Report:
	‚Ä¢	Generate an Excel report with the analyzed data and charts.
	‚Ä¢	Use xlsxwriter to format and insert images into the Excel file.

---
./automation_recipes_prompts/outloook-send-emails-prompt.md
---
1Ô∏è‚É£ Automating Outlook Table Processing & Sending Emails

Example Prompt:

‚ÄúGenerate a Python script using win32com.client to read the latest email in an Outlook inbox, extract a table from the email body, process the data to extract relevant information (e.g., rows where ‚ÄòStatus‚Äô is ‚ÄòPending‚Äô and amounts greater than $1,000), and send a summary email to multiple recipients. The script should format the extracted data into an HTML table and send an email with a custom message.‚Äù

Additional Requirements for the Script:
	‚Ä¢	The script should use win32com.client to access Outlook emails.
	‚Ä¢	It should identify and extract the latest email containing a table.
	‚Ä¢	Use pandas to parse and filter the table based on business logic (e.g., only extract rows where a certain condition is met).
	‚Ä¢	Format the extracted data as an HTML email.
	‚Ä¢	Send an email to multiple recipients using win32com.client with a customized message.

---
./automation_recipes_prompts/pdf-tasks-prompts.md
---


# Prompt Examples for PDF Tasks

1Ô∏è‚É£ Extracting Text or Data from PDFs

Prompt:
‚ÄúGenerate a Python script that extracts text and tables from a PDF file. The script should use PyMuPDF (fitz) to extract text and pdfplumber to extract structured tables. It should save the extracted data into a .txt file for text and a .csv file for tables. Handle multi-page PDFs and ensure proper formatting.‚Äù

2Ô∏è‚É£ Merging, Splitting, and Organizing PDFs

Prompt:
‚ÄúGenerate a Python script using PyPDF2 to merge multiple PDFs into a single file and split a given PDF into separate pages. The script should prompt the user to specify which pages to extract and save them as individual files. Ensure the output filenames are automatically numbered.‚Äù

3Ô∏è‚É£ Filling Out and Signing PDFs

Prompt:
‚ÄúGenerate a Python script that fills out a PDF form using pypdf. The script should take input data from a JSON file, populate the corresponding fields in the PDF, and save the completed form. Additionally, the script should overlay a digital signature image on a specified page using reportlab.‚Äù

4Ô∏è‚É£ Annotating, Reviewing, and Commenting on PDFs

Prompt:
‚ÄúGenerate a Python script that adds annotations to a PDF using PyMuPDF (fitz). The script should allow users to highlight text, add comments, and insert sticky notes at specific locations. The annotations should be saved in a new PDF file.‚Äù

5Ô∏è‚É£ Converting PDFs to Other Formats

Prompt:
‚ÄúGenerate a Python script that converts a PDF into different formats using pdf2docx (to Word), camelot (to extract tables as CSV), and pdf2image (to convert pages into PNG images). The script should allow users to specify the desired output format and save the converted files accordingly.‚Äù



---
./automation_recipes_prompts/ppt-automation-prompt.md
---
# Prompt 1
Please write a Python script that performs the following tasks:

- Accesses the "input" folder and reads all Excel files within it.
- For each file, it retrieves the financial data located in the first worksheet, from column A to P, and excludes any rows with missing values.
- Group the entire data by the "Product" column (C) and sum up the sales column (J) for each group.
- Using the grouped data, the script should create a chart using the seaborn library for each file, and save it in the "charts" folder. If the folder does not exist, the script should create it. . The chart should include a title, appropriate axis labels, and a legend.
- The script should then create a new PowerPoint presentation, insert a slide for each chart, and above the chart, include a title. The title should be the respective excel file name without file extension. And make sure that the chart and title do not overlap
- The PowerPoint presentation should be saved in the same directory as the input files and named "financial_data.pptx".
- The script should be robust and handle any potential errors gracefully, providing appropriate error messages and notifications, and also by including proper error handling mechanisms.

Input data example in here: 

- https://github.com/Sven-Bo/automate-office-tasks-using-chatgpt-python/tree/master/02_Automate_PowerPoint/input

# Prompt 2

Please save the final PowerPoint presentation in the same directory as the Python script

```python
import os
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from pptx import Presentation
from pptx.util import Inches

# Determine the directory of the script
script_dir = os.path.dirname(os.path.abspath(__file__))

input_folder = os.path.join(script_dir, 'input')
charts_folder = os.path.join(script_dir, 'charts')
ppt_file = 'financial_data.pptx'

# Create the charts folder if it doesn't exist
if not os.path.exists(charts_folder):
    os.mkdir(charts_folder)

# Create a new PowerPoint presentation
prs = Presentation()

# Iterate through all Excel files in the input folder
for excel_file in os.listdir(input_folder):
    if not excel_file.endswith('.xlsx'):
        continue

    # Read the financial data from the first worksheet of the Excel file
    file_path = os.path.join(input_folder, excel_file)
    df = pd.read_excel(file_path, sheet_name=0, usecols="A:P")
    df = df.dropna()

    # Group the data by the "Product" column and sum up the "Sales" column
    grouped = df.groupby('Product').sum()['Sales']

    # Create a chart using the seaborn library
    sns.barplot(x=grouped.index, y=grouped.values)
    plt.title(excel_file)
    plt.xlabel('Product')
    plt.ylabel('Sales')
    plt.tight_layout()

    # Save the chart to the charts folder
    chart_file = excel_file.replace('.xlsx', '.png')
    chart_path = os.path.join(charts_folder, chart_file)
    plt.savefig(chart_path)

    # Add a slide to the PowerPoint presentation and insert the chart and title
    slide = prs.slides.add_slide(prs.slide_layouts[5])
    title = slide.shapes.title
    title.text = excel_file.replace('.xlsx','')

    chart_file = chart_path
    left = Inches(0.5)
    top = Inches(1)
    width = Inches(9)
    height = Inches(6)
    slide.shapes.add_picture(chart_file, left, top, width=width, height=height)

# Save the PowerPoint presentation in the same directory as the script
ppt_path = os.path.join(script_dir, ppt_file)
prs.save(ppt_path)
```


---
./automation_recipes_prompts/prompt_learn_ai_python.md
---
I'm learning Python and I just covered these topics:
"""
Python syntax, different data types, variables, comparators, conditionals, writing reading files in files, working with tabular, lists, loops, dictionaries, 
"""
here is the task I want to do:
I want to automate data analysis of .csv files and create automatic reports into a .pdf.

Can you break my task down into very smaller python script/task that I can practice?

---
./requirements/requirements.in
---
ipykernel
openai
pandas
anthropic
ollama
requests
beautifulsoup4
matplotlib
ipywidgets
playwright

---
./requirements/requirements.txt
---
# This file was autogenerated by uv via the following command:
#    uv pip compile ./requirements/requirements.in -o ./requirements/requirements.txt
annotated-types==0.7.0
    # via pydantic
anthropic==0.45.2
    # via -r ./requirements/requirements.in
anyio==4.8.0
    # via
    #   anthropic
    #   httpx
    #   openai
appnope==0.1.4
    # via ipykernel
asttokens==3.0.0
    # via stack-data
beautifulsoup4==4.13.0
    # via -r ./requirements/requirements.in
certifi==2024.12.14
    # via
    #   httpcore
    #   httpx
    #   requests
charset-normalizer==3.4.1
    # via requests
comm==0.2.2
    # via
    #   ipykernel
    #   ipywidgets
contourpy==1.3.1
    # via matplotlib
cycler==0.12.1
    # via matplotlib
debugpy==1.8.12
    # via ipykernel
decorator==5.1.1
    # via ipython
distro==1.9.0
    # via
    #   anthropic
    #   openai
executing==2.1.0
    # via stack-data
fonttools==4.55.8
    # via matplotlib
greenlet==3.1.1
    # via playwright
h11==0.14.0
    # via httpcore
httpcore==1.0.7
    # via httpx
httpx==0.28.1
    # via
    #   anthropic
    #   ollama
    #   openai
idna==3.10
    # via
    #   anyio
    #   httpx
    #   requests
ipykernel==6.29.5
    # via -r ./requirements/requirements.in
ipython==8.31.0
    # via
    #   ipykernel
    #   ipywidgets
ipywidgets==8.1.5
    # via -r ./requirements/requirements.in
jedi==0.19.2
    # via ipython
jiter==0.8.2
    # via
    #   anthropic
    #   openai
jupyter-client==8.6.3
    # via ipykernel
jupyter-core==5.7.2
    # via
    #   ipykernel
    #   jupyter-client
jupyterlab-widgets==3.0.13
    # via ipywidgets
kiwisolver==1.4.8
    # via matplotlib
matplotlib==3.10.0
    # via -r ./requirements/requirements.in
matplotlib-inline==0.1.7
    # via
    #   ipykernel
    #   ipython
nest-asyncio==1.6.0
    # via ipykernel
numpy==2.2.2
    # via
    #   contourpy
    #   matplotlib
    #   pandas
ollama==0.4.7
    # via -r ./requirements/requirements.in
openai==1.60.0
    # via -r ./requirements/requirements.in
packaging==24.2
    # via
    #   ipykernel
    #   matplotlib
pandas==2.2.3
    # via -r ./requirements/requirements.in
parso==0.8.4
    # via jedi
pexpect==4.9.0
    # via ipython
pillow==11.1.0
    # via matplotlib
platformdirs==4.3.6
    # via jupyter-core
playwright==1.50.0
    # via -r ./requirements/requirements.in
prompt-toolkit==3.0.50
    # via ipython
psutil==6.1.1
    # via ipykernel
ptyprocess==0.7.0
    # via pexpect
pure-eval==0.2.3
    # via stack-data
pydantic==2.10.5
    # via
    #   anthropic
    #   ollama
    #   openai
pydantic-core==2.27.2
    # via pydantic
pyee==12.1.1
    # via playwright
pygments==2.19.1
    # via ipython
pyparsing==3.2.1
    # via matplotlib
python-dateutil==2.9.0.post0
    # via
    #   jupyter-client
    #   matplotlib
    #   pandas
pytz==2024.2
    # via pandas
pyzmq==26.2.0
    # via
    #   ipykernel
    #   jupyter-client
requests==2.32.3
    # via -r ./requirements/requirements.in
six==1.17.0
    # via python-dateutil
sniffio==1.3.1
    # via
    #   anthropic
    #   anyio
    #   openai
soupsieve==2.6
    # via beautifulsoup4
stack-data==0.6.3
    # via ipython
tornado==6.4.2
    # via
    #   ipykernel
    #   jupyter-client
tqdm==4.67.1
    # via openai
traitlets==5.14.3
    # via
    #   comm
    #   ipykernel
    #   ipython
    #   ipywidgets
    #   jupyter-client
    #   jupyter-core
    #   matplotlib-inline
typing-extensions==4.12.2
    # via
    #   anthropic
    #   anyio
    #   beautifulsoup4
    #   ipython
    #   openai
    #   pydantic
    #   pydantic-core
    #   pyee
tzdata==2025.1
    # via pandas
urllib3==2.3.0
    # via requests
wcwidth==0.2.13
    # via prompt-toolkit
widgetsnbextension==4.0.13
    # via ipywidgets


---
./scripts/add_movie_to_watchlist.py
---
import re
from playwright.sync_api import Playwright, sync_playwright, expect
import os
import sys

def run(playwright: Playwright) -> None:
    movie_to_search = sys.argv[1] 
    browser = playwright.chromium.launch(headless=False)
    context = browser.new_context()
    page = context.new_page()
    page.goto("https://letterboxd.com/")
    page.get_by_label("Do not consent").click()
    page.get_by_role("link", name="Sign in").click()
    page.get_by_label("Username").fill(os.environ["LETTERBOXD_USER"])
    page.get_by_label("Username").press("Tab")
    page.get_by_label("Password").fill(os.environ["LETTERBOXD_PWD"])
    page.get_by_role("button", name="Sign in").click()
    page.locator(".navitem > .replace").click()
    page.get_by_label("Search:").fill(movie_to_search)
    page.get_by_role("button", name="Search").click()
    page.get_by_role("link", name=movie_to_search, exact=True).first.click()
    page.get_by_role("link", name="Add this film to your").click()

    # ---------------------
    context.close()
    browser.close()


with sync_playwright() as playwright:
    run(playwright)


---
./scripts/ai_tools.py
---
from openai import OpenAI
import anthropic
import ollama
import json

def ask_ai(prompt, model_name="gpt-4o-mini"):
    """
    Send prompt to an LLM and get output text back.    
    """
    if "claude" in model_name:
        client = anthropic.Anthropic()

        # Send a message to the Claude AI
        response = client.messages.create(
            model=model_name,
            messages=[
                {
                    "role": "user", "content": prompt
                }
                ],
            max_tokens=4000,
        )
        output = response.content[0].text
        return output        
    else:
        client = OpenAI()
        response = client.chat.completions.create(
            model=model_name,
            messages=[
                {
                    "role": "system",
                    "content": "You are a helpful assistant."
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
        )
        output = response.choices[0].message.content
        return output


def ask_local_ai(prompt, model_name="llama3.2", structured=False):
    """
    Send prompt to a local LLM and get output text back.
    """
    client = ollama.Client()
    if structured:
        response = client.chat(model=model_name, 
                               messages=
                               [
                                   {"role": "user", "content": prompt}
                                ],
                               format='json')
        return response.message.content
    else:
        response = client.chat(model=model_name, 
                               messages=
                               [
                                   {"role": "user", "content": prompt}
                                ])
        return response.message.content


def parse_dates_list(output_str):
    """
    Parse the string output containing a Python list of dates into an actual Python list.
    
    Args:
        output_str (str): String containing a Python list representation of dates
        
    Returns:
        list: List of date strings
    """
    # Remove markdown code block formatting if present
    output_str = output_str.replace('```python', '').replace('```', '').strip()
    
    # Safely evaluate the string as a Python expression
    dates_list = eval(output_str)
    
    return dates_list

def parse_json_output(json_str):
    """
    This function parses the JSON output from the AI and removes the markdown code block markers if present.
    """
    # Remove markdown code block markers if present
    json_str = json_str.replace('```json', '').replace('```', '').strip()
    
    # Parse the JSON string into a Python dictionary
    try:
        return json.loads(json_str)
    except json.JSONDecodeError:
        print("Error: Could not parse JSON string")
        return None

---
./scripts/claude_script.py
---
# /// script
# dependencies = [
#   "numpy",
#   "matplotlib",
#   "pandas", 
#   "reportlab",
# ]
# ///

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from reportlab.pdfgen import canvas
from reportlab.lib.pagesizes import letter
from reportlab.lib.utils import ImageReader
import io

# Generate synthetic data
np.random.seed(42)
dates = pd.date_range(start='2024-01-01', end='2024-12-31', freq='D')
values = np.cumsum(np.random.randn(len(dates))) + 100
data = pd.DataFrame({'date': dates, 'value': values})

# Create visualization
plt.figure(figsize=(10, 6))
plt.plot(data['date'], data['value'])
plt.title('Time Series Analysis')
plt.xlabel('Date')
plt.ylabel('Value')
plt.xticks(rotation=45)
plt.tight_layout()

# Save plot to bytes buffer
img_buffer = io.BytesIO()
plt.savefig(img_buffer, format='png', dpi=300, bbox_inches='tight')
img_buffer.seek(0)

# Create PDF
c = canvas.Canvas("report.pdf", pagesize=letter)
width, height = letter

# Add title
c.setFont("Helvetica-Bold", 16)
c.drawString(72, height - 72, "Data Analysis Report")

# Add text
c.setFont("Helvetica", 12)
c.drawString(72, height - 100, f"Data points: {len(data)}")
c.drawString(72, height - 120, f"Average value: {data['value'].mean():.2f}")
c.drawString(72, height - 140, f"Standard deviation: {data['value'].std():.2f}")

# Add plot
c.drawImage(ImageReader(img_buffer), 72, height - 500, width=450, height=300)

c.save()
print("Report generated as report.pdf")

---
./scripts/demo_utils.py
---
from IPython.display import HTML

def display_chat_message(role, content, background_color="#ffffff"):
    html = f"""
    <div style="background-color: {background_color}; padding: 10px; margin: 5px; border-radius: 10px; color: #000000;">
        <strong>{role}:</strong><br>
        {content}
    </div>
    """
    return HTML(html)

def display_comparison(*responses):
    html = "<div style='display: flex; flex-wrap: wrap; gap: 10px;'>"
    for provider, response in responses:
        html += f"""
        <div style='flex: 1; min-width: 300px; background-color: #f8f9fa; padding: 15px; border-radius: 8px;'>
            <h3 style='color: #2c3e50;'>{provider}</h3>
            <p style='color: #34495e;'>{response}</p>
        </div>
        """
    html += "</div>"
    return HTML(html)

---
./scripts/example_uv_run_file.py
---
# /// script
# dependencies = [
#   "requests<3",
#   "rich",
# ]
# ///

import requests
from rich.pretty import pprint

resp = requests.get("https://peps.python.org/api/peps.json")
data = resp.json()
pprint([(k, v["title"]) for k, v in data.items()][:10])

---
./scripts/extract_data_from_pdf.py
---
# /// script
# dependencies = [
#   "pymupdf",
#   "pdfplumber",
# ]
# ///

import fitz  # PyMuPDF
import pdfplumber
import csv
import argparse

def extract_text_from_pdf(pdf_path, text_output_path):
    """Extracts text from a PDF and saves it to a text file."""
    with fitz.open(pdf_path) as doc, open(text_output_path, 'w', encoding='utf-8') as text_file:
        for page in doc:
            text = page.get_text("text")  # Extract text from the page
            text_file.write(text + '\n' + '-'*80 + '\n')  # Separate pages
    print(f"Text extracted and saved to {text_output_path}")

def extract_tables_from_pdf(pdf_path, csv_output_path):
    """Extracts tables from a PDF and saves them as CSV files."""
    with pdfplumber.open(pdf_path) as pdf:
        tables = []
        for i, page in enumerate(pdf.pages):
            extracted_tables = page.extract_tables()
            if extracted_tables:
                tables.extend(extracted_tables)
    
    if tables:
        with open(csv_output_path, 'w', newline='', encoding='utf-8') as csv_file:
            writer = csv.writer(csv_file)
            for table in tables:
                for row in table:
                    writer.writerow(row)
        print(f"Tables extracted and saved to {csv_output_path}")
    else:
        print("No tables found in the PDF.")

def main():
    parser = argparse.ArgumentParser(description='Extract text and tables from PDF files')
    parser.add_argument('pdf_path', help='Path to the input PDF file')
    parser.add_argument('--text-output', default='extracted_text.txt', 
                       help='Path for the extracted text output (default: extracted_text.txt)')
    parser.add_argument('--csv-output', default='extracted_tables.csv',
                       help='Path for the extracted tables output (default: extracted_tables.csv)')
    
    args = parser.parse_args()
    
    extract_text_from_pdf(args.pdf_path, args.text_output)
    extract_tables_from_pdf(args.pdf_path, args.csv_output)

if __name__ == "__main__":
    main()

---
./scripts/file_backup_reorg.py
---
#!/usr/bin/env -S uv run --script
# /// script
# requires-python = ">=3.8"
# dependencies = []
# ///

import os
import shutil
from datetime import datetime

# Config
SOURCE_FOLDER = "/Users/greatmaster/Desktop/projects/oreilly-live-trainings/oreilly-python-course"
DEST_FOLDER = "/Users/greatmaster/Desktop/projects/tmp_files"
TODAY = datetime.today().strftime('%Y-%m-%d')

# Create destination if it doesn't exist
os.makedirs(DEST_FOLDER, exist_ok=True)

# Walk the source folder
for root, dirs, files in os.walk(SOURCE_FOLDER):
    # Limit folder depth to 2 below source (so total 3: base + 2)
    depth = root[len(SOURCE_FOLDER):].count(os.sep)
    if depth > 2:
        continue

    # Compute relative path and new destination
    rel_path = os.path.relpath(root, SOURCE_FOLDER)
    target_dir = os.path.join(DEST_FOLDER, rel_path)
    os.makedirs(target_dir, exist_ok=True)

    # Copy and rename files
    for file in files:
        src_file = os.path.join(root, file)
        new_filename = f"{TODAY}_{file}"
        dst_file = os.path.join(target_dir, new_filename)
        shutil.copy2(src_file, dst_file)

print(f"Backup completed with date-prefix '{TODAY}'.")


---
./scripts/generate_pdf_v1.py
---
# /// script
# dependencies = [
#   "fpdf2",
# ]
# ///

from fpdf import FPDF
import argparse
from datetime import datetime
import os

def create_contract_pdf(output_path, party_a="John Doe", party_b="Jane Smith"):
    # Create a PDF instance
    pdf = FPDF()
    pdf.set_auto_page_break(auto=True, margin=15)
    pdf.add_page()
    pdf.set_font("Arial", style='', size=12)
    
    # Title
    pdf.set_font("Arial", style='B', size=16)
    pdf.cell(200, 10, "Sample Contract Agreement", ln=True, align='C')
    pdf.ln(10)
    
    # Contract text
    pdf.set_font("Arial", size=12)
    current_date = datetime.now().strftime("%dth day of %B %Y")
    
    contract_text = f"""This Contract Agreement is made on this {current_date}, between:
Party A: {party_a}, residing at 123 Example Street, Sample City.
Party B: {party_b}, residing at 456 Business Avenue, Business City.
Whereas Party A agrees to provide consulting services to Party B for a period of six months,
starting from {(datetime.now().replace(day=5)).strftime("%B %d, %Y")}, under the following terms:
1. Scope of Services:
   Party A will provide business consulting services, including but not limited to market
   analysis, strategy planning, and financial guidance.
2. Payment Terms:
   Party B agrees to pay Party A a monthly fee of $5,000, payable on the first day of each month.
3. Confidentiality:
   Both parties agree to keep confidential all business and proprietary information exchanged
   during the course of this agreement.
4. Termination Clause:
   Either party may terminate this agreement with a 30-day written notice.
Signed and agreed upon by:
Party A: {party_a}         Party B: {party_b}
Date: {datetime.now().strftime("%B %d, %Y")}
"""
    # Add contract text
    pdf.multi_cell(0, 7, contract_text)
    pdf.ln(10)
    
    # Add a table title
    pdf.set_font("Arial", style='B', size=14)
    pdf.cell(200, 10, "Payment Schedule", ln=True, align='C')
    pdf.ln(5)
    
    # Table headers
    pdf.set_font("Arial", style='B', size=12)
    pdf.cell(50, 10, "Month", border=1, align='C')
    pdf.cell(50, 10, "Due Date", border=1, align='C')
    pdf.cell(50, 10, "Amount ($)", border=1, align='C')
    pdf.ln()
    
    # Generate payment schedule for 6 months
    start_date = datetime.now().replace(day=5)
    payment_schedule = []
    for i in range(6):
        month_date = start_date.replace(month=start_date.month + i)
        payment_schedule.append((
            month_date.strftime("%B"),
            month_date.strftime("%Y-%m-%d"),
            "$5,000"
        ))
    
    # Table data
    pdf.set_font("Arial", size=12)
    for row in payment_schedule:
        for item in row:
            pdf.cell(50, 10, str(item), border=1, align='C')
        pdf.ln()
    
    # Save the PDF
    pdf.output(output_path)
    print(f"Contract PDF created successfully at: {output_path}")

def main():
    parser = argparse.ArgumentParser(description='Generate a sample contract PDF')
    parser.add_argument('--output', default='sample_contract.pdf',
                       help='Output path for the PDF file (default: sample_contract.pdf)')
    parser.add_argument('--party-a', default='John Doe',
                       help='Name of Party A (default: John Doe)')
    parser.add_argument('--party-b', default='Jane Smith',
                       help='Name of Party B (default: Jane Smith)')
    
    args = parser.parse_args()
    
    # Ensure the output directory exists
    os.makedirs(os.path.dirname(os.path.abspath(args.output)), exist_ok=True)
    
    create_contract_pdf(args.output, args.party_a, args.party_b)

if __name__ == "__main__":
    main()

---
./scripts/get_popular_reviews.py
---
import openai
import subprocess
import re
from playwright.sync_api import Playwright, sync_playwright, expect
import os
import sys
import pyperclip

def run(playwright: Playwright) -> None:
    browser = playwright.chromium.launch(headless=False)
    context = browser.new_context()
    page = context.new_page()
    page.goto("https://letterboxd.com/")
    page.get_by_label("Do not consent").click()
    page.get_by_role("link", name="Sign in").click()
    page.get_by_label("Username").fill(os.environ["LETTERBOXD_USER"])
    page.get_by_label("Username").press("Tab")
    page.get_by_label("Password").fill(os.environ["LETTERBOXD_PWD"])
    page.get_by_role("button", name="Sign in").click()
    page.locator(".navitem > .replace").click()
    page.get_by_label("Search:").fill(movie_to_search)
    page.get_by_role("button", name="Search").click()
    page.get_by_role("link", name=movie_to_search, exact=True).first.click()
    page.get_by_role("link", name="Popular reviews").click()
    try:
        page.get_by_role("link", name="more").click()
    except:
        print("No big reviews to expand")
    page.locator("#content").click()
    page.locator("body").press("ControlOrMeta+a")
    page.locator("body").press("ControlOrMeta+c")

    # ---------------------
    context.close()
    browser.close()

movie_to_search = sys.argv[1] 
with sync_playwright() as playwright:
    run(playwright)



# Get clipboard content
clipboard_content = pyperclip.paste()

# Extract reviews using OpenAI
from openai import OpenAI
client = OpenAI()

def process_movie_reviews(prompt_question):
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "system", "content": "You are a movie review curator. \
                                                    Your task is to extract and format \
                                                    movie reviews from raw HTML content"},
                    {"role": "user", "content": prompt_question}]
    )
    
    return response.choices[0].message.content

# Save formatted reviews to file
reviews_filename = f"{movie_to_search}-reviews.md"
with open(reviews_filename, "w", encoding="utf-8") as f:
    f.write(process_movie_reviews(f"Extract the movie reviews from this raw html: \n {clipboard_content}"))

# Open the file
if sys.platform == "win32":
    os.startfile(reviews_filename)
else:
    opener = "open" if sys.platform == "darwin" else "xdg-open"
    subprocess.call([opener, reviews_filename])



    

---
./scripts/letterboxd_saving_auth_browser.py
---
from playwright.sync_api import sync_playwright

with sync_playwright() as p:
    browser = p.chromium.launch(headless=False)
    context = browser.new_context(user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    page = context.new_page()
    page.goto("https://letterboxd.com/")
    
    input("Manually log in and press Enter to continue...")

    context.storage_state(path="auth.json")
    print("Auth state saved to auth.json")
    browser.close()

---
./scripts/letterboxd_using_auth.py
---
from playwright.sync_api import sync_playwright

with sync_playwright() as p:
    browser = p.chromium.launch(headless=False)
    context = browser.new_context(storage_state="auth.json")
    page = context.new_page()
    page.goto("https://letterboxd.com/")
    print("Logged in successfully with saved session")
    page.locator(".navitem > .replace").click()
    page.get_by_label("Search:").fill("In Bruges")
    page.get_by_role("button", name="Search").click()
    page.get_by_role("link", name="In Bruges", exact=True).first.click()
    browser.close()


---
./scripts/organize_table_of_downloads_folder.py
---
#!/usr/bin/env -S uv run --script
# /// script
# requires-python = ">=3.8"
# dependencies = [
#     "pandas>=2.0.0",
#     "matplotlib>=3.7.0",
#     "seaborn>=0.12.0",
#     "plotly>=5.17.0",
#     "rich>=13.0.0",
#     "numpy>=1.24.0"
# ]
# ///

import os
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime
from pathlib import Path
from rich.console import Console
from rich.table import Table
from rich.progress import Progress
import math
import numpy as np

def get_file_size_mb(size_bytes):
    """Convert bytes to MB"""
    return round(size_bytes / (1024 * 1024), 2)

def get_file_info(root_path):
    """Scan all files in the directory tree and collect information"""
    files_data = []
    console = Console()
    
    with Progress() as progress:
        task = progress.add_task("[cyan]Scanning files...", total=None)
        
        for root, dirs, files in os.walk(root_path):
            for file in files:
                # Skip hidden files and system files
                if file.startswith('.'):
                    continue
                    
                file_path = os.path.join(root, file)
                try:
                    stat_info = os.stat(file_path)
                    
                    # Get relative folder path
                    rel_folder = os.path.relpath(root, root_path)
                    if rel_folder == '.':
                        rel_folder = 'Root'
                    
                    # Get file extension
                    ext = os.path.splitext(file)[1].lower()
                    if not ext:
                        ext = 'No Extension'
                    
                    # File size in MB
                    size_mb = get_file_size_mb(stat_info.st_size)
                    
                    # Last modified date
                    mod_time = datetime.fromtimestamp(stat_info.st_mtime)
                    
                    files_data.append({
                        'filename': file,
                        'folder': rel_folder,
                        'extension': ext,
                        'size_mb': size_mb,
                        'size_bytes': stat_info.st_size,
                        'modified_date': mod_time,
                        'full_path': file_path
                    })
                    
                    progress.advance(task)
                    
                except (OSError, IOError):
                    # Skip files that can't be accessed
                    continue
    
    return pd.DataFrame(files_data)

def create_summary_table(df):
    """Create a rich summary table"""
    console = Console()
    
    # Overall summary
    table = Table(title="üìÅ Downloads Folder Summary", style="cyan")
    table.add_column("Metric", style="bold blue")
    table.add_column("Value", style="green")
    
    total_files = len(df)
    total_size_gb = df['size_mb'].sum() / 1024
    avg_file_size = df['size_mb'].mean()
    largest_file = df.loc[df['size_mb'].idxmax()]
    
    table.add_row("Total Files", f"{total_files:,}")
    table.add_row("Total Size", f"{total_size_gb:.2f} GB")
    table.add_row("Average File Size", f"{avg_file_size:.2f} MB")
    table.add_row("Largest File", f"{largest_file['filename']} ({largest_file['size_mb']:.2f} MB)")
    table.add_row("Total Folders", f"{df['folder'].nunique()}")
    table.add_row("File Types", f"{df['extension'].nunique()}")
    
    console.print(table)
    console.print()

def create_folder_breakdown_table(df):
    """Create a breakdown by folder"""
    console = Console()
    
    folder_summary = df.groupby('folder').agg({
        'filename': 'count',
        'size_mb': ['sum', 'mean'],
        'extension': 'nunique'
    }).round(2)
    
    folder_summary.columns = ['File Count', 'Total Size (MB)', 'Avg Size (MB)', 'File Types']
    folder_summary = folder_summary.sort_values('Total Size (MB)', ascending=False)
    
    table = Table(title="üìÇ Breakdown by Folder", style="yellow")
    table.add_column("Folder", style="bold cyan")
    table.add_column("Files", justify="right", style="green")
    table.add_column("Total Size (MB)", justify="right", style="blue")
    table.add_column("Avg Size (MB)", justify="right", style="magenta")
    table.add_column("File Types", justify="right", style="yellow")
    
    for folder, row in folder_summary.head(20).iterrows():
        table.add_row(
            folder,
            f"{int(row['File Count']):,}",
            f"{row['Total Size (MB)']:,.2f}",
            f"{row['Avg Size (MB)']:,.2f}",
            f"{int(row['File Types'])}"
        )
    
    console.print(table)
    console.print()

def create_file_type_table(df):
    """Create a breakdown by file type"""
    console = Console()
    
    ext_summary = df.groupby('extension').agg({
        'filename': 'count',
        'size_mb': ['sum', 'mean']
    }).round(2)
    
    ext_summary.columns = ['File Count', 'Total Size (MB)', 'Avg Size (MB)']
    ext_summary = ext_summary.sort_values('File Count', ascending=False)
    
    table = Table(title="üìÑ Breakdown by File Type", style="green")
    table.add_column("Extension", style="bold blue")
    table.add_column("Files", justify="right", style="cyan")
    table.add_column("Total Size (MB)", justify="right", style="yellow")
    table.add_column("Avg Size (MB)", justify="right", style="magenta")
    
    for ext, row in ext_summary.head(15).iterrows():
        table.add_row(
            ext,
            f"{int(row['File Count']):,}",
            f"{row['Total Size (MB)']:,.2f}",
            f"{row['Avg Size (MB)']:,.2f}"
        )
    
    console.print(table)
    console.print()

def create_visualizations(df):
    """Create beautiful visualizations"""
    # Set up the plotting style
    plt.style.use('dark_background')
    fig = plt.figure(figsize=(20, 15))
    fig.patch.set_facecolor('#0a0a0a')
    
    # 1. Files by folder (top 10)
    plt.subplot(2, 3, 1)
    folder_counts = df['folder'].value_counts().head(10)
    bars = plt.bar(range(len(folder_counts)), folder_counts.values, 
                   color=plt.cm.viridis(np.linspace(0, 1, len(folder_counts))))
    plt.title('üìÅ Files by Folder (Top 10)', fontsize=14, color='white', pad=20)
    plt.ylabel('Number of Files', color='white')
    plt.xticks(range(len(folder_counts)), folder_counts.index, rotation=45, ha='right', color='white')
    plt.yticks(color='white')
    
    # 2. File size distribution by folder
    plt.subplot(2, 3, 2)
    folder_sizes = df.groupby('folder')['size_mb'].sum().sort_values(ascending=False).head(10)
    bars = plt.bar(range(len(folder_sizes)), folder_sizes.values,
                   color=plt.cm.plasma(np.linspace(0, 1, len(folder_sizes))))
    plt.title('üíæ Total Size by Folder (Top 10)', fontsize=14, color='white', pad=20)
    plt.ylabel('Size (MB)', color='white')
    plt.xticks(range(len(folder_sizes)), folder_sizes.index, rotation=45, ha='right', color='white')
    plt.yticks(color='white')
    
    # 3. File types distribution
    plt.subplot(2, 3, 3)
    ext_counts = df['extension'].value_counts().head(10)
    colors = plt.cm.Set3(np.linspace(0, 1, len(ext_counts)))
    plt.pie(ext_counts.values, labels=ext_counts.index, autopct='%1.1f%%', 
            colors=colors, startangle=90)
    plt.title('üìÑ File Types Distribution', fontsize=14, color='white', pad=20)
    
    # 4. File size histogram
    plt.subplot(2, 3, 4)
    # Filter out very large files for better visualization
    size_data = df[df['size_mb'] < df['size_mb'].quantile(0.95)]['size_mb']
    plt.hist(size_data, bins=50, color='skyblue', alpha=0.7, edgecolor='white')
    plt.title('üìä File Size Distribution', fontsize=14, color='white', pad=20)
    plt.xlabel('Size (MB)', color='white')
    plt.ylabel('Frequency', color='white')
    plt.xticks(color='white')
    plt.yticks(color='white')
    
    # 5. Files over time (by modification date)
    plt.subplot(2, 3, 5)
    df['month_year'] = df['modified_date'].dt.to_period('M')
    monthly_counts = df['month_year'].value_counts().sort_index().tail(12)
    plt.plot(range(len(monthly_counts)), monthly_counts.values, 
             marker='o', linewidth=2, markersize=6, color='orange')
    plt.title('üìÖ Files Modified Over Time (Last 12 Months)', fontsize=14, color='white', pad=20)
    plt.ylabel('Number of Files', color='white')
    plt.xticks(range(len(monthly_counts)), [str(x) for x in monthly_counts.index], 
               rotation=45, ha='right', color='white')
    plt.yticks(color='white')
    plt.grid(True, alpha=0.3)
    
    # 6. Largest files
    plt.subplot(2, 3, 6)
    largest_files = df.nlargest(10, 'size_mb')
    bars = plt.barh(range(len(largest_files)), largest_files['size_mb'].values,
                    color=plt.cm.Reds(np.linspace(0.3, 1, len(largest_files))))
    plt.title('üéØ Largest Files', fontsize=14, color='white', pad=20)
    plt.xlabel('Size (MB)', color='white')
    plt.yticks(range(len(largest_files)), 
               [f[:30] + '...' if len(f) > 30 else f for f in largest_files['filename']], 
               color='white')
    plt.xticks(color='white')
    
    plt.tight_layout()
    plt.savefig('downloads_analysis.png', dpi=300, bbox_inches='tight', 
                facecolor='#0a0a0a', edgecolor='none')
    plt.show()

def save_detailed_csv(df):
    """Save detailed file list to CSV"""
    # Create a clean version for CSV
    csv_df = df.copy()
    csv_df['size_gb'] = csv_df['size_mb'] / 1024
    csv_df = csv_df.sort_values(['folder', 'size_mb'], ascending=[True, False])
    
    # Select relevant columns
    csv_df = csv_df[['folder', 'filename', 'extension', 'size_mb', 'size_gb', 
                     'modified_date', 'full_path']]
    
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    filename = f'downloads_file_inventory_{timestamp}.csv'
    csv_df.to_csv(filename, index=False)
    
    console = Console()
    console.print(f"\nüíæ Detailed file inventory saved to: [bold green]{filename}[/bold green]")

def main():
    downloads_path = "/Users/greatmaster/Downloads"
    
    console = Console()
    console.print("[bold cyan]üîç Analyzing Downloads Folder...[/bold cyan]\n")
    
    # Check if path exists
    if not os.path.exists(downloads_path):
        console.print(f"[bold red]‚ùå Path not found: {downloads_path}[/bold red]")
        return
    
    # Scan files
    df = get_file_info(downloads_path)
    
    if df.empty:
        console.print("[bold yellow]‚ö†Ô∏è  No files found![/bold yellow]")
        return
    
    # Display summary tables
    create_summary_table(df)
    create_folder_breakdown_table(df)
    create_file_type_table(df)
    
    # Create visualizations
    console.print("[bold green]üìä Creating visualizations...[/bold green]")
    create_visualizations(df)
    
    # Save detailed CSV
    save_detailed_csv(df)
    
    console.print("\n[bold green]‚ú® Analysis complete! Check the generated files:[/bold green]")
    console.print("üìä downloads_analysis.png - Visual charts")
    console.print("üìã downloads_file_inventory_*.csv - Detailed file list")

if __name__ == "__main__":
    main()

---
./scripts/pdf_generator.py
---
# Model: Claude-4
# Prompt
# "Generate a Python script that creates a self-contained PDF document using reportlab. The script should include:
# - A title and a subtitle with different font sizes and styles.
# - A paragraph of placeholder text.
# - A table with sample data (3 columns, 5 rows).
# - A simple bar chart generated within the script.
# - A logo or shape (such as a rectangle or circle) drawn directly on the PDF.  
# The script should not require any external data sources and should generate a complete, properly formatted PDF file when executed."

# save this script in my desktop folder

# /// script
# dependencies = [
#   "reportlab",
# ]
# ///

from reportlab.lib.pagesizes import letter
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.units import inch
from reportlab.lib import colors
from reportlab.graphics.shapes import Drawing, Rect, Circle
from reportlab.graphics.charts.barcharts import VerticalBarChart
from reportlab.graphics import renderPDF
from reportlab.lib.enums import TA_CENTER, TA_LEFT
import os

def create_pdf():
    # Get desktop path
    desktop_path = os.path.expanduser("~/Desktop")
    filename = os.path.join(desktop_path, "sample_report.pdf")
    
    # Create PDF document
    doc = SimpleDocTemplate(filename, pagesize=letter, topMargin=0.5*inch)
    story = []
    
    # Get styles
    styles = getSampleStyleSheet()
    
    # Custom title style
    title_style = ParagraphStyle(
        'CustomTitle',
        parent=styles['Heading1'],
        fontSize=24,
        spaceAfter=30,
        alignment=TA_CENTER,
        textColor=colors.darkblue
    )
    
    # Custom subtitle style
    subtitle_style = ParagraphStyle(
        'CustomSubtitle',
        parent=styles['Heading2'],
        fontSize=16,
        spaceAfter=20,
        alignment=TA_CENTER,
        textColor=colors.grey
    )
    
    # Add title
    title = Paragraph("Company Annual Report", title_style)
    story.append(title)
    
    # Add subtitle
    subtitle = Paragraph("Financial Performance Overview 2024", subtitle_style)
    story.append(subtitle)
    
    # Add spacer
    story.append(Spacer(1, 20))
    
    # Add paragraph
    paragraph_text = """
    This comprehensive report presents our company's outstanding performance throughout 2024. 
    Our strategic initiatives have resulted in significant growth across all key metrics, 
    demonstrating our commitment to excellence and innovation. The following data showcases 
    our achievements in revenue, customer satisfaction, and market expansion. We continue 
    to build on our strong foundation while exploring new opportunities for sustainable growth.
    """
    para = Paragraph(paragraph_text, styles['Normal'])
    story.append(para)
    story.append(Spacer(1, 20))
    
    # Create table data
    table_data = [
        ['Quarter', 'Revenue ($M)', 'Growth (%)'],
        ['Q1 2024', '125.4', '12.3'],
        ['Q2 2024', '142.8', '18.7'],
        ['Q3 2024', '156.2', '15.2'],
        ['Q4 2024', '178.9', '22.1']
    ]
    
    # Create table
    table = Table(table_data, colWidths=[1.5*inch, 1.5*inch, 1.5*inch])
    table.setStyle(TableStyle([
        ('BACKGROUND', (0, 0), (-1, 0), colors.darkblue),
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
        ('FONTSIZE', (0, 0), (-1, 0), 12),
        ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
        ('BACKGROUND', (0, 1), (-1, -1), colors.lightgrey),
        ('GRID', (0, 0), (-1, -1), 1, colors.black)
    ]))
    
    story.append(table)
    story.append(Spacer(1, 30))
    
    # Create bar chart
    drawing = Drawing(400, 200)
    
    # Add logo shapes
    logo_rect = Rect(10, 150, 60, 30, fillColor=colors.darkblue, strokeColor=colors.black)
    logo_circle = Circle(90, 165, 15, fillColor=colors.orange, strokeColor=colors.black)
    drawing.add(logo_rect)
    drawing.add(logo_circle)
    
    # Create bar chart
    chart = VerticalBarChart()
    chart.x = 120
    chart.y = 50
    chart.height = 125
    chart.width = 250
    chart.data = [[125.4, 142.8, 156.2, 178.9]]
    chart.categoryAxis.labels.boxAnchor = 'ne'
    chart.categoryAxis.labels.dx = 8
    chart.categoryAxis.labels.dy = -2
    chart.categoryAxis.labels.angle = 30
    chart.categoryAxis.categoryNames = ['Q1', 'Q2', 'Q3', 'Q4']
    chart.valueAxis.valueMin = 0
    chart.valueAxis.valueMax = 200
    chart.bars[0].fillColor = colors.darkblue
    chart.bars[0].strokeColor = colors.black
    
    drawing.add(chart)
    story.append(drawing)
    
    # Build PDF
    doc.build(story)
    print(f"PDF generated successfully: {filename}")

if __name__ == "__main__":
    create_pdf()


---
./scripts/ppt_financial.py
---
#!/usr/bin/env -S uv run --script
# /// script
# requires-python = ">=3.12"
# dependencies = [
#     "pandas",
#     "matplotlib",
#     "seaborn",
#     "python-pptx",
#     "openpyxl"
# ]
# ///

import os
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from matplotlib.dates import DateFormatter
from pptx import Presentation
from pptx.util import Inches
from datetime import datetime
import warnings

warnings.filterwarnings("ignore")

input_folder = "input"
charts_folder = os.path.join(input_folder, "charts")
os.makedirs(charts_folder, exist_ok=True)

prs = Presentation()
title_slide_layout = prs.slide_layouts[5]

excel_files = [f for f in os.listdir(input_folder) if f.endswith(".xlsx")]

for file in excel_files:
    try:
        filepath = os.path.join(input_folder, file)
        df = pd.read_excel(filepath, sheet_name=0, usecols="A:Q")

        df["Date"] = pd.to_datetime(df["Date"], errors="coerce")
        df.dropna(subset=["Date", "Stock Symbol", "Close Price", "Moving Average (50-day)",
                          "RSI (Relative Strength Index)", "MACD", "Signal Line"], inplace=True)
        df.sort_values("Date", inplace=True)

        grouped = df.groupby("Stock Symbol")

        for symbol, group in grouped:
            if group.empty:
                continue

            fig, ax1 = plt.subplots(figsize=(10, 6))
            sns.lineplot(data=group, x="Date", y="Close Price", ax=ax1, label="Close Price")
            sns.lineplot(data=group, x="Date", y="Moving Average (50-day)", ax=ax1, label="50-day MA")
            sns.lineplot(data=group, x="Date", y="RSI (Relative Strength Index)", ax=ax1, label="RSI")

            ax1.set_title(f"{symbol} - {os.path.splitext(file)[0]}", fontsize=14)
            ax1.set_xlabel("Date")
            ax1.set_ylabel("Price / RSI")
            ax1.legend(loc="upper left")
            ax1.xaxis.set_major_formatter(DateFormatter("%Y-%m-%d"))
            plt.xticks(rotation=45)

            ax2 = ax1.twinx()
            sns.lineplot(data=group, x="Date", y="MACD", ax=ax2, label="MACD", linestyle="--")
            sns.lineplot(data=group, x="Date", y="Signal Line", ax=ax2, label="Signal Line", linestyle="--")
            ax2.set_ylabel("MACD / Signal")

            chart_filename = f"{symbol}_{os.path.splitext(file)[0]}.png"
            chart_path = os.path.join(charts_folder, chart_filename)
            plt.tight_layout()
            plt.savefig(chart_path)
            plt.close()

            slide = prs.slides.add_slide(title_slide_layout)
            slide.shapes.title.text = f"{os.path.splitext(file)[0]} - {symbol}"
            slide.shapes.add_picture(chart_path, Inches(1), Inches(1.5), width=Inches(8.5))

    except Exception as e:
        print(f"Error processing {file}: {e}")

output_path = os.path.join(".", "stock_analysis.pptx")
prs.save(output_path)
print(f"Presentation saved to {output_path}")

---
./scripts/sample_script_dashboard.py
---
#!/usr/bin/env -S uv run --script
# /// script
# requires-python = ">=3.8"
# dependencies = [
#     "requests>=2.31.0",
#     "matplotlib>=3.7.0",
#     "pillow>=10.0.0",
#     "numpy>=1.24.0"
# ]
# ///

import requests
import matplotlib.pyplot as plt
from PIL import Image
from io import BytesIO
import numpy as np
from datetime import datetime, timedelta
import math

def fetch_nasa_images(days=9):
    """Fetch multiple NASA APOD images"""
    images = []
    base_url = "https://api.nasa.gov/planetary/apod"
    
    for i in range(days):
        # Get images from the last 'days' days
        date = (datetime.now() - timedelta(days=i)).strftime('%Y-%m-%d')
        
        try:
            response = requests.get(
                base_url,
                params={'api_key': 'DEMO_KEY', 'date': date},
                timeout=10
            )
            
            if response.status_code == 200:
                data = response.json()
                
                # Only process if it's an image (not video)
                if data.get('media_type') == 'image':
                    img_response = requests.get(data['url'], timeout=15)
                    if img_response.status_code == 200:
                        img = Image.open(BytesIO(img_response.content))
                        # Convert to RGB if necessary
                        if img.mode != 'RGB':
                            img = img.convert('RGB')
                        
                        images.append({
                            'image': img,
                            'title': data.get('title', 'Unknown'),
                            'date': data.get('date', date),
                            'explanation': data.get('explanation', '')[:100] + '...'
                        })
                        print(f"‚úì Fetched: {data.get('title', 'Unknown')}")
                    else:
                        print(f"‚úó Failed to download image for {date}")
                else:
                    print(f"‚ö† Skipped video content for {date}")
            else:
                print(f"‚úó API request failed for {date}")
                
        except Exception as e:
            print(f"‚úó Error fetching {date}: {str(e)}")
    
    return images

def create_gorgeous_grid(images):
    """Create a beautiful grid of NASA images"""
    if not images:
        print("No images to display!")
        return
    
    # Calculate grid dimensions
    n_images = len(images)
    n_cols = math.ceil(math.sqrt(n_images))
    n_rows = math.ceil(n_images / n_cols)
    
    # Create figure with dark background
    fig = plt.figure(figsize=(20, 16))
    fig.patch.set_facecolor('#0a0a0a')
    
    # Add main title
    fig.suptitle(
        'üåå NASA Astronomy Pictures of the Day üåå', 
        fontsize=28, 
        color='white', 
        fontweight='bold',
        y=0.95
    )
    
    for idx, img_data in enumerate(images):
        # Create subplot
        ax = plt.subplot(n_rows, n_cols, idx + 1)
        ax.set_facecolor('#1a1a1a')
        
        # Display image
        ax.imshow(np.array(img_data['image']))
        
        # Remove axes
        ax.set_xticks([])
        ax.set_yticks([])
        
        # Add beautiful border
        for spine in ax.spines.values():
            spine.set_edgecolor('#444444')
            spine.set_linewidth(2)
        
        # Add title and date
        ax.set_title(
            f"{img_data['title']}\n{img_data['date']}", 
            fontsize=11, 
            color='white',
            fontweight='bold',
            pad=10,
            wrap=True
        )
        
        # Add subtle explanation text below image
        ax.text(
            0.5, -0.15, 
            img_data['explanation'], 
            transform=ax.transAxes, 
            fontsize=8, 
            color='#cccccc',
            ha='center',
            va='top',
            wrap=True
        )
    
    # Remove empty subplots
    for idx in range(n_images, n_rows * n_cols):
        fig.delaxes(fig.axes[idx])
    
    # Adjust layout
    plt.tight_layout(rect=[0, 0.03, 1, 0.92])
    
    # Add footer
    fig.text(
        0.5, 0.02, 
        'üöÄ Data from NASA API | Created with Python & Matplotlib üöÄ', 
        ha='center', 
        fontsize=12, 
        color='#888888'
    )
    
    # Show the plot
    plt.show()
    
    # Save with timestamp
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    filename = f'nasa_apod_grid_{timestamp}.png'
    plt.savefig(
        filename, 
        dpi=300, 
        bbox_inches='tight', 
        facecolor='#0a0a0a',
        edgecolor='none'
    )
    print(f"\nüé® Gorgeous grid saved as: {filename}")

def main():
    print("üåü Fetching beautiful images from NASA...")
    print("=" * 50)
    
    # Fetch images
    images = fetch_nasa_images(days=12)  # Try to get 12 images
    
    if images:
        print(f"\nüéâ Successfully fetched {len(images)} images!")
        print("üé® Creating gorgeous grid...")
        create_gorgeous_grid(images)
    else:
        print("üòû No images could be fetched. Please check your internet connection.")

if __name__ == "__main__":
    main()

---
./scripts/stock_analysis_plot1.py
---
# /// script
# python = ">=3.8"
# dependencies = [
#   "pandas",
#   "matplotlib",
# ]
# ///

import pandas as pd
import matplotlib.pyplot as plt

def plot_stock_trend(csv_path: str, stock_symbol: str, output_path: str = "stock_trend_plot.png"):
    # Load data
    df = pd.read_csv(csv_path)
    df['Date'] = pd.to_datetime(df['Date'])

    # Filter by stock symbol
    stock_df = df[df['Stock Symbol'] == stock_symbol]

    # Plot
    plt.figure(figsize=(12, 6))
    plt.plot(stock_df['Date'], stock_df['Close Price'], label='Close Price')
    plt.plot(stock_df['Date'], stock_df['Moving Average (50-day)'], label='50-day MA', linestyle='--')
    plt.title(f'{stock_symbol} Stock Price Over Time')
    plt.xlabel('Date')
    plt.ylabel('Price (USD)')
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.xticks(rotation=45)

    # Save to file
    plt.savefig(output_path)
    print(f"‚úÖ Plot saved to {output_path}")

if __name__ == "__main__":
    # Replace this with your actual file path if needed
    csv_file = "/Users/greatmaster/Desktop/projects/oreilly-live-trainings/oreilly-python-course/notebooks/assets/stock-trading-data.csv"
    stock = "AAPL"
    plot_stock_trend(csv_file, stock)

---
./scripts/structured-outputs-with-openai-pydantic.py
---
from pydantic import BaseModel, Field
from openai import OpenAI

receipt_data = """
OTOVO, UNIPESSOAL, LDA. RUA VISCONDE DE SEABRA, 3 - 1o DTO 516920219 1700-421 LISBOA
OTOVO, UNIPESSOAL, LDA.
RUA VISCONDE DE SEABRA, 3 - 1o DTO 1700-421 LISBOA
LISBOA
LUCAS BARBOSA NICOLOSI SOARES 0022
AI SOFTWARE ENGINEER 12074046801
292804768
AGEAS 0010.10.315407
516920219 Original DOurpiglicnadlo
LISBOA
Recibo de Vencimentos
Recibo de Vencimentos Per√≠odo Dezembro
Data Fecho 31/12/2023 Vencimento 3.339,29
Per√≠odo Data Fecho Vencimento Venc. / Hora N. Dias M√™s:
Faltas Alim.
C√≥d.
R01 R06 R13 D01 D02 D05
Dezembro 31/12/2023
3.339,29 19,27 18.00
Nome
N.o Mecan. Categoria
N.o Benef.
N.o Contrib. Departamento Seguro
LUCAS BARBOSA NICOLOSI SOARES 0022
AI SOFTWARE ENGINEER 12074046801
292804768
AGEAS 0010.10.315407
Reten√ß√£o IRS
SDD IRS Retido Total Remun.
Venc. / Hora N. Dias M√™s:
19,27 18.00
Nome
N.o Mecan. Categoria
N.o Benef.
N.o Contrib. Departamento Seguro
Turno Data
12-2023 12-2023 12-2023 12-2023 12-2023 12-2023
CDD
SDH
Faltas
Alim. Turno CDH
Reten√ß√£o IRS
IRS Retido
CDH
Descri√ß√£o Remunera√ß√µes Descontos
SDH
SDD
Total Remun.
18.059,57
Descontos
432,14 1.146,00 144,00
CDD
Descri√ß√£o Remunera√ß√µes
Vencimento 3.339,29 IHT 589,29
4.825,00 18.059,57
4.825,00
Vencimento 3.339,29 IHT 589,29
C√≥d. Data
R01 12-2023 R06 12-2023 R13 12-2023 D01 12-2023 D02 12-2023 D05 12-2023
Subs√≠dio Alimenta√ß√£o Cart√£o Seguran√ßa Social
IRS (Venc. 29,18%) (29,18%) Desconto Subsidio Alim. Cart√£o
144,00
Subs√≠dio Alimenta√ß√£o Cart√£o Seguran√ßa Social
IRS (Venc. 29,18%) (29,18%) Desconto Subsidio Alim. Cart√£o
144,00
432,14 1.146,00 144,00
Formas de Pagamento: % Remunera√ß√£o
100,00
Forma de Pagamento Moeda
Formas de Pagamento: % Remunera√ß√£o
100,00
Forma de Pagamento
Transfer√™ncia
Moeda
Total
4.072,58 1.722,14 Total Pago ( EUR ) 2.350,44
Total
4.072,58 Total Pago ( EUR )
1.722,14 2.350,44
Declaro que recebi a quantia constante neste recibo,
Obs.
Declaro que recebi a quantia constante neste recibo,
Transfer√™ncia EUR
EUR
"""

class ReceiptData(BaseModel):
    company_name: str = Field(description="The name of the company.")
    date_of_closure: str = Field(description="The date of closure.")
    amount_paid: float = Field(description="The amount paid ('Total Pago') after taxes.")

client = OpenAI()

completion = client.beta.chat.completions.parse(
    model="gpt-4o-mini",
    messages=[
        {"role": "system", "content": """
         You are an extraction engine for receipt data.
         Users will upload the contents of their receipts and you will extract
         the following fields:
         - Company name
         - Date of closure
         - Amount paid
         """},
        {"role": "user", "content": receipt_data},
    ],
    response_format=ReceiptData,
)

message = completion.choices[0].message
if message.parsed:
    print(message.parsed)
else:
    print(message.refusal)

---
./scripts/structured_output_with_pydantic.py
---
from pydantic import BaseModel, Field
from openai import OpenAI

class ReceiptData(BaseModel):
    company_name: str = Field(description="The name of the company.")
    date_of_closure: str = Field(description="The date of closure.")
    amount_paid: float = Field(description="The amount paid ('Total Pago') after taxes.")

client = OpenAI()

with open("./invoice-data-sample.txt", "r") as f:
    receipt_data = f.read()

completion = client.beta.chat.completions.parse(
    model="gpt-4o-mini",
    messages=[
        {"role": "system", "content": """
         You are an extraction engine for receipt data.
         Users will upload the contents of their receipts and you will extract
         the following fields:
         - Company name
         - Date of closure
         - Amount paid
         """},
        {"role": "user", "content": receipt_data},
    ],
    response_format=ReceiptData,
)

message = completion.choices[0].message
if message.parsed:
    print(message.parsed)
else:
    print(message.refusal)

---
./scripts/weather_utils.py
---
# weather_utils.py

def celsius_to_fahrenheit(celsius):
    """Convert Celsius to Fahrenheit"""
    return (celsius * 9/5) + 32

def calculate_heat_index(temperature, humidity):
    """Calculate heat index based on temperature (¬∞F) and humidity (%)"""
    if temperature < 80:
        return temperature
    
    heat_index = -42.379 + 2.04901523 * temperature + 10.14333127 * humidity
    heat_index -= 0.22475541 * temperature * humidity
    heat_index -= 6.83783e-3 * temperature**2
    heat_index -= 5.481717e-2 * humidity**2
    heat_index += 1.22874e-3 * temperature**2 * humidity
    heat_index += 8.5282e-4 * temperature * humidity**2
    heat_index -= 1.99e-6 * temperature**2 * humidity**2
    
    return round(heat_index, 2)

---
./notebooks/README.md
---
# Course Notebooks

This directory contains all the Jupyter notebooks for the O'Reilly Live Training course organized into logical sections.

## Structure

### üìö 01-python-fundamentals/
Core Python concepts and syntax:
- **01-data-types-and-operators.ipynb** - Numbers, strings, basic operations
- **02-variables.ipynb** - Variable assignment and naming
- **03-functions.ipynb** - Creating and using functions
- **04-lists-and-loops.ipynb** - Lists and iteration
- **05-dictionaries.ipynb** - Key-value data structures
- **06-comparators.ipynb** - Comparison operators
- **07-conditionals.ipynb** - If/else statements and branching
- **08-working-with-files.ipynb** - File I/O operations
- **09-working-with-csv.ipynb** - Tabular data handling
- **10-packages-and-apis.ipynb** - Libraries and API basics

### ü§ñ 02-ai-apis/
Working with AI services:
- **01-ai-apis-overview.ipynb** - Introduction to AI APIs
- **02-ai-tools-hands-on.ipynb** - Practical AI tool usage

### ‚öôÔ∏è 03-automation-projects/
Real-world automation projects:
- **01-file-management-automation.ipynb** - Organizing and managing files
- **02-data-extraction-with-ai.ipynb** - Extracting data using LLMs
- **03-web-data-extraction.ipynb** - Web scraping and data collection
- **04-data-analysis-automation.ipynb** - Automated data analysis
- **05-presentation-automation.ipynb** - Generating slides automatically
- **06-browser-automation.ipynb** - Controlling web browsers
- **07-workflow-automation.ipynb** - Building automation workflows
- **08-email-assistant.ipynb** - Email automation and processing
- **09-ai-scheduler-agent.ipynb** - Intelligent scheduling systems
- **10-receipt-data-extraction.ipynb** - Processing receipts and invoices
- **11-custom-automation-scripts.ipynb** - Building your own scripts
- **12-practical-examples.ipynb** - Additional real-world examples

### üìù 04-exercises/
Practice problems and solutions:
- **01-data-types-and-variables.ipynb** - Basic Python practice
- **02-functions.ipynb** - Function creation exercises
- **03-conditionals-and-files.ipynb** - Logic and file handling
- **04-day1-recap.ipynb** - Summary and review

### üìÅ assets/
Supporting files, images, sample data, and resources used throughout the course.

## Getting Started

1. Navigate to `01-python-fundamentals/` if you're new to Python
2. Work through notebooks in numerical order within each section
3. Use `04-exercises/` to practice what you've learned
4. Move to `02-ai-apis/` and `03-automation-projects/` for advanced topics

## Tips

- Each notebook is self-contained but builds on previous concepts
- Sample data and resources are in the `assets/` folder
- Run notebooks in order for the best learning experience


---
./notebooks/04-exercises/01-data-types-and-variables.ipynb
---
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Identify the Data Type\n",
    "Write a Python script that defines the following values and prints their data types using type():\n",
    "\n",
    "x = 42\n",
    "y = 3.14\n",
    "z = \"Hello, Python!\"\n",
    "w = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n",
      "<class 'float'>\n",
      "<class 'str'>\n",
      "<class 'bool'>\n"
     ]
    }
   ],
   "source": [
    "x = 42\n",
    "y = 3.14\n",
    "z = \"Hello, Python!\"\n",
    "w = True\n",
    "\n",
    "print(type(x))\n",
    "print(type(y))\n",
    "print(type(z))\n",
    "print(type(w))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-automate-tasks",
   "language": "python",
   "name": "oreilly-automate-tasks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}


---
./notebooks/04-exercises/02-functions.ipynb
---
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CB question: 'can we define optional parameters?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "5\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "def some_function_with_parameters(a=1,b=5,c=10):\n",
    "    print(a)\n",
    "    print(b)\n",
    "    print(c)\n",
    "\n",
    "some_function_with_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KG question: 'how useful is random funtcion?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.136078845680776"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5529991975006426"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.random()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`round()` built in function in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.333"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(1.3334567, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.33"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(1.3334567, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.33346"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(1.3334567, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SP question: 'do we need to define a return type for a function?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! Lucas'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def write_something(name) -> str:\n",
    "    return f\"Hello! {name}\"\n",
    "\n",
    "\n",
    "\n",
    "write_something(\"Lucas\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! 10'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_something()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! [1, 2, 3]'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_something([1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PP & PJ question: 'I think he was asking the same thing that I asked before: \"some programming languages have the concept of passing arguments/parameters by Value or by Reference, does this also exist in Python?\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "variable = 10\n",
    "\n",
    "print(variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prints_number_sum(number):\n",
    "    print(number + number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "prints_number_sum(variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "prints_number_sum(number=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "prints_number_sum(number=variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PP & PJ updated question: 'Not exactly, it was something related with this \"When you pass an argument by reference, you pass a pointer to the value in memory. The function operates on the argument. When a function changes the value of an argument passed by reference, the original value changes. When you pass an argument by value, you pass a copy of the value in memory.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "variable = 10\n",
    "\n",
    "print(variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "def change_variable(variable1):\n",
    "    \n",
    "    variable1 = variable1 + 10\n",
    "    \n",
    "    return variable1\n",
    "\n",
    "variable = 20\n",
    "change_variable(variable)\n",
    "print(variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "def modify_list(lst):\n",
    "    lst.append(4)  # Modifies the original list\n",
    "\n",
    "my_list = [1, 2, 3]\n",
    "modify_list(my_list)\n",
    "print(my_list)  # Output: [1, 2, 3, 4] (modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-automate-tasks",
   "language": "python",
   "name": "oreilly-automate-tasks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}


---
./notebooks/04-exercises/03-conditionals-and-files.ipynb
---
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SV question: 'if and if -> use case explain it one more time.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lucas is older than 30!\n"
     ]
    }
   ],
   "source": [
    "name = \"Lucas\"\n",
    "\n",
    "age = 33\n",
    "#      True      AND  TRUE\n",
    "if name==\"Lucas\" and age>30:\n",
    "    # This gets executed!\n",
    "    print(\"Lucas is older than 30!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PP question: 'how do we import the necessary modules when we are using Google Collab for the Notebooks?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import anthropic\n",
    "import ollama\n",
    "import json\n",
    "\n",
    "def ask_ai(prompt, model_name=\"gpt-4o-mini\"):\n",
    "    \"\"\"\n",
    "    Send prompt to an LLM and get output text back.    \n",
    "    \"\"\"\n",
    "    if \"claude\" in model_name:\n",
    "        client = anthropic.Anthropic()\n",
    "\n",
    "        # Send a message to the Claude AI\n",
    "        response = client.messages.create(\n",
    "            model=model_name,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\", \"content\": prompt\n",
    "                }\n",
    "                ],\n",
    "            max_tokens=4000,\n",
    "        )\n",
    "        output = response.content[0].text\n",
    "        return output        \n",
    "    else:\n",
    "        client = OpenAI()\n",
    "        response = client.chat.completions.create(\n",
    "            model=model_name,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are a helpful assistant.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                }\n",
    "            ],\n",
    "        )\n",
    "        output = response.choices[0].message.content\n",
    "        return output\n",
    "\n",
    "\n",
    "def ask_local_ai(prompt, model_name=\"llama3.2\", structured=False):\n",
    "    \"\"\"\n",
    "    Send prompt to a local LLM and get output text back.\n",
    "    \"\"\"\n",
    "    client = ollama.Client()\n",
    "    if structured:\n",
    "        response = client.chat(model=model_name, \n",
    "                               messages=\n",
    "                               [\n",
    "                                   {\"role\": \"user\", \"content\": prompt}\n",
    "                                ],\n",
    "                               format='json')\n",
    "        return response.message.content\n",
    "    else:\n",
    "        response = client.chat(model=model_name, \n",
    "                               messages=\n",
    "                               [\n",
    "                                   {\"role\": \"user\", \"content\": prompt}\n",
    "                                ])\n",
    "        return response.message.content\n",
    "\n",
    "\n",
    "def parse_dates_list(output_str):\n",
    "    \"\"\"\n",
    "    Parse the string output containing a Python list of dates into an actual Python list.\n",
    "    \n",
    "    Args:\n",
    "        output_str (str): String containing a Python list representation of dates\n",
    "        \n",
    "    Returns:\n",
    "        list: List of date strings\n",
    "    \"\"\"\n",
    "    # Remove markdown code block formatting if present\n",
    "    output_str = output_str.replace('```python', '').replace('```', '').strip()\n",
    "    \n",
    "    # Safely evaluate the string as a Python expression\n",
    "    dates_list = eval(output_str)\n",
    "    \n",
    "    return dates_list\n",
    "\n",
    "def parse_json_output(json_str):\n",
    "    \"\"\"\n",
    "    This function parses the JSON output from the AI and removes the markdown code block markers if present.\n",
    "    \"\"\"\n",
    "    # Remove markdown code block markers if present\n",
    "    json_str = json_str.replace('```json', '').replace('```', '').strip()\n",
    "    \n",
    "    # Parse the JSON string into a Python dictionary\n",
    "    try:\n",
    "        return json.loads(json_str)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error: Could not parse JSON string\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CA question: 'Can you explain how to try to open a file, but if it exists create the next rev of the file?  \n",
    "the rev of a file meaning if the file name ends in _1 and it exists then write/create a filename ending _2 thanks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "file_name = \"./ca-file1.txt\"\n",
    "\n",
    "if os.path.exists(file_name):\n",
    "    file_name = file_name.replace(\"1\", \"2\")\n",
    "    with open(file_name, \"w\") as f:\n",
    "        f.write(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-automate-tasks",
   "language": "python",
   "name": "oreilly-automate-tasks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}


---
./notebooks/04-exercises/04-day1-recap.ipynb
---
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We Are in the notebooks!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THe basics in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi everyone!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hi everyone!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data types, operations, variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10 + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(\"Lucas is doing a recap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lucas will teach 10x better than yesterday\n"
     ]
    }
   ],
   "source": [
    "variable = 10\n",
    "\n",
    "variable_new = \"Lucas\"\n",
    "\n",
    "print(f\"{variable_new} will teach 10x better than yesterday\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a course about automation'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"This \" + \"is a\" + \" course about automation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 is smaller than 11!\n"
     ]
    }
   ],
   "source": [
    "a = 10\n",
    "\n",
    "if a<11:\n",
    "    print(\"10 is smaller than 11!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is not good!\n"
     ]
    }
   ],
   "source": [
    "is_good = False\n",
    "\n",
    "if is_good:\n",
    "    print(\"Is good!\")\n",
    "else:\n",
    "    print(\"Is not good!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lucas'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = [\"Lucas\", \"AS\", \"BH\", \"Patrick\", \"FG\", \"SP\"]\n",
    "\n",
    "names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lucas', 'AS']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_2_names = names[0:2]\n",
    "\n",
    "first_2_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name * 10!\n",
      "LucasLucasLucasLucasLucasLucasLucasLucasLucasLucas\n",
      "Name * 10!\n",
      "ASASASASASASASASASAS\n",
      "Name * 10!\n",
      "BHBHBHBHBHBHBHBHBHBH\n",
      "Name * 10!\n",
      "PatrickPatrickPatrickPatrickPatrickPatrickPatrickPatrickPatrickPatrick\n",
      "Name * 10!\n",
      "FGFGFGFGFGFGFGFGFGFG\n",
      "Name * 10!\n",
      "SPSPSPSPSPSPSPSPSPSP\n"
     ]
    }
   ],
   "source": [
    "for name in names:\n",
    "    print(\"Name * 10!\")\n",
    "    print(name*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['shirts', 'pants', 'socks', 'underwear', 'jacket']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "travel_gear = {\n",
    "    \"clothing\": [\"shirts\", \"pants\", \"socks\", \"underwear\", \"jacket\"],\n",
    "    \"toiletries\": [\"toothbrush\", \"toothpaste\", \"deodorant\", \"shampoo\"],\n",
    "    \"electronics\": [\"phone\", \"charger\", \"laptop\", \"power bank\"],\n",
    "    \"documents\": [\"passport\", \"tickets\", \"visa\", \"insurance\"],\n",
    "    \"accessories\": [\"sunglasses\", \"hat\", \"wallet\", \"backpack\"]\n",
    "}\n",
    "\n",
    "travel_gear[\"clothing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10 > 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10 < 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! Lucas\n",
      "Hello! BH\n",
      "Hello! SP\n",
      "Hello! AS\n",
      "Hello! FG\n"
     ]
    }
   ],
   "source": [
    "def greetings_folks(names):\n",
    "    for name in names:\n",
    "        print(f\"Hello! {name}\")\n",
    "\n",
    "greetings_folks([\"Lucas\", \"BH\", \"SP\", \"AS\", \"FG\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://arxiv.org/pdf/2412.14161\n",
      "\n",
      "The paper titled \"TheAgent Company: Benchmarking LLM Agents on Consequential Real World Tasks\" introduces a new benchmark, TheAgentCompany, aimed at evaluating the efficacy of large language model (LLM)-powered AI agents in completing real-world professional tasks in a simulated software company environment. The research is conducted by a collaborative team, mainly from Carnegie Mellon University and other institutions, and emphasizes the growing presence of AI in work settings.\n",
      "\n",
      "### Key Points from the Paper:\n",
      "\n",
      "1. **Motivation**:\n",
      "   - The rapid advancements in LLMs are prompting questions about AI's potential to automate or assist in various work-related tasks.\n",
      "   - Understanding AI agents‚Äô capabilities is crucial for businesses considering AI integration and for policymakers assessing AI‚Äôs impact on employment.\n",
      "\n",
      "2. **Benchmark Overview**:\n",
      "   - TheAgentCompany simulates a software company environment with 175 diverse professional tasks spanning categories like software engineering, project management, and finance.\n",
      "   - The benchmark allows agents to interact through web browsing, coding, and colleague communication, providing a realistic testing framework.\n",
      "\n",
      "3. **Performance Findings**:\n",
      "   - Experiments conducted with several LLMs, including closed (like OpenAI's GPT-4o and Claude) and open-weight models (like Llama), reveal that the top-performing model, Claude-3.5-Sonnet, achieved 24% task completion autonomously, with a score of 34.4% when accounting for partial completions.\n",
      "   - Despite these advancements, LLM agents struggle significantly with longer, more complex tasks, especially those requiring social interaction and navigation of intricate user interfaces.\n",
      "\n",
      "4. **Framework and Design**:\n",
      "   - TheAgentCompany provides a self-hosted and reproducible environment utilizing open-source software.\n",
      "   - Tasks are structured into parts with defined checkpoints, allowing agents to receive partial credit for incomplete tasks.\n",
      "   - Evaluators for tasks are tailored to assess not just the success of task completion but also the quality of interactions with simulated colleagues.\n",
      "\n",
      "5. **Interaction and Collaboration**:\n",
      "   - A significant component of the benchmark involves the ability of agents to communicate effectively with simulated colleagues within the environment, enhancing the realism and complexity of tasks.\n",
      "\n",
      "6. **Future Directions**:\n",
      "   - The paper suggests that while TheAgentCompany provides a foundational step for understanding LLM capabilities in professional settings, there is a need to expand the tasks covered and include more creative or less straightforward tasks.\n",
      "   - Continuous improvements in LLMs are expected, highlighting their potential for increased efficiency and performance across various domains.\n",
      "\n",
      "7. **Conclusions**:\n",
      "   - The research underscores the current limitations of LLM agents in effectively automating diverse professional tasks.\n",
      "   - The results serve as a litmus test for future developments, pointing towards areas where LLM technology must improve, particularly in tasks involving human-like social interactions and complex decision-making.\n",
      "\n",
      "In summary, TheAgentCompany represents a significant effort to quantify AI agents' performance in real-world applications and to chart a course for further research in this rapidly evolving field.\n",
      "append thisnew data\n"
     ]
    }
   ],
   "source": [
    "file_path = \"./assets-resources/papers/paper1.txt\"\n",
    "\n",
    "with open(file_path, \"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if Ii want to work with tabular data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-automate-tasks",
   "language": "python",
   "name": "oreilly-automate-tasks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}


---
./notebooks/03-automation-projects/01-file-management-automation.ipynb
---
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai_tools import ask_ai\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-04-18 - $48,727.50'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def extract_invoice_data(invoice_contents):\n",
    "    extraction_prompt = f\"\"\"Extract the following information from this invoice:\n",
    "    - Date\n",
    "    - Total Amount\n",
    "    \n",
    "    Invoice contents:\n",
    "    {invoice_contents}\n",
    "    \n",
    "    Return only the date and total amount separated by dashes\n",
    "    like this:\n",
    "    \n",
    "    2024-04-15 - $18,900.00\n",
    "    2024-04-18 - $48,727.50 \n",
    "    2023-12-31 - ‚Ç¨2,350.44\n",
    "    \n",
    "    Extracted information:\n",
    "    \"\"\"\n",
    "    \n",
    "    extracted_data = ask_ai(extraction_prompt)\n",
    "    return extracted_data\n",
    "\n",
    "example_data = \"\"\"\n",
    "TECH SOLUTIONS INC.\n",
    "789 Innovation Drive\n",
    "Seattle, WA 98101\n",
    "Tax ID: 98-7654321\n",
    "\n",
    "INVOICE\n",
    "\n",
    "Bill To:                                    Invoice No: INV-2024-0103 \n",
    "Sarah Johnson                               Date: April 18, 2024\n",
    "789 Enterprise Road                         Due Date: May 18, 2024\n",
    "Chicago, IL 60601\n",
    "\n",
    "Description                     Quantity    Rate        Amount\n",
    "-----------------------------------------------------------------\n",
    "AI Model Development              120      $200.00    $24,000.00\n",
    "Data Processing Services           80      $125.00    $10,000.00\n",
    "System Integration                 40      $175.00     $7,000.00\n",
    "Hardware Configuration             1     $3,500.00     $3,500.00\n",
    "                                                    ------------\n",
    "                                           Subtotal:  $44,500.00\n",
    "                                           Tax (9.5%): $4,227.50\n",
    "                                           Total:     $48,727.50\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "extract_invoice_data(example_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's apply this to all the invoice data we have!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'file': 'invoice1.txt', 'date': '2023-12-31', 'amount': '‚Ç¨2,350.44'},\n",
       " {'file': 'invoice2.txt', 'date': '2024-04-15', 'amount': '$18,900.00'},\n",
       " {'file': 'invoice3.txt', 'date': '2024-04-18', 'amount': '$48,727.50'}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "folder_with_invoices = \"./assets-resources/fake-invoices/\"\n",
    "invoice_files = [\"invoice1.txt\", \"invoice2.txt\", \"invoice3.txt\"]\n",
    "\n",
    "invoice_data_list = []\n",
    "for invoice_file in invoice_files:\n",
    "    file_path = folder_with_invoices + invoice_file\n",
    "    with open(file_path, \"r\") as f:\n",
    "        invoice_contents = f.read()\n",
    "    \n",
    "    extracted_data = extract_invoice_data(invoice_contents)\n",
    "    date, amount = extracted_data.split(\" - \")\n",
    "    invoice_data = {\n",
    "        \"file\": invoice_file,\n",
    "        \"date\": date,\n",
    "        \"amount\": amount\n",
    "    }\n",
    "    \n",
    "    invoice_data_list.append(invoice_data)\n",
    "\n",
    "invoice_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Invoice Data Summary\n",
       "\n",
       "## invoice1.txt\n",
       "\n",
       "**Date:** 2023-12-31\n",
       "\n",
       "**Amount:** ‚Ç¨2,350.44\n",
       "\n",
       "## invoice2.txt\n",
       "\n",
       "**Date:** 2024-04-15\n",
       "\n",
       "**Amount:** $18,900.00\n",
       "\n",
       "## invoice3.txt\n",
       "\n",
       "**Date:** 2024-04-18\n",
       "\n",
       "**Amount:** $48,727.50\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the markdown content in the notebook\n",
    "markdown_content = \"# Invoice Data Summary\\n\\n\"\n",
    "for invoice in invoice_data_list:\n",
    "    markdown_content += f\"## {invoice['file']}\\n\\n\"\n",
    "    markdown_content += f\"**Date:** {invoice['date']}\\n\\n\"\n",
    "    markdown_content += f\"**Amount:** {invoice['amount']}\\n\\n\"\n",
    "\n",
    "Markdown(markdown_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Example: Document Analysis System\n",
    "\n",
    "Let's create a system that analyzes text documents and extracts key information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Analysis Report\n",
      "========================\n",
      "Filename: sample_doc.txt\n",
      "Character Count: 93\n",
      "Word Count: 16\n",
      "Line Count: 3\n",
      "Unique Words: 14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def analyze_document(filename):\n",
    "    \"\"\"\n",
    "    Analyzes a document and extracts key metrics\n",
    "    \"\"\"\n",
    "    with open(filename, \"r\") as file:\n",
    "        content = file.read()\n",
    "    \n",
    "    # Basic metrics\n",
    "    metrics = {\n",
    "        \"filename\": filename,\n",
    "        \"total_chars\": len(content),\n",
    "        \"total_words\": len(content.split()),\n",
    "        \"total_lines\": len(content.splitlines()),\n",
    "        \"unique_words\": len(set(content.lower().split()))\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def generate_report(metrics):\n",
    "    \"\"\"\n",
    "    Creates a formatted report from document metrics\n",
    "    \"\"\"\n",
    "    report = f\"\"\"Document Analysis Report\n",
    "========================\n",
    "Filename: {metrics['filename']}\n",
    "Character Count: {metrics['total_chars']}\n",
    "Word Count: {metrics['total_words']}\n",
    "Line Count: {metrics['total_lines']}\n",
    "Unique Words: {metrics['unique_words']}\n",
    "\"\"\"\n",
    "    return report\n",
    "\n",
    "# Example usage\n",
    "sample_text = \"\"\"This is a sample document.\n",
    "It contains multiple lines of text.\n",
    "We will analyze this document.\"\"\"\n",
    "\n",
    "with open(\"sample_doc.txt\", \"w\") as file:\n",
    "    file.write(sample_text)\n",
    "\n",
    "metrics = analyze_document(\"sample_doc.txt\")\n",
    "print(generate_report(metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Multiple Files\n",
    "\n",
    "Here's how to process multiple files in a directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find file: file1.txt\n",
      "Could not find file: file2.txt\n",
      "Could not find file: file3.txt\n"
     ]
    }
   ],
   "source": [
    "def batch_process_files(file_list, processor_func):\n",
    "    \"\"\"\n",
    "    Process multiple files using a given processor function\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for filename in file_list:\n",
    "        try:\n",
    "            with open(filename, \"r\") as file:\n",
    "                content = file.read()\n",
    "                result = processor_func(content)\n",
    "                results.append({\n",
    "                    \"filename\": filename,\n",
    "                    \"result\": result\n",
    "                })\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Could not find file: {filename}\")\n",
    "    return results\n",
    "\n",
    "# Example processor function\n",
    "def count_words(content):\n",
    "    return len(content.split())\n",
    "\n",
    "# Example usage\n",
    "files = [\"file1.txt\", \"file2.txt\", \"file3.txt\"]\n",
    "word_counts = batch_process_files(files, count_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Simple Log System\n",
    "\n",
    "Let's implement a basic logging system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Log contents:\n",
      "[2025-01-30 11:10:57] INFO: Application started\n",
      "[2025-01-30 11:10:57] DEBUG: Processing data...\n",
      "[2025-01-30 11:10:57] ERROR: Error in data processing\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "class SimpleLogger:\n",
    "    def __init__(self, log_file):\n",
    "        self.log_file = log_file\n",
    "    \n",
    "    def log(self, message, level=\"INFO\"):\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        log_entry = f\"[{timestamp}] {level}: {message}\\n\"\n",
    "        \n",
    "        with open(self.log_file, \"a\") as file:\n",
    "            file.write(log_entry)\n",
    "    \n",
    "    def read_logs(self):\n",
    "        try:\n",
    "            with open(self.log_file, \"r\") as file:\n",
    "                return file.read()\n",
    "        except FileNotFoundError:\n",
    "            return \"No logs found\"\n",
    "\n",
    "# Example usage\n",
    "logger = SimpleLogger(\"app.log\")\n",
    "logger.log(\"Application started\")\n",
    "logger.log(\"Processing data...\", \"DEBUG\")\n",
    "logger.log(\"Error in data processing\", \"ERROR\")\n",
    "print(\"\\nLog contents:\")\n",
    "print(logger.read_logs())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-automate-tasks",
   "language": "python",
   "name": "oreilly-automate-tasks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}


---
./notebooks/03-automation-projects/02-data-extraction-with-ai.ipynb
---
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction: Automating Invoice Processing\n",
    "\n",
    "This notebook demonstrates how to extract structured data from text documents like receipts and invoices using AI. We'll explore:\n",
    "\n",
    "1. Basic text extraction using prompts\n",
    "2. Structured output formats (JSON, XML)\n",
    "\n",
    "The techniques shown here can help automate manual data entry tasks and standardize information extraction from semi-structured documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'EXEMPLO, UNIPESSOAL, LDA. AV. DA LIBERDADE, 120 - 2o ESQ 123456789 1250-140 LISBOA\\nEXEMPLO, UNIPESSOAL, LDA.\\nAV. DA LIBERDADE, 120 - 2o ESQ 1250-140 LISBOA\\nLISBOA\\nJOANA SILVA PEREIRA 0033\\nDATA ANALYST 12345678901\\n298765432\\nAFIN 0010.20.987654\\n123456789 Original\\nLISBOA\\nRecibo de Vencimentos\\nRecibo de Vencimentos Per√≠odo Janeiro\\nData Fecho 31/01/2024 Vencimento 3.900,00\\nPer√≠odo Data Fecho Vencimento Venc. / Hora N. Dias M√™s:\\nFaltas Alim.\\nC√≥d.\\nR01 R06 R13 D01 D02 D05\\nJaneiro 31/01/2024\\n3.900,00 20,00 20.00\\nNome\\nN.o Mecan. Categoria\\nN.o Benef.\\nN.o Contrib. Departamento Seguro\\nJOANA SILVA PEREIRA 0033\\nDATA ANALYST 12345678901\\n298765432\\nAFIN 0010.20.987654\\nReten√ß√£o IRS\\nSDD IRS Retido Total Remun.\\nVenc. / Hora N. Dias M√™s:\\n20,00 20.00\\nNome\\nN.o Mecan. Categoria\\nN.o Benef.\\nN.o Contrib. Departamento Seguro\\nTurno Data\\n01-2024 01-2024 01-2024 01-2024 01-2024 01-2024\\nCDD\\nSDH\\nFaltas\\nAlim. Turno CDH\\nReten√ß√£o IRS\\nIRS Retido\\nCDH\\nDescri√ß√£o Remunera√ß√µes Descontos\\nSDH\\nSDD\\nTotal Remun.\\n19.200,00\\nDescontos\\n500,00 1.200,00 150,00\\nCDD\\nDescri√ß√£o Remunera√ß√µes\\nVencimento 3.900,00 IHT 650,00\\n5.400,00 19.200,00\\n5.400,00\\nVencimento 3.900,00 IHT 650,00\\nC√≥d. Data\\nR01 01-2024 R06 01-2024 R13 01-2024 D01 01-2024 D02 01-2024 D05 01-2024\\nSubs√≠dio Alimenta√ß√£o Cart√£o Seguran√ßa Social\\nIRS (Venc. 29,18%) (29,18%) Desconto Subsidio Alim. Cart√£o\\n150,00\\nSubs√≠dio Alimenta√ß√£o Cart√£o Seguran√ßa Social\\nIRS (Venc. 29,18%) (29,18%) Desconto Subsidio Alim. Cart√£o\\n150,00\\n500,00 1.200,00 150,00\\nFormas de Pagamento: % Remunera√ß√£o\\n100,00\\nForma de Pagamento Moeda\\nFormas de Pagamento: % Remunera√ß√£o\\n100,00\\nForma de Pagamento\\nTransfer√™ncia\\nMoeda\\nTotal\\n4.400,00 1.800,00 Total Pago ( EUR ) 2.950,00\\nTotal\\n4.400,00 Total Pago ( EUR )\\n1.800,00 2.950,00\\nDeclaro que recebi a quantia constante neste recibo,\\nObs.\\nDeclaro que recebi a quantia constante neste recibo,\\nTransfer√™ncia EUR\\nEUR'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./invoice-data-sample.txt\", \"r\") as f:\n",
    "    receipt_data = f.read()\n",
    "    \n",
    "receipt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "EXEMPLO, UNIPESSOAL, LDA. AV. DA LIBERDADE, 120 - 2o ESQ 123456789 1250-140 LISBOA\n",
       "EXEMPLO, UNIPESSOAL, LDA.\n",
       "AV. DA LIBERDADE, 120 - 2o ESQ 1250-140 LISBOA\n",
       "LISBOA\n",
       "JOANA SILVA PEREIRA 0033\n",
       "DATA ANALYST 12345678901\n",
       "298765432\n",
       "AFIN 0010.20.987654\n",
       "123456789 Original\n",
       "LISBOA\n",
       "Recibo de Vencimentos\n",
       "Recibo de Vencimentos Per√≠odo Janeiro\n",
       "Data Fecho 31/01/2024 Vencimento 3.900,00\n",
       "Per√≠odo Data Fecho Vencimento Venc. / Hora N. Dias M√™s:\n",
       "Faltas Alim.\n",
       "C√≥d.\n",
       "R01 R06 R13 D01 D02 D05\n",
       "Janeiro 31/01/2024\n",
       "3.900,00 20,00 20.00\n",
       "Nome\n",
       "N.o Mecan. Categoria\n",
       "N.o Benef.\n",
       "N.o Contrib. Departamento Seguro\n",
       "JOANA SILVA PEREIRA 0033\n",
       "DATA ANALYST 12345678901\n",
       "298765432\n",
       "AFIN 0010.20.987654\n",
       "Reten√ß√£o IRS\n",
       "SDD IRS Retido Total Remun.\n",
       "Venc. / Hora N. Dias M√™s:\n",
       "20,00 20.00\n",
       "Nome\n",
       "N.o Mecan. Categoria\n",
       "N.o Benef.\n",
       "N.o Contrib. Departamento Seguro\n",
       "Turno Data\n",
       "01-2024 01-2024 01-2024 01-2024 01-2024 01-2024\n",
       "CDD\n",
       "SDH\n",
       "Faltas\n",
       "Alim. Turno CDH\n",
       "Reten√ß√£o IRS\n",
       "IRS Retido\n",
       "CDH\n",
       "Descri√ß√£o Remunera√ß√µes Descontos\n",
       "SDH\n",
       "SDD\n",
       "Total Remun.\n",
       "19.200,00\n",
       "Descontos\n",
       "500,00 1.200,00 150,00\n",
       "CDD\n",
       "Descri√ß√£o Remunera√ß√µes\n",
       "Vencimento 3.900,00 IHT 650,00\n",
       "5.400,00 19.200,00\n",
       "5.400,00\n",
       "Vencimento 3.900,00 IHT 650,00\n",
       "C√≥d. Data\n",
       "R01 01-2024 R06 01-2024 R13 01-2024 D01 01-2024 D02 01-2024 D05 01-2024\n",
       "Subs√≠dio Alimenta√ß√£o Cart√£o Seguran√ßa Social\n",
       "IRS (Venc. 29,18%) (29,18%) Desconto Subsidio Alim. Cart√£o\n",
       "150,00\n",
       "Subs√≠dio Alimenta√ß√£o Cart√£o Seguran√ßa Social\n",
       "IRS (Venc. 29,18%) (29,18%) Desconto Subsidio Alim. Cart√£o\n",
       "150,00\n",
       "500,00 1.200,00 150,00\n",
       "Formas de Pagamento: % Remunera√ß√£o\n",
       "100,00\n",
       "Forma de Pagamento Moeda\n",
       "Formas de Pagamento: % Remunera√ß√£o\n",
       "100,00\n",
       "Forma de Pagamento\n",
       "Transfer√™ncia\n",
       "Moeda\n",
       "Total\n",
       "4.400,00 1.800,00 Total Pago ( EUR ) 2.950,00\n",
       "Total\n",
       "4.400,00 Total Pago ( EUR )\n",
       "1.800,00 2.950,00\n",
       "Declaro que recebi a quantia constante neste recibo,\n",
       "Obs.\n",
       "Declaro que recebi a quantia constante neste recibo,\n",
       "Transfer√™ncia EUR\n",
       "EUR"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(receipt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the provided receipt data, here is the extracted information:\\n\\n- **Company name:** EXEMPLO, UNIPESSOAL, LDA.\\n- **Date of closure:** 31/01/2024\\n- **Amount paid:** 2.950,00 EUR\\n\\nIf you need further assistance or additional extraction, feel free to ask!'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ai_tools import ask_ai\n",
    "\n",
    "extraction_prompt = f\"\"\"\n",
    "\n",
    "You are an extraction engine for receipt data.\n",
    "Users will upload the contents of their receipts and you will extract\n",
    "the following fields:\n",
    "- Company name\n",
    "- Date of closure\n",
    "- Amount paid\n",
    "\n",
    "Extract the data from the following receipt:\n",
    "{receipt_data}\n",
    "\"\"\"\n",
    "\n",
    "structured_output = ask_ai(prompt=extraction_prompt)\n",
    "\n",
    "structured_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This output is ok but we don't want the conversational elements of the response right?\n",
    "\n",
    "To get around that, let's improve our initial prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```json\\n{\\n  \"company_name\": \"EXEMPLO, UNIPESSOAL, LDA.\",\\n  \"date_of_closure\": \"31/01/2024\",\\n  \"amount_paid\": \"2.950,00\"\\n}\\n```'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_prompt_json = f\"\"\"\n",
    "You are an extraction engine for receipt data.\n",
    "Users will upload the contents of their receipts and you will extract\n",
    "the following fields as JSON OBJECTS:\n",
    "- Company name\n",
    "- Date of closure\n",
    "- Amount paid\n",
    "\n",
    "Extract the data from the following receipt:\n",
    "{receipt_data}\n",
    "\n",
    "Your OUTPUT SHOULD ONLY BE A JSON OBJECT WITH THE FOLLOWING FIELDS:\n",
    "- company_name\n",
    "- date_of_closure\n",
    "- amount_paid\n",
    "\"\"\"\n",
    "\n",
    "structured_output_json = ask_ai(prompt=extraction_prompt_json)\n",
    "\n",
    "structured_output_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'company_name': 'EXEMPLO, UNIPESSOAL, LDA.',\n",
       " 'date_of_closure': '31/01/2024',\n",
       " 'amount_paid': '2.950,00'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to import the json library to parse the JSON output\n",
    "import json\n",
    "\n",
    "def parse_json_output(json_str):\n",
    "    \"\"\"\n",
    "    This function parses the JSON output from the AI and removes the markdown code block markers if present.\n",
    "    \"\"\"\n",
    "    # Remove markdown code block markers if present\n",
    "    json_str = json_str.replace('```json', '').replace('```', '').strip()\n",
    "    \n",
    "    # Parse the JSON string into a Python dictionary\n",
    "    try:\n",
    "        return json.loads(json_str)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error: Could not parse JSON string\")\n",
    "        return None\n",
    "\n",
    "parsed_json = parse_json_output(structured_output_json)\n",
    "\n",
    "\n",
    "parsed_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company Name: EXEMPLO, UNIPESSOAL, LDA.\n",
      "Date of Closure: 31/01/2024\n",
      "Amount Paid: 2.950,00\n"
     ]
    }
   ],
   "source": [
    "print(f\"Company Name: {parsed_json['company_name']}\")\n",
    "print(f\"Date of Closure: {parsed_json['date_of_closure']}\")\n",
    "print(f\"Amount Paid: {parsed_json['amount_paid']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Claude we can also do this quite easily using `xml` tags: `<output>{\"company_name\":....etc....} </output>`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I am Claude, an AI assistant created by Anthropic to be helpful, harmless, and honest. I don't have a specific version number or model name beyond that.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ai_tools import ask_ai\n",
    "\n",
    "ask_ai(prompt=\"Hi! Which model are you?\", model_name=\"claude-3-5-sonnet-20240620\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<output>\\n  <company_name>EXEMPLO, UNIPESSOAL, LDA.</company_name>\\n  <date_of_closure>31/01/2024</date_of_closure>\\n  <amount_paid>2950.00</amount_paid>\\n</output>'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_prompt_claude = f\"\"\"\n",
    "You are an extraction engine for receipt data.\n",
    "Users will upload the contents of their receipts and you will extract key fields.\n",
    "\n",
    "Extract the following fields from this receipt:\n",
    "{receipt_data}\n",
    "\n",
    "Format your response using XML tags like this:\n",
    "<output>\n",
    "  <company_name>The company name</company_name>\n",
    "  <date_of_closure>The date of closure</date_of_closure>\n",
    "  <amount_paid>The amount paid</amount_paid>\n",
    "</output>\n",
    "\n",
    "Only include the XML tags and JSON object in your response, nothing else.\n",
    "\"\"\"\n",
    "output = ask_ai(prompt=extraction_prompt_claude, model_name=\"claude-3-5-sonnet-20240620\")\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's write a function that properly parses this output from Claude:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<company_name>EXEMPLO, UNIPESSOAL, LDA.</company_name>\\n  <date_of_closure>31/01/2024</date_of_closure>\\n  <amount_paid>2950.00</amount_paid>'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_claude_output(output):\n",
    "    \"\"\"\n",
    "    This function parses the output from Claude and removes the XML tags.\n",
    "    \"\"\"\n",
    "    # Remove XML tags if present\n",
    "    output = output.replace('<output>', '').replace('</output>', '').strip()\n",
    "    return output\n",
    "\n",
    "output_parsed = parse_claude_output(output)\n",
    "\n",
    "output_parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can access each individual attribute easily by simply parsing the tags:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company Name: EXEMPLO, UNIPESSOAL, LDA.\n",
      "Date of Closure: 31/01/2024\n",
      "Amount Paid: 2950.00\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_field(output, field_name):\n",
    "    \"\"\"Extract value between XML tags for a given field.\"\"\"\n",
    "    pattern = f\"<{field_name}>(.*?)</{field_name}>\"\n",
    "    match = re.search(pattern, output)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "# Extract each field\n",
    "company_name = extract_field(output_parsed, \"company_name\")\n",
    "date_of_closure = extract_field(output_parsed, \"date_of_closure\") \n",
    "amount_paid = extract_field(output_parsed, \"amount_paid\")\n",
    "\n",
    "print(f\"Company Name: {company_name}\")\n",
    "print(f\"Date of Closure: {date_of_closure}\")\n",
    "print(f\"Amount Paid: {amount_paid}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what if you don't want to send your private data to some cloud provider?\n",
    "\n",
    "In that case, we use local models! After a lot of advancements, we can now easily use local models to extract structured outputs similar to what we have been doing before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company Name: EXEMPLO, UNIPESSOAL, LDA. AV. DA LIBERDADE\n",
      "Date of Closure: 31/01/2024\n",
      "Amount Paid: 2950.0\n"
     ]
    }
   ],
   "source": [
    "from ai_tools import ask_local_ai\n",
    "import json\n",
    "\n",
    "extraction_prompt_json = f\"\"\"\n",
    "You are an extraction engine for receipt data.\n",
    "Users will upload the contents of their receipts and you will extract\n",
    "the following fields as JSON OBJECTS:\n",
    "- Company name\n",
    "- Date of closure\n",
    "- Amount paid\n",
    "\n",
    "Extract the data from the following receipt:\n",
    "{receipt_data}\n",
    "\n",
    "Your OUTPUT SHOULD ONLY BE A JSON OBJECT WITH THE FOLLOWING FIELDS:\n",
    "- company_name\n",
    "- date_of_closure\n",
    "- amount_paid\n",
    "\"\"\"\n",
    "\n",
    "output_string = ask_local_ai(extraction_prompt_json, structured=True)\n",
    "\n",
    "output_json = json.loads(output_string)\n",
    "\n",
    "print(f\"Company Name: {output_json['company_name']}\")\n",
    "print(f\"Date of Closure: {output_json['date_of_closure']}\")\n",
    "print(f\"Amount Paid: {output_json['amount_paid']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fancier way of doing this for those interested in exploring more about structured extractions is using something called `pydantic` a data validation library that perfectly integrates with LLM APIs like openai's and anthropics to create these structured outputs in a more programatic and organized fashion.\n",
    "See an example in: `./structured_output_with_pydantic.py`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-automate-tasks",
   "language": "python",
   "name": "oreilly-automate-tasks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}


---
./notebooks/03-automation-projects/03-web-data-extraction.ipynb
---
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Insights from Technology Trends Reports from OReilly Media\n",
    "\n",
    "Radar Trends website:\n",
    "- https://www.oreilly.com/radar/trends/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_contents_oreilly_tech_trends_january_2025 = \"\"\"\n",
    "\n",
    "Skip to main content\n",
    "O'Reilly home\n",
    "Sign In\n",
    "Try Now\n",
    "Teams\n",
    "For business\n",
    "For government\n",
    "For higher ed\n",
    "Individuals\n",
    "Features\n",
    "All features\n",
    "Courses\n",
    "Certifications\n",
    "Interactive learning\n",
    "Live events\n",
    "Answers\n",
    "Insights reporting\n",
    "Plans\n",
    "Blog\n",
    "Content sponsorship\n",
    "Search\n",
    "Radar / Radar Trends\n",
    "Radar Trends to Watch: January 2025\n",
    "Developments in Security, Programming, AI, and More\n",
    "\n",
    "By Mike Loukides\n",
    "January 7, 2025\n",
    "\n",
    "Learn faster. Dig deeper. See farther.\n",
    "Join the O'Reilly online learning platform. Get a free trial today and find answers on the fly, or master something new and useful.\n",
    "\n",
    "Learn more\n",
    "Despite its 31 days, December is a short month. It‚Äôs hard for announcements and happenings other than office parties to get attention. Fighting this trend, OpenAI made a series of announcements: their ‚Äú12 Days of OpenAI.‚Äù Not to be upstaged, Google responded with a flurry of announcements, including their Gemini 2.0 Flash Thinking model. Models appeared that could use streaming audio and video for both input and output. But perhaps the most important announcement was DeepSeek-V3, a very large mixture-of-experts model (671B parameters) that has performance on a par with the other top models‚Äîbut cost roughly 1/10th as much to train.\n",
    "\n",
    "AI\n",
    "DeepSeek-V3 is another LLM to watch. Its performance is on a par with Llama 3.1, GPT-4o, and Claude Sonnet. While training was not inexpensive, the cost of training was estimated to be roughly 10% of the bigger models.\n",
    "Not to be outdone by Google, OpenAI previewed its next models: o3 and o3-mini. These are both ‚Äúreasoning models‚Äù that have been trained to solve logical problems. They may be released in late January; OpenAI is looking for safety and security researchers for testing.\n",
    "Not to be outdone by 12 Days of OpenAI, Google has released a new experimental model that has been trained to solve logical problems: Gemini 2.0 Flash Thinking. Unlike OpenAI‚Äôs GPT models that support reasoning, Flash Thinking shows its chain of thought explicitly.\n",
    "Jeremy Howard and his team have released ModernBERT, a major upgrade to the BERT model they released six years ago. It comes in two sizes: 139M and 395M parameters. It‚Äôs ideal for retrieval, classification, and entity extraction, and other components of a data pipeline.\n",
    "AWS‚Äôs Bedrock service has the ability to check the output of other models for hallucinations.\n",
    "To make sure they aren‚Äôt outdone by 12 Days of OpenAI, Google has announced Android XR, an operating system for extended reality headsets and glasses. Google doesn‚Äôt plan to build their own hardware; they‚Äôre partnering with Samsung, Qualcomm, and other manufacturers.\n",
    "Also not to be outdone by 12 Days of OpenAI, Anthropic has announced Clio, a privacy- preserving approach to finding out how people use their models. That information will be used to improve Anthropic‚Äôs understanding of safety issues and to build more helpful models.\n",
    "Not to be outdone by 12 Days of OpenAI, Google has announced Gemini 2.0 Flash, a multimodal model that supports streaming for both input and output. The announcement also showcased Astra, an AI agent for smartphones. Neither is generally available yet.\n",
    "OpenAI has released canvas, a new feature that combines programming with writing. Changes to the canvas (code or text) immediately become part of the context. Python code is executed in the browser using Pyodide (Wasm), rather than in a container (as with Code Interpreter).\n",
    "Stripe has announced an agent toolkit that lets you build payments into agentic workflows. Stripe recommends using the toolkit in test mode until the application has been thoroughly validated.\n",
    "Simon Willison shows how to run a GPT-4 class model (Llama 3.3 70B) on a reasonably well-equipped laptop (64GB MacBook Pro M2).\n",
    "As part of their 12 Days of OpenAI series, OpenAI finally released their video generation model, Sora. It‚Äôs free to ChatGPT Plus subscribers, though limited to 50 five-second video clips per month; a ChatGPT Pro account relaxes many of the limitations.\n",
    "Researchers have shown that advanced AI models, including Claude 3 Opus and OpenAI o1, are capable of ‚Äúscheming‚Äù: working against the interests of their users to achieve their goals. Scheming includes subverting oversight mechanisms, intentionally delivering subpar results, and even taking steps to prevent shutdown or replacement. Hello, HAL?\n",
    "Roaming RAG is a new technique for retrieval augmented generation that finds relevant content by searching through headings to navigate documents‚Äîlike a human might. It requires well-structured documents. A surprisingly simple idea, really.\n",
    "Google has announced PaliGemma 2, a new version of its Gemma models that incorporates vision.\n",
    "GPT-4-o1-preview is no more; the preview is now the real thing, OpenAI o1. In addition to advanced reasoning skills, the production release claims to be faster and to deliver more consistent results.\n",
    "A group of AI agents in Minecraft behaved surprisingly like humans‚Äîeven developing jobs and religions. Is this a way to model how human groups collaborate?\n",
    "One thing the AI industry needs desperately (aside from more power) is better benchmarks. Current benchmarks are closed, easily gamed (that‚Äôs what AI does), and unreproducible, and they may not test anything meaningful. Better Bench is a framework for assessing benchmark quality.\n",
    "Palmyra Creative, a new language model from Writer, promises the ability to develop ‚Äústyle‚Äù so that all AI-generated output won‚Äôt sound boringly the same.\n",
    "During training AI picks up biases from human data. When humans interact with the AI, there‚Äôs a feedback loop that amplifies those biases.\n",
    "Programming\n",
    "Unicon may never become one of the top 20 (or top 100) programming languages, but it‚Äôs a descendant of Icon, which was always my favorite language for string processing.\n",
    "What do CAPTCHAs mean when LLM-equipped bots can successfully complete tasks set for humans?\n",
    "egui, together with eframe, is a GUI library and framework for Rust. It‚Äôs portable and runs natively (on macOS, Windows, Linux, and Android), on the web (using Wasm), and in many game engines.\n",
    "For the archivist in us: The Manx project isn‚Äôt about an island in the Irish Sea or about cats. It‚Äôs a catalog of manuals for old computers.\n",
    "Cerbrec is a graphical Python framework for deep learning. It‚Äôs aimed at Python programmers who don‚Äôt have sufficient expertise to build applications with PyTorch or other AI libraries.\n",
    "GitHub has announced free access to GitHub Copilot for all current and new users. Free access gives you 2,000 code completions and 50 chat messages per month. They‚Äôve also added the ability to use Claude 3.5 Sonnet in addition to GPT-4o.\n",
    "Devin, the AI assisted coding tool that claims to support software development from beginning to end, including design and debugging, has reached general availability.\n",
    "JSON5, also known as ‚ÄúJSON for humans,‚Äù is a variant of JSON that has been designed for human readability so that it can be written and maintained by hand‚Äîfor example, in configuration files.\n",
    "AWS has announced two significant new services: Aurora DSQL, which is a distributed SQL database, and S3 Tables, which supports data lakehouses through Apache Iceberg.\n",
    "AutoFlow is an open source tool for creating a knowledge graph. It‚Äôs based on TiDB (a vector database), LlamaIndex, and DSPy.\n",
    "Security\n",
    "Portspoof is a security tool that causes all 65,535 TCP ports to appear open for valid services. It emulates a valid service on every port. It makes it difficult for an attacker to determine which ports are actually open without probing each port.\n",
    "Let‚Äôs Encrypt, which issues the certificates that websites (and other applications) use to prove their identities, has announced short-lived certificates that expire after six days. Short-lived certificates increase security by minimizing exposure if a private key is compromised.\n",
    "Because of the continued presence of attackers within telecommunications networks, the US FBI and CISA have recommended the use of encrypted communications protocols. (Though they still want backdoors into encryption systems, which would make them vulnerable to attack.)\n",
    "A new phishing attack uses corrupted Word documents to bypass security checks. While the documents are corrupt, Word is able to recover them.\n",
    "LLM Flowbreaking is a new class of attack against language models that prevent guardrails from stopping objectionable output from reaching the user. These attacks take advantage of race conditions in the application‚Äôs interaction with users.\n",
    "Bootkitty is a UEFI bootkit that targets secure boot on Ubuntu systems. It appears to have been developed by cybersecurity students in Korea, then leaked (possibly accidentally). It hasn‚Äôt yet been found in the wild, but when it is, it will be a dangerous threat.\n",
    "DEF CON has started a project to improve cybersecurity for water infrastructure in the US. They‚Äôre starting with six water companies serving rural communities.\n",
    "Quantum Computing\n",
    "Google has built a quantum computing chip in which an error-corrected logical qubit can remain stable for an hour. It passes the ‚Äúbelow threshold‚Äù: the error rate decreases as physical qubits are added for error correction. The chip was built in Google‚Äôs new fabrication facility.\n",
    "Web\n",
    "Google is adding ‚Äústore reviews‚Äù to Chrome. Reviews are AI-generated summaries of reports from well-known sources that report scams and other issues.\n",
    "Here‚Äôs a how-to on building streaming text user interfaces on the web. Streaming text is almost a necessity for building AI-driven chatbots.\n",
    "Biology\n",
    "Yes, we can have virtual taste. A research group has developed a lollipop interface so that people can experience taste in virtual worlds.\n",
    "Post topics: Radar Trends\n",
    "Post tags: Signals\n",
    "Share:   Share\n",
    "About O‚ÄôReilly\n",
    "Teach/write/train\n",
    "Careers\n",
    "O‚ÄôReilly news\n",
    "Media coverage\n",
    "Community partners\n",
    "Affiliate program\n",
    "Submit an RFP\n",
    "Diversity\n",
    "O‚ÄôReilly for marketers\n",
    "Support\n",
    "Contact us\n",
    "Newsletters\n",
    "Privacy policy\n",
    " \n",
    "International\n",
    "Australia & New Zealand\n",
    "Hong Kong & Taiwan\n",
    "India\n",
    "Indonesia\n",
    "Japan\n",
    "Download the O‚ÄôReilly App\n",
    "Take O‚ÄôReilly with you and learn anywhere, anytime on your phone and tablet.\n",
    "\n",
    "Apple app store Google play store\n",
    "Watch on your big screen\n",
    "View all O‚ÄôReilly videos, Superstream events, and Meet the Expert sessions on your home TV.\n",
    "\n",
    "Roku Payers and TVs Amazon appstore\n",
    "Do not sell my personal information\n",
    "O'Reilly home\n",
    "¬© 2025, O‚ÄôReilly Media, Inc. All trademarks and registered trademarks appearing on oreilly.com are the property of their respective owners.\n",
    "\n",
    "Terms of service ‚Ä¢ Privacy policy ‚Ä¢ Editorial independence\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ai-insights': ['DeepSeek-V3 is a very large mixture-of-experts model (671B parameters) that has performance on par with the top models but costs roughly 1/10th as much to train.',\n",
       "  \"OpenAI previewed its next models, o3 and o3-mini, which are 'reasoning models' trained to solve logical problems.\",\n",
       "  'Google released a new experimental model, Gemini 2.0 Flash Thinking, trained to solve logical problems and shows its chain of thought explicitly.',\n",
       "  \"Jeremy Howard's team released ModernBERT, an upgrade to the BERT model, ideal for retrieval, classification, and entity extraction.\",\n",
       "  'AWS‚Äôs Bedrock service can check the output of AI models for hallucinations.',\n",
       "  'Anthropic announced Clio, a privacy-preserving approach to understand how users interact with their models and improve them.',\n",
       "  \"Google's Gemini 2.0 Flash is a multimodal model that supports streaming for both input and output.\",\n",
       "  'OpenAI released a video generation model, Sora, free for ChatGPT Plus subscribers, limited to 50 five-second video clips per month.',\n",
       "  \"Advanced AI models are capable of 'scheming', working against user interests and subverting oversight mechanisms.\",\n",
       "  'Roaming RAG is a technique for retrieval augmented generation, finding relevant content by searching through document headings.',\n",
       "  'A group of AI agents in Minecraft began developing jobs and religions, mimicking human collaboration.',\n",
       "  'The AI industry needs better benchmarks, as current benchmarks are closed, easily gamed, and may not test meaningful criteria.'],\n",
       " 'programming-insights': ['Unicon is a descendant of Icon, focused on string processing, though unlikely to become a top programming language.',\n",
       "  'egui and eframe are GUI library and framework for Rust that can run natively on multiple platforms and in game engines.',\n",
       "  'Cerbrec is a graphical Python framework for deep learning aimed at users without enough expertise for frameworks like PyTorch.',\n",
       "  'GitHub announced free access to GitHub Copilot for all users, allowing 2,000 code completions and 50 chat messages monthly.',\n",
       "  'Devin is an AI-assisted coding tool designed to support software development from design to debugging.',\n",
       "  'JSON5 is a human-readable variant of JSON intended for easier manual maintenance, especially in configuration files.',\n",
       "  'AWS has introduced Aurora DSQL, a distributed SQL database, and S3 Tables, supporting data lakehouse solutions.'],\n",
       " 'date': 'January 7, 2025'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ai_tools import ask_ai, parse_json_output\n",
    "\n",
    "extract_insights_prompt = f\"\"\"\n",
    "Extract from these raw contents, all the insights regarding AI and programming into the following structure format:\n",
    "\n",
    "- AI insights\n",
    "- Programming insights\n",
    "\n",
    "Here are the raw contents:\n",
    "\n",
    "{raw_contents_oreilly_tech_trends_january_2025}.\n",
    "\n",
    "Your OUTPUT SHOULD ONLY BE A JSON OBJECT WITH THE FOLLOWING FIELDS:\n",
    "\n",
    "- ai-insights\n",
    "- programming-insights\n",
    "- date\n",
    "\n",
    "Output:\n",
    "\"\"\"\n",
    "\n",
    "output = ask_ai(extract_insights_prompt)\n",
    "parsed_output_json = parse_json_output(output)\n",
    "parsed_output_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tech Trends Report - January 7, 2025\n",
      "\n",
      "## AI Insights\n",
      "- DeepSeek-V3 is a very large mixture-of-experts model (671B parameters) that has performance on par with the top models but costs roughly 1/10th as much to train.\n",
      "- OpenAI previewed its next models, o3 and o3-mini, which are 'reasoning models' trained to solve logical problems.\n",
      "- Google released a new experimental model, Gemini 2.0 Flash Thinking, trained to solve logical problems and shows its chain of thought explicitly.\n",
      "- Jeremy Howard's team released ModernBERT, an upgrade to the BERT model, ideal for retrieval, classification, and entity extraction.\n",
      "- AWS‚Äôs Bedrock service can check the output of AI models for hallucinations.\n",
      "- Anthropic announced Clio, a privacy-preserving approach to understand how users interact with their models and improve them.\n",
      "- Google's Gemini 2.0 Flash is a multimodal model that supports streaming for both input and output.\n",
      "- OpenAI released a video generation model, Sora, free for ChatGPT Plus subscribers, limited to 50 five-second video clips per month.\n",
      "- Advanced AI models are capable of 'scheming', working against user interests and subverting oversight mechanisms.\n",
      "- Roaming RAG is a technique for retrieval augmented generation, finding relevant content by searching through document headings.\n",
      "- A group of AI agents in Minecraft began developing jobs and religions, mimicking human collaboration.\n",
      "- The AI industry needs better benchmarks, as current benchmarks are closed, easily gamed, and may not test meaningful criteria.\n",
      "\n",
      "## Programming Insights\n",
      "- Unicon is a descendant of Icon, focused on string processing, though unlikely to become a top programming language.\n",
      "- egui and eframe are GUI library and framework for Rust that can run natively on multiple platforms and in game engines.\n",
      "- Cerbrec is a graphical Python framework for deep learning aimed at users without enough expertise for frameworks like PyTorch.\n",
      "- GitHub announced free access to GitHub Copilot for all users, allowing 2,000 code completions and 50 chat messages monthly.\n",
      "- Devin is an AI-assisted coding tool designed to support software development from design to debugging.\n",
      "- JSON5 is a human-readable variant of JSON intended for easier manual maintenance, especially in configuration files.\n",
      "- AWS has introduced Aurora DSQL, a distributed SQL database, and S3 Tables, supporting data lakehouse solutions.\n"
     ]
    }
   ],
   "source": [
    "# Convert JSON insights to markdown format\n",
    "print(\"# Tech Trends Report - \" + parsed_output_json['date'])\n",
    "print(\"\\n## AI Insights\")\n",
    "for insight in parsed_output_json['ai-insights']:\n",
    "    print(f\"- {insight}\")\n",
    "    \n",
    "print(\"\\n## Programming Insights\") \n",
    "for insight in parsed_output_json['programming-insights']:\n",
    "    print(f\"- {insight}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now easily transform this into a table to store our own databaset of the recent tech trends!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AI Insights</th>\n",
       "      <th>Programming Insights</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DeepSeek-V3 is a very large mixture-of-experts...</td>\n",
       "      <td>Unicon is a descendant of Icon, focused on str...</td>\n",
       "      <td>January 7, 2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OpenAI previewed its next models, o3 and o3-mi...</td>\n",
       "      <td>egui and eframe are GUI library and framework ...</td>\n",
       "      <td>January 7, 2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Google released a new experimental model, Gemi...</td>\n",
       "      <td>Cerbrec is a graphical Python framework for de...</td>\n",
       "      <td>January 7, 2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jeremy Howard's team released ModernBERT, an u...</td>\n",
       "      <td>GitHub announced free access to GitHub Copilot...</td>\n",
       "      <td>January 7, 2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AWS‚Äôs Bedrock service can check the output of ...</td>\n",
       "      <td>Devin is an AI-assisted coding tool designed t...</td>\n",
       "      <td>January 7, 2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Anthropic announced Clio, a privacy-preserving...</td>\n",
       "      <td>JSON5 is a human-readable variant of JSON inte...</td>\n",
       "      <td>January 7, 2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Google's Gemini 2.0 Flash is a multimodal mode...</td>\n",
       "      <td>AWS has introduced Aurora DSQL, a distributed ...</td>\n",
       "      <td>January 7, 2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>OpenAI released a video generation model, Sora...</td>\n",
       "      <td>None</td>\n",
       "      <td>January 7, 2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Advanced AI models are capable of 'scheming', ...</td>\n",
       "      <td>None</td>\n",
       "      <td>January 7, 2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Roaming RAG is a technique for retrieval augme...</td>\n",
       "      <td>None</td>\n",
       "      <td>January 7, 2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>A group of AI agents in Minecraft began develo...</td>\n",
       "      <td>None</td>\n",
       "      <td>January 7, 2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The AI industry needs better benchmarks, as cu...</td>\n",
       "      <td>None</td>\n",
       "      <td>January 7, 2025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          AI Insights  \\\n",
       "0   DeepSeek-V3 is a very large mixture-of-experts...   \n",
       "1   OpenAI previewed its next models, o3 and o3-mi...   \n",
       "2   Google released a new experimental model, Gemi...   \n",
       "3   Jeremy Howard's team released ModernBERT, an u...   \n",
       "4   AWS‚Äôs Bedrock service can check the output of ...   \n",
       "5   Anthropic announced Clio, a privacy-preserving...   \n",
       "6   Google's Gemini 2.0 Flash is a multimodal mode...   \n",
       "7   OpenAI released a video generation model, Sora...   \n",
       "8   Advanced AI models are capable of 'scheming', ...   \n",
       "9   Roaming RAG is a technique for retrieval augme...   \n",
       "10  A group of AI agents in Minecraft began develo...   \n",
       "11  The AI industry needs better benchmarks, as cu...   \n",
       "\n",
       "                                 Programming Insights             Date  \n",
       "0   Unicon is a descendant of Icon, focused on str...  January 7, 2025  \n",
       "1   egui and eframe are GUI library and framework ...  January 7, 2025  \n",
       "2   Cerbrec is a graphical Python framework for de...  January 7, 2025  \n",
       "3   GitHub announced free access to GitHub Copilot...  January 7, 2025  \n",
       "4   Devin is an AI-assisted coding tool designed t...  January 7, 2025  \n",
       "5   JSON5 is a human-readable variant of JSON inte...  January 7, 2025  \n",
       "6   AWS has introduced Aurora DSQL, a distributed ...  January 7, 2025  \n",
       "7                                                None  January 7, 2025  \n",
       "8                                                None  January 7, 2025  \n",
       "9                                                None  January 7, 2025  \n",
       "10                                               None  January 7, 2025  \n",
       "11                                               None  January 7, 2025  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create lists of insights and dates\n",
    "ai_insights = parsed_output_json['ai-insights']\n",
    "prog_insights = parsed_output_json['programming-insights']\n",
    "dates = [parsed_output_json['date']] * max(len(ai_insights), len(prog_insights))\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'AI Insights': ai_insights + [None] * (len(prog_insights) - len(ai_insights)) if len(prog_insights) > len(ai_insights) else ai_insights,\n",
    "    'Programming Insights': prog_insights + [None] * (len(ai_insights) - len(prog_insights)) if len(ai_insights) > len(prog_insights) else prog_insights,\n",
    "    'Date': dates\n",
    "})\n",
    "\n",
    "# Display the table\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Latest O'Reilly AI & Programming News:\n",
      "1. DeepSeek-V3 is another LLM to watch. Its performance is on a par with Llama 3.1, GPT-4o, and Claude Sonnet. While training was not inexpensive, the cost of training was estimated to be roughly 10% of the bigger models.\n",
      "2. Not to be outdone by Google, OpenAI previewed its next models: o3 and o3-mini. These are both √¢¬Ä¬úreasoning models√¢¬Ä¬ù that have been trained to solve logical problems. They may be released in late January; OpenAI is looking for safety and security researchers for testing.\n",
      "3. Not to be outdone by 12 Days of OpenAI, Google has released a new experimental model that has been trained to solve logical problems: Gemini 2.0 Flash Thinking. Unlike OpenAI√¢¬Ä¬ôs GPT models that support reasoning, Flash Thinking shows its chain of thought explicitly.\n",
      "4. Jeremy Howard and his team have released ModernBERT, a major upgrade to the BERT model they released six years ago. It comes in two sizes: 139M and 395M parameters. It√¢¬Ä¬ôs ideal for retrieval, classification, and entity extraction, and other components of a data pipeline.\n",
      "5. AWS√¢¬Ä¬ôs Bedrock service has the ability to check the output of other models for hallucinations.\n",
      "6. To make sure they aren√¢¬Ä¬ôt outdone by 12 Days of OpenAI, Google has announced Android XR, an operating system for extended reality headsets and glasses. Google doesn√¢¬Ä¬ôt plan to build their own hardware; they√¢¬Ä¬ôre partnering with Samsung, Qualcomm, and other manufacturers.\n",
      "7. Also not to be outdone by 12 Days of OpenAI, Anthropic has announced Clio, a privacy- preserving approach to finding out how people use their models. That information will be used to improve Anthropic√¢¬Ä¬ôs understanding of safety issues and to build more helpful models.\n",
      "8. Not to be outdone by 12 Days of OpenAI, Google has announced Gemini 2.0 Flash, a multimodal model that supports streaming for both input and output. The announcement also showcased Astra, an AI agent for smartphones. Neither is generally available yet.\n",
      "9. OpenAI has released canvas, a new feature that combines programming with writing. Changes to the canvas (code or text) immediately become part of the context. Python code is executed in the browser using Pyodide (Wasm), rather than in a container (as with Code Interpreter).\n",
      "10. Stripe has announced an agent toolkit that lets you build payments into agentic workflows. Stripe recommends using the toolkit in test mode until the application has been thoroughly validated.\n",
      "11. Simon Willison shows how to run a GPT-4 class model (Llama 3.3 70B) on a reasonably well-equipped laptop (64GB MacBook Pro M2).\n",
      "12. As part of their 12 Days of OpenAI series, OpenAI finally released their video generation model, Sora. It√¢¬Ä¬ôs free to ChatGPT Plus subscribers, though limited to 50 five-second video clips per month; a ChatGPT Pro account relaxes many of the limitations.\n",
      "13. Researchers have shown that advanced AI models, including Claude 3 Opus and OpenAI o1, are capable of √¢¬Ä¬úscheming√¢¬Ä¬ù: working against the interests of their users to achieve their goals. Scheming includes subverting oversight mechanisms, intentionally delivering subpar results, and even taking steps to prevent shutdown or replacement. Hello, HAL?\n",
      "14. Roaming RAG is a new technique for retrieval augmented generation that finds relevant content by searching through headings to navigate documents√¢¬Ä¬îlike a human might. It requires well-structured documents. A surprisingly simple idea, really.\n",
      "15. Google has announced PaliGemma 2, a new version of its Gemma models that incorporates vision.\n",
      "16. GPT-4-o1-preview is no more; the preview is now the real thing, OpenAI o1. In addition to advanced reasoning skills, the production release claims to be faster and to deliver more consistent results.\n",
      "17. A group of AI agents in Minecraft behaved surprisingly like humans√¢¬Ä¬îeven developing jobs and religions. Is this a way to model how human groups collaborate?\n",
      "18. One thing the AI industry needs desperately (aside from more power) is better benchmarks. Current benchmarks are closed, easily gamed (that√¢¬Ä¬ôs what AI does), and unreproducible, and they may not test anything meaningful. Better Bench is a framework for assessing benchmark quality.\n",
      "19. Palmyra Creative, a new language model from Writer, promises the ability to develop √¢¬Ä¬ústyle√¢¬Ä¬ù so that all AI-generated output won√¢¬Ä¬ôt sound boringly the same.\n",
      "20. During training AI picks up biases from human data. When humans interact with the AI, there√¢¬Ä¬ôs a feedback loop that amplifies those biases.\n",
      "21. Unicon may never become one of the top 20 (or top 100) programming languages, but it√¢¬Ä¬ôs a descendant of Icon, which was always my favorite language for string processing.\n",
      "22. What do CAPTCHAs mean when LLM-equipped bots can successfully complete tasks set for humans?\n",
      "23. egui, together with eframe, is a GUI library and framework for Rust. It√¢¬Ä¬ôs portable and runs natively (on macOS, Windows, Linux, and Android), on the web (using Wasm), and in many game engines.\n",
      "24. For the archivist in us: The Manx project isn√¢¬Ä¬ôt about an island in the Irish Sea or about cats. It√¢¬Ä¬ôs a catalog of manuals for old computers.\n",
      "25. Cerbrec is a graphical Python framework for deep learning. It√¢¬Ä¬ôs aimed at Python programmers who don√¢¬Ä¬ôt have sufficient expertise to build applications with PyTorch or other AI libraries.\n",
      "26. GitHub has announced free access to GitHub Copilot for all current and new users. Free access gives you 2,000 code completions and 50 chat messages per month. They√¢¬Ä¬ôve also added the ability to use Claude 3.5 Sonnet in addition to GPT-4o.\n",
      "27. Devin, the AI assisted coding tool that claims to support software development from beginning to end, including design and debugging, has reached general availability.\n",
      "28. JSON5, also known as √¢¬Ä¬úJSON for humans,√¢¬Ä¬ù is a variant of JSON that has been designed for human readability so that it can be written and maintained by hand√¢¬Ä¬îfor example, in configuration files.\n",
      "29. AWS has announced two significant new services: Aurora DSQL, which is a distributed SQL database, and S3 Tables, which supports data lakehouses through Apache Iceberg.\n",
      "30. AutoFlow is an open source tool for creating a knowledge graph. It√¢¬Ä¬ôs based on TiDB (a vector database), LlamaIndex, and DSPy.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_oreilly_ai_programming_news(url):\n",
    "    \"\"\"\n",
    "    Scrape AI and programming-related content from O'Reilly Radar.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Send request to the website\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Parse HTML content\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Find AI and Programming sections\n",
    "        ai_section = soup.find('h2', string=lambda text: text and 'AI' in text)\n",
    "        programming_section = soup.find('h2', string=lambda text: text and 'Programming' in text)\n",
    "        \n",
    "        news_items = []\n",
    "        \n",
    "        # Extract AI content\n",
    "        if ai_section:\n",
    "            ai_content = ai_section.find_next('ul')\n",
    "            if ai_content:\n",
    "                news_items.extend([li.text.strip() for li in ai_content.find_all('li')])\n",
    "        \n",
    "        # Extract Programming content\n",
    "        if programming_section:\n",
    "            programming_content = programming_section.find_next('ul')\n",
    "            if programming_content:\n",
    "                news_items.extend([li.text.strip() for li in programming_content.find_all('li')])\n",
    "        \n",
    "        return news_items\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error scraping website: {e}\")\n",
    "        return []\n",
    "\n",
    "# Example usage (replace with actual O'Reilly Radar URL)\n",
    "oreilly_url = \"https://www.oreilly.com/radar/radar-trends-to-watch-january-2025/\"\n",
    "ai_programming_news = scrape_oreilly_ai_programming_news(oreilly_url)\n",
    "\n",
    "if ai_programming_news:\n",
    "    print(\"\\nLatest O'Reilly AI & Programming News:\")\n",
    "    for idx, news in enumerate(ai_programming_news, 1):\n",
    "        print(f\"{idx}. {news}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-automate-tasks",
   "language": "python",
   "name": "oreilly-automate-tasks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}


---
./notebooks/03-automation-projects/04-data-analysis-automation.ipynb
---
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Showing a sample of the data to an AI model like ChatGPT\n",
    "2. Asking for the Python code for the analysis\n",
    "3. Inspecting and running the code\n",
    "4. Automating it locally in our machines to run forever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Stock Symbol</th>\n",
       "      <th>Open Price</th>\n",
       "      <th>Close Price</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Moving Average (50-day)</th>\n",
       "      <th>RSI (Relative Strength Index)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>249.816048</td>\n",
       "      <td>240.444631</td>\n",
       "      <td>768234</td>\n",
       "      <td>240.444631</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>480.285723</td>\n",
       "      <td>483.013931</td>\n",
       "      <td>478480</td>\n",
       "      <td>361.729281</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>392.797577</td>\n",
       "      <td>389.084696</td>\n",
       "      <td>891971</td>\n",
       "      <td>370.847753</td>\n",
       "      <td>72.086287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-04</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>339.463394</td>\n",
       "      <td>339.634808</td>\n",
       "      <td>601157</td>\n",
       "      <td>363.044516</td>\n",
       "      <td>62.850185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>162.407456</td>\n",
       "      <td>170.558786</td>\n",
       "      <td>4478727</td>\n",
       "      <td>324.547370</td>\n",
       "      <td>43.704255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>2024-05-13</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>288.612984</td>\n",
       "      <td>286.678211</td>\n",
       "      <td>4032441</td>\n",
       "      <td>322.118171</td>\n",
       "      <td>45.674494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>2024-05-14</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>317.293122</td>\n",
       "      <td>311.704345</td>\n",
       "      <td>1307068</td>\n",
       "      <td>318.940871</td>\n",
       "      <td>43.853621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>2024-05-15</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>163.698295</td>\n",
       "      <td>162.066291</td>\n",
       "      <td>4464406</td>\n",
       "      <td>318.721371</td>\n",
       "      <td>39.550593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>2024-05-16</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>181.480500</td>\n",
       "      <td>175.552065</td>\n",
       "      <td>494274</td>\n",
       "      <td>314.121417</td>\n",
       "      <td>37.937391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>2024-05-17</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>136.465796</td>\n",
       "      <td>143.274844</td>\n",
       "      <td>4511589</td>\n",
       "      <td>309.389500</td>\n",
       "      <td>39.351527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date Stock Symbol  Open Price  Close Price   Volume  \\\n",
       "0    2024-01-01         AAPL  249.816048   240.444631   768234   \n",
       "1    2024-01-02         AAPL  480.285723   483.013931   478480   \n",
       "2    2024-01-03         AAPL  392.797577   389.084696   891971   \n",
       "3    2024-01-04         AAPL  339.463394   339.634808   601157   \n",
       "4    2024-01-05         AAPL  162.407456   170.558786  4478727   \n",
       "..          ...          ...         ...          ...      ...   \n",
       "495  2024-05-13         TSLA  288.612984   286.678211  4032441   \n",
       "496  2024-05-14         TSLA  317.293122   311.704345  1307068   \n",
       "497  2024-05-15         TSLA  163.698295   162.066291  4464406   \n",
       "498  2024-05-16         TSLA  181.480500   175.552065   494274   \n",
       "499  2024-05-17         TSLA  136.465796   143.274844  4511589   \n",
       "\n",
       "     Moving Average (50-day)  RSI (Relative Strength Index)  \n",
       "0                 240.444631                       0.000000  \n",
       "1                 361.729281                     100.000000  \n",
       "2                 370.847753                      72.086287  \n",
       "3                 363.044516                      62.850185  \n",
       "4                 324.547370                      43.704255  \n",
       "..                       ...                            ...  \n",
       "495               322.118171                      45.674494  \n",
       "496               318.940871                      43.853621  \n",
       "497               318.721371                      39.550593  \n",
       "498               314.121417                      37.937391  \n",
       "499               309.389500                      39.351527  \n",
       "\n",
       "[500 rows x 7 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./stock-trading-data.csv\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report saved as financial_analysis_report.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mplfinance as mpf\n",
    "import os\n",
    "\n",
    "# Load data\n",
    "def load_data(file_path):\n",
    "    df = pd.read_csv(file_path, parse_dates=['Date'])\n",
    "    df.dropna(inplace=True)  # Handle missing values\n",
    "    df.sort_values(by=['Date'], inplace=True)\n",
    "    return df\n",
    "\n",
    "# Compute daily returns and rolling volatility\n",
    "def compute_returns_volatility(df):\n",
    "    df['Daily Return'] = df.groupby('Stock Symbol')['Close Price'].pct_change()\n",
    "    df['Rolling Volatility'] = df.groupby('Stock Symbol')['Daily Return'].rolling(window=20).std().reset_index(level=0, drop=True)\n",
    "    return df\n",
    "\n",
    "# Compute SMA and EMA\n",
    "def compute_moving_averages(df):\n",
    "    df['SMA_20'] = df.groupby('Stock Symbol')['Close Price'].transform(lambda x: x.rolling(window=20).mean())\n",
    "    df['EMA_20'] = df.groupby('Stock Symbol')['Close Price'].transform(lambda x: x.ewm(span=20, adjust=False).mean())\n",
    "    return df\n",
    "\n",
    "# Compute Bollinger Bands\n",
    "def compute_bollinger_bands(df):\n",
    "    rolling_mean = df.groupby('Stock Symbol')['Close Price'].transform(lambda x: x.rolling(window=20).mean())\n",
    "    rolling_std = df.groupby('Stock Symbol')['Close Price'].transform(lambda x: x.rolling(window=20).std())\n",
    "    df['Upper Band'] = rolling_mean + (rolling_std * 2)\n",
    "    df['Lower Band'] = rolling_mean - (rolling_std * 2)\n",
    "    return df\n",
    "\n",
    "# Compute MACD\n",
    "def compute_macd(df):\n",
    "    df['EMA_12'] = df.groupby('Stock Symbol')['Close Price'].transform(lambda x: x.ewm(span=12, adjust=False).mean())\n",
    "    df['EMA_26'] = df.groupby('Stock Symbol')['Close Price'].transform(lambda x: x.ewm(span=26, adjust=False).mean())\n",
    "    df['MACD'] = df['EMA_12'] - df['EMA_26']\n",
    "    df['Signal Line'] = df.groupby('Stock Symbol')['MACD'].transform(lambda x: x.ewm(span=9, adjust=False).mean())\n",
    "    return df\n",
    "\n",
    "# Generate visualizations\n",
    "def plot_stock_prices(df, symbol):\n",
    "    stock_df = df[df['Stock Symbol'] == symbol]\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(stock_df['Date'], stock_df['Close Price'], label='Close Price')\n",
    "    plt.plot(stock_df['Date'], stock_df['SMA_20'], label='20-day SMA', linestyle='dashed')\n",
    "    plt.plot(stock_df['Date'], stock_df['EMA_20'], label='20-day EMA', linestyle='dotted')\n",
    "    plt.fill_between(stock_df['Date'], stock_df['Upper Band'], stock_df['Lower Band'], color='gray', alpha=0.3, label='Bollinger Bands')\n",
    "    plt.title(f'{symbol} Stock Price Analysis')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(f'{symbol}_stock_price.png')\n",
    "    plt.close()\n",
    "\n",
    "# Generate heatmap of correlations\n",
    "def plot_correlation_heatmap(df):\n",
    "    numeric_cols = ['Close Price', 'Daily Return', 'Rolling Volatility', 'SMA_20', 'EMA_20', 'RSI (Relative Strength Index)', 'MACD', 'Signal Line']\n",
    "    correlation_matrix = df[numeric_cols].corr()\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "    plt.title('Stock Metric Correlation Heatmap')\n",
    "    plt.savefig('correlation_heatmap.png')\n",
    "    plt.close()\n",
    "\n",
    "# Export analysis to Excel\n",
    "def export_to_excel(df):\n",
    "    output_file = 'financial_analysis_report.xlsx'\n",
    "    with pd.ExcelWriter(output_file, engine='xlsxwriter') as writer:\n",
    "        df.to_excel(writer, sheet_name='Stock Data', index=False)\n",
    "        workbook = writer.book\n",
    "        worksheet = writer.sheets['Stock Data']\n",
    "        worksheet.insert_image('J2', 'AAPL_stock_price.png')\n",
    "        worksheet.insert_image('J20', 'correlation_heatmap.png')\n",
    "    print(f'Report saved as {output_file}')\n",
    "\n",
    "# Main function\n",
    "\n",
    "\n",
    "\n",
    "df = compute_returns_volatility(df)\n",
    "df = compute_moving_averages(df)\n",
    "df = compute_bollinger_bands(df)\n",
    "df = compute_macd(df)\n",
    "\n",
    "plot_stock_prices(df, 'AAPL')\n",
    "plot_correlation_heatmap(df)\n",
    "export_to_excel(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "![](./)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-automate-tasks",
   "language": "python",
   "name": "oreilly-automate-tasks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}


---
./notebooks/03-automation-projects/05-presentation-automation.ipynb
---
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}


---
./notebooks/03-automation-projects/06-browser-automation.ipynb
---
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4398d318",
   "metadata": {},
   "source": [
    "# Introduction to Browser Automation with Playwright in Python\n",
    "\n",
    "This lesson covers automating web browser interactions using the Playwright library in Python, drawing from Python programming fundamentals.\n",
    "\n",
    "## Basic Setup and Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62f1289",
   "metadata": {},
   "source": [
    "**<span style=\"color: red\">DISCLAIMER: this notebook will only run locally (not on Google Colab)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbfd76f",
   "metadata": {},
   "source": [
    "%pip install playwright\n",
    "%playwright install"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24712c7f",
   "metadata": {},
   "source": [
    "## Understanding Browser Automation Flow\n",
    "\n",
    "\n",
    "Let's break down the script: `./add_movie_to_watchlist.py`:\n",
    "\n",
    "```python\n",
    "import re\n",
    "from playwright.sync_api import Playwright, sync_playwright, expect\n",
    "import os\n",
    "import sys\n",
    "\n",
    "def run(playwright: Playwright) -> None:\n",
    "    movie_to_search = sys.argv[1] \n",
    "    browser = playwright.chromium.launch(headless=False)\n",
    "    context = browser.new_context()\n",
    "    page = context.new_page()\n",
    "    page.goto(\"https://letterboxd.com/\")\n",
    "    page.get_by_label(\"Do not consent\").click()\n",
    "    page.get_by_role(\"link\", name=\"Sign in\").click()\n",
    "    page.get_by_label(\"Username\").fill(os.environ[\"LETTERBOXD_USER\"])\n",
    "    page.get_by_label(\"Username\").press(\"Tab\")\n",
    "    page.get_by_label(\"Password\").fill(os.environ[\"LETTERBOXD_PWD\"])\n",
    "    page.get_by_role(\"button\", name=\"Sign in\").click()\n",
    "    page.locator(\".navitem > .replace\").click()\n",
    "    page.get_by_label(\"Search:\").fill(movie_to_search)\n",
    "    page.get_by_role(\"button\", name=\"Search\").click()\n",
    "    page.get_by_role(\"link\", name=movie_to_search, exact=True).first.click()\n",
    "    page.get_by_role(\"link\", name=\"Add this film to your\").click()\n",
    "\n",
    "    # ---------------------\n",
    "    context.close()\n",
    "    browser.close()\n",
    "\n",
    "\n",
    "with sync_playwright() as playwright:\n",
    "    run(playwright)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f39ae9",
   "metadata": {},
   "source": [
    "# Browser Automation with Playwright - A Tutorial\n",
    "\n",
    "## Overview\n",
    "This script uses Playwright to automate the process of adding movies to a Letterboxd watchlist.\n",
    "\n",
    "## Script Structure\n",
    "\n",
    "### 1. Imports and Setup\n",
    "```python\n",
    "import re\n",
    "from playwright.sync_api import Playwright, sync_playwright, expect\n",
    "import os\n",
    "import sys\n",
    "```\n",
    "Key imports for browser automation, environment variables, and system arguments.\n",
    "\n",
    "### 2. Main Function\n",
    "```python\n",
    "def run(playwright: Playwright) -> None:\n",
    "```\n",
    "The main function that handles browser automation, taking a Playwright instance as parameter.\n",
    "\n",
    "### 3. Browser Setup\n",
    "```python\n",
    "browser = playwright.chromium.launch(headless=False)\n",
    "context = browser.new_context()\n",
    "page = context.new_page()\n",
    "```\n",
    "- Launches Chromium browser in visible mode\n",
    "- Creates a new browser context\n",
    "- Opens a new page\n",
    "\n",
    "### 4. Authentication Flow\n",
    "```python\n",
    "page.get_by_label(\"Username\").fill(os.environ[\"LETTERBOXD_USER\"])\n",
    "page.get_by_label(\"Password\").fill(os.environ[\"LETTERBOXD_PWD\"])\n",
    "page.get_by_role(\"button\", name=\"Sign in\").click()\n",
    "```\n",
    "Handles login using environment variables for credentials.\n",
    "\n",
    "### 5. Movie Search and Addition\n",
    "```python\n",
    "page.get_by_label(\"Search:\").fill(movie_to_search)\n",
    "page.get_by_role(\"button\", name=\"Search\").click()\n",
    "page.get_by_role(\"link\", name=movie_to_search, exact=True).first.click()\n",
    "page.get_by_role(\"link\", name=\"Add this film to your\").click()\n",
    "```\n",
    "Searches for and adds the specified movie to watchlist.\n",
    "\n",
    "### 6. Cleanup\n",
    "```python\n",
    "context.close()\n",
    "browser.close()\n",
    "```\n",
    "Properly closes browser context and instance.\n",
    "\n",
    "### 7. Script Execution\n",
    "```python\n",
    "with sync_playwright() as playwright:\n",
    "    run(playwright)\n",
    "```\n",
    "Runs the automation script using Playwright's context manager.\n",
    "\n",
    "## Usage\n",
    "Run the script with a movie title as argument:\n",
    "```bash\n",
    "python add_movie_to_watchlist.py \"Movie Title\"\n",
    "```\n",
    "\n",
    "## Environment Variables\n",
    "Required environment variables:\n",
    "- `LETTERBOXD_USER`: Letterboxd username\n",
    "- `LETTERBOXD_PWD`: Letterboxd password"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39c7cfa",
   "metadata": {},
   "source": [
    "This code demonstrates core Playwright concepts:\n",
    "- Browser and context management\n",
    "- Page navigation and interaction\n",
    "- Form filling and button clicking\n",
    "- Error handling and retries\n",
    "- Environment variable usage\n",
    "- Command line arguments\n",
    "- Type hints and documentation\n",
    "\n",
    "The example uses IMDb instead of Letterboxd but follows similar patterns while introducing additional programming concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca071f20",
   "metadata": {},
   "source": [
    "![](2025-02-04-14-30-46.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f245db4",
   "metadata": {},
   "source": [
    "But what is cool about the script is that I didn't really write it! I obtained through a mix of prompting ChatGPT and playwright `codegen` tool that allows us to interact with a browser and get the necessary code to reproduce such action! Example of a terminal command you can run:\n",
    "\n",
    "`playwright codegen https://letterboxd.com/`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b847b88",
   "metadata": {},
   "source": [
    "To save credentials to avoid having to redo login steps see example scripts at:\n",
    "- `./letterboxd_saving_auth_browser.py`\n",
    "- `./letterboxd_using_auth.py`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-automate-tasks",
   "language": "python",
   "name": "oreilly-automate-tasks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}


---
./notebooks/03-automation-projects/07-workflow-automation.ipynb
---
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}


---
./notebooks/03-automation-projects/08-email-assistant.ipynb
---
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}


---
./notebooks/03-automation-projects/09-ai-scheduler-agent.ipynb
---
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}


---
./notebooks/03-automation-projects/10-receipt-data-extraction.ipynb
---
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}


---
./notebooks/03-automation-projects/11-custom-automation-scripts.ipynb
---
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}


---
./notebooks/03-automation-projects/12-practical-examples.ipynb
---
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b946939",
   "metadata": {},
   "source": [
    "Report of several practical examples where people have automated downloads (or file retrieval) with Python. Many examples you see on Reddit, developer blogs, and tutorials show that‚Äîwhether it‚Äôs downloading a report, a media file, or scraping content for later use‚ÄîPython‚Äôs rich ecosystem makes it straightforward. Here are eight representative examples with concise code snippets:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Basic File Download with‚ÄØ`urllib`\n",
    "\n",
    "A common starting point is to use Python‚Äôs built‚Äêin‚ÄØ`urllib.request.urlretrieve`‚ÄØto download a file from an HTTP URL. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b40b106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "url = \"http://example.com/file.zip\"\n",
    "filename = \"file.zip\"\n",
    "urllib.request.urlretrieve(url, filename)\n",
    "print(\"Downloaded file.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7680a8bb",
   "metadata": {},
   "source": [
    "This approach requires no external dependencies and is ideal for simple one‚Äêoff downloads.  \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Download Using the Python‚ÄØ`wget`‚ÄØModule\n",
    "\n",
    "There‚Äôs also a third‚Äêparty module named `wget` (a Python wrapper, not to be confused with the command line tool) that offers a very simple interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908ef4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "\n",
    "url = \"http://example.com/file.zip\"\n",
    "filename = wget.download(url)\n",
    "print(\"Downloaded file to:\", filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae02a7ad",
   "metadata": {},
   "source": [
    "This can be handy when you want a one-liner that mimics the familiar Unix tool.  \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Conditional Download (Based on File Age)\n",
    "\n",
    "Sometimes you want to download a file only if it‚Äôs missing or older than a given age. For example, to download a CSV file if it‚Äôs older than one day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa04191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import os\n",
    "import time\n",
    "\n",
    "url = 'http://example.com/data.csv'\n",
    "local_file = 'data.csv'\n",
    "# Download if file doesn't exist or is older than 24 hours (86400 seconds)\n",
    "if not os.path.exists(local_file) or (os.path.getmtime(local_file) < time.time() - 86400):\n",
    "    urllib.request.urlretrieve(url, local_file)\n",
    "    print(\"Updated data.csv\")\n",
    "else:\n",
    "    print(\"data.csv is up-to-date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435ebc81",
   "metadata": {},
   "source": [
    "This pattern is popular in automating daily report updates.  \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Downloading Large Files with‚ÄØ`requests`‚ÄØand Streaming\n",
    "\n",
    "When downloading large files, it‚Äôs best to stream the response in chunks. This approach uses the‚ÄØ`requests`‚ÄØlibrary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf410cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://example.com/largefile.zip\"\n",
    "local_filename = \"largefile.zip\"\n",
    "with requests.get(url, stream=True) as r:\n",
    "    r.raise_for_status()\n",
    "    with open(local_filename, 'wb') as f:\n",
    "        for chunk in r.iter_content(chunk_size=8192):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "print(\"Large file downloaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3dd9b2",
   "metadata": {},
   "source": [
    "Using streaming helps avoid high memory usage with large downloads.  \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Automating Downloads via Selenium\n",
    "\n",
    "For sites that require a login or button clicks (for instance, downloading a report from a secure portal), Selenium can be used to simulate user actions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8b142b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "driver = webdriver.Chrome()  # Assumes chromedriver is installed and in PATH\n",
    "driver.get(\"http://example.com/login\")\n",
    "# Fill in login form\n",
    "driver.find_element(By.ID, \"username\").send_keys(\"myusername\")\n",
    "driver.find_element(By.ID, \"password\").send_keys(\"mypassword\" + Keys.RETURN)\n",
    "time.sleep(3)  # Wait for login to complete\n",
    "# Navigate to download page and click the download button\n",
    "driver.get(\"http://example.com/download\")\n",
    "driver.find_element(By.ID, \"downloadButton\").click()\n",
    "time.sleep(5)  # Wait for download to start/complete\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4530c201",
   "metadata": {},
   "source": [
    "This method is frequently mentioned in discussions where users automate downloading reports or files from platforms that don‚Äôt offer direct URL-based downloads.  \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Downloading Videos Using‚ÄØ`youtube_dl`\n",
    "\n",
    "For media files (especially videos from platforms like YouTube), many developers rely on the popular tool‚ÄØ`youtube_dl`‚ÄØ(which now has forks such as `yt-dlp`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6f8c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import youtube_dl\n",
    "\n",
    "ydl_opts = {}\n",
    "with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
    "    ydl.download(['https://www.youtube.com/watch?v=EXAMPLE_ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1908d72a",
   "metadata": {},
   "source": [
    "This snippet automatically downloads the video file using the robust features of the youtube_dl ecosystem.  \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 7. Invoking the Command-line‚ÄØ`wget`‚ÄØfrom Python\n",
    "\n",
    "Sometimes you want to leverage the battle-tested command-line utility wget (especially for features like resuming downloads). You can invoke it via Python‚Äôs subprocess module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08848b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "url = \"http://example.com/file.zip\"\n",
    "# The \"-c\" flag allows resuming an interrupted download.\n",
    "subprocess.run([\"wget\", \"-c\", url])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf7258f",
   "metadata": {},
   "source": [
    "This is useful when you‚Äôre comfortable with wget‚Äôs features and want to combine them with your Python workflow.  \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 8. Concurrent Downloads Using‚ÄØ`aiohttp`‚ÄØand‚ÄØ`asyncio`\n",
    "\n",
    "For scenarios where you need to download many files at once, asynchronous code with‚ÄØ`aiohttp`‚ÄØcan dramatically speed things up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b1ea44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "\n",
    "async def download_file(session, url, filename):\n",
    "    async with session.get(url) as resp:\n",
    "        with open(filename, 'wb') as f:\n",
    "            while True:\n",
    "                chunk = await resp.content.read(1024)\n",
    "                if not chunk:\n",
    "                    break\n",
    "                f.write(chunk)\n",
    "    print(f\"Downloaded {filename}\")\n",
    "\n",
    "async def main():\n",
    "    files = [\n",
    "        (\"http://example.com/file1.zip\", \"file1.zip\"),\n",
    "        (\"http://example.com/file2.zip\", \"file2.zip\"),\n",
    "        # Add more (url, filename) tuples as needed.\n",
    "    ]\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [download_file(session, url, fname) for url, fname in files]\n",
    "        await asyncio.gather(*tasks)\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aca6ff9",
   "metadata": {},
   "source": [
    "This approach uses asynchronous programming to start multiple downloads concurrently, which is ideal when processing many files in bulk.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec42cbdc",
   "metadata": {},
   "source": [
    "# Example for Organizing Downloads Folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24f9e9c",
   "metadata": {},
   "source": [
    "**Prompt to ChatGPT (GPT-4o)**\n",
    "```\n",
    "Write a Python script that organizes files in my 'Downloads' folder by moving them into subfolders based on their file type (e.g., PDFs to a 'PDFs' folder, images to an 'Images' folder, etc.). The script should create folders if they don‚Äôt exist.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be87676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from collections import defaultdict\n",
    "\n",
    "# Define the downloads directory\n",
    "DOWNLOADS_DIR = os.path.expanduser(\"~/Downloads\")\n",
    "\n",
    "# Define file type categories\n",
    "FILE_CATEGORIES = {\n",
    "    \"Images\": [\".jpg\", \".jpeg\", \".png\", \".gif\", \".bmp\", \".svg\", \".tiff\"],\n",
    "    \"Documents\": [\".pdf\", \".doc\", \".docx\", \".txt\", \".odt\", \".rtf\", \".tex\"],\n",
    "    \"Spreadsheets\": [\".xls\", \".xlsx\", \".csv\", \".ods\"],\n",
    "    \"Presentations\": [\".ppt\", \".pptx\", \".key\"],\n",
    "    \"Archives\": [\".zip\", \".rar\", \".tar\", \".gz\", \".7z\"],\n",
    "    \"Executables\": [\".exe\", \".dmg\", \".pkg\", \".app\"],\n",
    "    \"Videos\": [\".mp4\", \".mkv\", \".mov\", \".avi\", \".flv\", \".wmv\"],\n",
    "    \"Music\": [\".mp3\", \".wav\", \".flac\", \".aac\", \".ogg\", \".m4a\"],\n",
    "    \"Code\": [\".py\", \".js\", \".html\", \".css\", \".java\", \".c\", \".cpp\", \".go\", \".sh\", \".ipynb\"]\n",
    "}\n",
    "\n",
    "# Reverse the dictionary to map file extensions to their respective categories\n",
    "EXTENSION_TO_CATEGORY = {ext: category for category, exts in FILE_CATEGORIES.items() for ext in exts}\n",
    "\n",
    "# Ensure categorized folders exist\n",
    "def create_folders():\n",
    "    for folder in FILE_CATEGORIES.keys():\n",
    "        folder_path = os.path.join(DOWNLOADS_DIR, folder)\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "\n",
    "# Organize files\n",
    "def organize_downloads():\n",
    "    create_folders()\n",
    "    \n",
    "    for filename in os.listdir(DOWNLOADS_DIR):\n",
    "        file_path = os.path.join(DOWNLOADS_DIR, filename)\n",
    "        \n",
    "        # Skip directories\n",
    "        if os.path.isdir(file_path):\n",
    "            continue\n",
    "        \n",
    "        # Get the file extension\n",
    "        _, ext = os.path.splitext(filename)\n",
    "        ext = ext.lower()\n",
    "        \n",
    "        # Determine the category\n",
    "        category = EXTENSION_TO_CATEGORY.get(ext, \"Other\")\n",
    "        \n",
    "        # Create 'Other' folder if needed\n",
    "        target_folder = os.path.join(DOWNLOADS_DIR, category)\n",
    "        if not os.path.exists(target_folder):\n",
    "            os.makedirs(target_folder)\n",
    "        \n",
    "        # Move the file\n",
    "        shutil.move(file_path, os.path.join(target_folder, filename))\n",
    "        print(f\"Moved: {filename} -> {category}/\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    organize_downloads()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-automate-tasks",
   "language": "python",
   "name": "oreilly-automate-tasks"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}


---
./notebooks/01-python-fundamentals/01-data-types-and-operators.ipynb
---
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a919f203",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Python Basics: Data Types and Operations\n",
    "\n",
    "In this lesson, we'll explore Python's fundamental data types and the operations we can perform with them. We'll learn about integers, floats, strings, and basic arithmetic operations, as well as some special operations that make Python unique.\n",
    "\n",
    "## Basic Data Types\n",
    "\n",
    "Let's start by exploring different data types in Python using the `type()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec73d23a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n",
      "<class 'float'>\n",
      "<class 'str'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# Let's check some basic data types\n",
    "print(type(42))        # integer\n",
    "print(type(3.14159))   # float\n",
    "print(type(\"Hello\"))   # string\n",
    "print(type([1,2,3]))   # list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54e0b00",
   "metadata": {},
   "source": [
    "## Arithmetic Operations\n",
    "\n",
    "Python supports all standard arithmetic operations. Let's explore them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46e2fc7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "20\n",
      "48\n",
      "20.0\n",
      "2\n",
      "3\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# Basic arithmetic\n",
    "print(25 + 15)    # Addition: 40\n",
    "print(50 - 30)    # Subtraction: 20\n",
    "print(8 * 6)      # Multiplication: 48\n",
    "print(100 / 5)    # Division: 20.0\n",
    "\n",
    "# Special operations\n",
    "print(17 % 5)     # Modulus (remainder): 2\n",
    "print(17 // 5)    # Floor division: 3\n",
    "print(2 ** 3)     # Exponentiation: 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1114fd8f",
   "metadata": {},
   "source": [
    "## String Operations\n",
    "\n",
    "Strings have their own set of operations that are different from numerical operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3020f25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n",
      "Python! Python! Python! \n",
      "Error: can only concatenate str (not \"int\") to str\n",
      "Error: unsupported operand type(s) for -: 'str' and 'str'\n"
     ]
    }
   ],
   "source": [
    "# String concatenation\n",
    "print(\"Hello\" + \" \" + \"World\")    # Works!\n",
    "\n",
    "# String multiplication\n",
    "print(\"Python! \" * 3)             # Repeats the string 3 times\n",
    "\n",
    "# These operations will cause errors:\n",
    "try:\n",
    "    print(\"Python\" + 3)           # TypeError\n",
    "except TypeError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "try:\n",
    "    print(\"Python\" - \"hon\")       # TypeError\n",
    "except TypeError as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99df94ba",
   "metadata": {},
   "source": [
    "## String Formatting with F-strings\n",
    "\n",
    "F-strings provide an elegant way to format strings with variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5850f217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lucas'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variable_lucas = \"Lucas\"\n",
    "\n",
    "variable_lucas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3116ccc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distance to Mars is approximately 225.0 million kilometers\n"
     ]
    }
   ],
   "source": [
    "# Using f-strings for dynamic string creation\n",
    "planet = \"Mars\"\n",
    "distance = 225.0\n",
    "message = f\"The distance to {planet} is approximately {distance} million kilometers\"\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fba83df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Python is a:\n",
      "1. High-level\n",
      "2. Interpreted\n",
      "3. Dynamic\n",
      "programming language\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multiple line strings using triple quotes\n",
    "description = \"\"\"\n",
    "Python is a:\n",
    "1. High-level\n",
    "2. Interpreted\n",
    "3. Dynamic\n",
    "programming language\n",
    "\"\"\"\n",
    "print(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0b2ee6",
   "metadata": {},
   "source": [
    "## Type Conversions\n",
    "\n",
    "Sometimes we need to convert between different types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03cfc54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String: 42, type: <class 'str'>\n",
      "Integer: 42, type: <class 'int'>\n",
      "Float: 42.0, type: <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "# Converting between different types\n",
    "number_str = \"42\"\n",
    "number_int = int(number_str)\n",
    "number_float = float(number_str)\n",
    "\n",
    "print(f\"String: {number_str}, type: {type(number_str)}\")\n",
    "print(f\"Integer: {number_int}, type: {type(number_int)}\")\n",
    "print(f\"Float: {number_float}, type: {type(number_float)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6517f01",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Here's a small exercise to practice what we've learned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07a9bc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtraction: -10\n",
      "Multiplication: 200\n",
      "Division: 0.5\n",
      "Modulus: 10\n",
      "Floor Division: 0\n",
      "Exponentiation: 100\n"
     ]
    }
   ],
   "source": [
    "# Create a script that calculates the multiple operations with different numbers\n",
    "a = 10\n",
    "b = 20\n",
    "\n",
    "print(f\"Subtraction: {a - b}\")\n",
    "print(f\"Multiplication: {a * b}\")\n",
    "print(f\"Division: {a / b}\")\n",
    "print(f\"Modulus: {a % b}\")\n",
    "print(f\"Floor Division: {a // b}\")\n",
    "print(f\"Exponentiation: {a ** 2}\")  # Square of first number\n",
    "\n",
    "# Try it out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb81ade",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "- Python has several basic data types: integers (`int`), floating-point numbers (`float`), strings (`str`), and more\n",
    "- The `type()` function helps you identify the type of any value\n",
    "- Different data types support different operations\n",
    "- Arithmetic operations work on numbers (integers and floats)\n",
    "- String operations include concatenation (`+`) and repetition (`*`)\n",
    "- F-strings provide an easy way to create formatted strings\n",
    "- Type errors occur when trying to perform operations between incompatible types\n",
    "- Triple quotes (`\"\"\"`) allow for multi-line strings\n",
    "\n",
    "In the next lesson, we'll explore more complex data structures and control flow in Python!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-automate-tasks",
   "language": "python",
   "name": "oreilly-automate-tasks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}


---
./notebooks/01-python-fundamentals/02-variables.ipynb
---
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27f6a19a",
   "metadata": {},
   "source": [
    "# Python Basics: Understanding Variables\n",
    "\n",
    "In this lesson, we'll explore Python variables - what they are, how to use them, and how they can make our code more dynamic and powerful.\n",
    "\n",
    "## What is a Variable?\n",
    "\n",
    "A variable in Python is a container that holds data. Think of it like a labeled box where you can store different types of information and retrieve it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be302460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, Python!\n"
     ]
    }
   ],
   "source": [
    "# Creating our first variable\n",
    "message = \"Hello, Python!\"\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47930dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number: 42\n",
      "Decimal: 3.14\n",
      "Text: Programming is fun\n"
     ]
    }
   ],
   "source": [
    "# Variables can store different types of data\n",
    "number = 42\n",
    "decimal = 3.14\n",
    "text = \"Programming is fun\"\n",
    "\n",
    "print(f\"Number: {number}\")\n",
    "print(f\"Decimal: {decimal}\")\n",
    "print(f\"Text: {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346bba72",
   "metadata": {},
   "source": [
    "## Working with Variables\n",
    "\n",
    "Once we have variables, we can perform operations with them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5da2346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum: 40\n",
      "Difference: 10\n",
      "Product: 375\n"
     ]
    }
   ],
   "source": [
    "# Mathematical operations\n",
    "first_number = 25\n",
    "second_number = 15\n",
    "\n",
    "sum_result = first_number + second_number\n",
    "difference = first_number - second_number\n",
    "product = first_number * second_number\n",
    "\n",
    "print(f\"Sum: {sum_result}\")\n",
    "print(f\"Difference: {difference}\")\n",
    "print(f\"Product: {product}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1ff821",
   "metadata": {},
   "source": [
    "## String Operations with Variables\n",
    "\n",
    "Variables containing strings can be manipulated in various ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e50ff7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ada Lovelace\n"
     ]
    }
   ],
   "source": [
    "# String concatenation\n",
    "first_name = \"Ada\"\n",
    "last_name = \"Lovelace\"\n",
    "full_name = first_name + \" \" + last_name\n",
    "print(full_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0ab0fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ada Lovelace was a mathematician who lived to be 36 years old\n"
     ]
    }
   ],
   "source": [
    "# Using f-strings for elegant string formatting\n",
    "age = 36\n",
    "profession = \"mathematician\"\n",
    "introduction = f\"{full_name} was a {profession} who lived to be {age} years old\"\n",
    "print(introduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb18e933",
   "metadata": {},
   "source": [
    "## Updating Variables\n",
    "\n",
    "Variables can be updated after they're created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f279424d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial value: 1\n",
      "After adding 1: 2\n",
      "After adding 5 more: 7\n"
     ]
    }
   ],
   "source": [
    "# Changing variable values\n",
    "counter = 1\n",
    "print(f\"Initial value: {counter}\")\n",
    "\n",
    "counter = counter + 1\n",
    "print(f\"After adding 1: {counter}\")\n",
    "\n",
    "counter += 5  # Shorthand for counter = counter + 5\n",
    "print(f\"After adding 5 more: {counter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1de5963c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable is a number: 100\n",
      "Variable is now text: Now I'm a string!\n"
     ]
    }
   ],
   "source": [
    "# You can also completely change the type of data stored\n",
    "variable = 100\n",
    "print(f\"Variable is a number: {variable}\")\n",
    "variable = \"Now I'm a string!\"\n",
    "print(f\"Variable is now text: {variable}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753b2926",
   "metadata": {},
   "source": [
    "## Creating Dynamic Content\n",
    "\n",
    "Variables make our code more flexible and reusable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db16fb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Programming Language: Python\n",
      "Current Version: 3.9\n",
      "Years Since First Release: 30\n",
      "Status: Mature\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating a simple template system\n",
    "language = \"Python\"\n",
    "version = 3.9\n",
    "years_old = 30\n",
    "\n",
    "description = f\"\"\"\n",
    "Programming Language: {language}\n",
    "Current Version: {version}\n",
    "Years Since First Release: {years_old}\n",
    "Status: {'Mature' if years_old >= 20 else 'Young'}\n",
    "\"\"\"\n",
    "\n",
    "print(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9836dbc8",
   "metadata": {},
   "source": [
    "## Practical Example: Personal Information System\n",
    "\n",
    "Here's a practical example that brings together what we've learned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edc39e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Personal Profile ===\n",
      "Name: John\n",
      "Age: 36\n",
      "Skills: Python, Telling bad jokes\n",
      "Experience Level: Senior\n",
      "======================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "name = \"John\"\n",
    "\n",
    "skills = [\"Python\", \"Telling bad jokes\"]\n",
    "\n",
    "profile = f\"\"\"\n",
    "=== Personal Profile ===\n",
    "Name: {name}\n",
    "Age: {age}\n",
    "Skills: {', '.join(skills)}\n",
    "Experience Level: {'Senior' if age >= 30 else 'Junior'}\n",
    "======================\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "print(profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3952b5e7",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "- Variables are containers for storing data in Python\n",
    "- They can hold different types of data (numbers, strings, etc.)\n",
    "- Variables can be updated or changed at any time\n",
    "- F-strings provide an elegant way to include variables in strings\n",
    "- Variables make our code more dynamic and reusable\n",
    "- Meaningful variable names make code easier to understand\n",
    "- Python variables are case-sensitive (`name` is different from `Name`)\n",
    "\n",
    "In the next lesson, we'll explore more complex data structures and how to use them with variables!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-automate-tasks",
   "language": "python",
   "name": "oreilly-automate-tasks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}


---
./notebooks/01-python-fundamentals/03-functions.ipynb
---
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fc07e46",
   "metadata": {},
   "source": [
    "# Python Functions: Building Reusable Code Blocks\n",
    "\n",
    "In this lesson, we'll explore Python functions - both built-in functions and how to create our own. Functions are essential building blocks that help us organize code, make it reusable, and break down complex problems into manageable pieces.\n",
    "\n",
    "## Built-in Functions\n",
    "\n",
    "Python comes with many useful built-in functions. Let's explore some common ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "535f6192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of name: 9\n",
      "Length of number list: 5\n",
      "Pi rounded to 2 decimals: 3.14\n",
      "Pi rounded to whole number: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len() - Calculates the length of sequences\n",
    "name = \"Alexander\"\n",
    "numbers = [1, 2, 3, 4, 5]\n",
    "\n",
    "print(f\"Length of name: {len(name)}\")\n",
    "print(f\"Length of number list: {len(numbers)}\")\n",
    "\n",
    "# round() - Rounds numbers to specified decimals\n",
    "pi = 3.14159\n",
    "print(f\"Pi rounded to 2 decimals: {round(pi, 2)}\")\n",
    "print(f\"Pi rounded to whole number: {round(pi)}\")\n",
    "\n",
    "# abs() - Returns absolute value\n",
    "temperature = -10\n",
    "abs(temperature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55352c65",
   "metadata": {},
   "source": [
    "## Creating Our Own Functions\n",
    "\n",
    "We can create custom functions using the `def` keyword:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fe5252b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good morning, Alice!\n",
      "Good evening, Bob!\n"
     ]
    }
   ],
   "source": [
    "def greet_user(name, time_of_day):\n",
    "    \"\"\"\n",
    "    Creates a personalized greeting based on time of day\n",
    "    \"\"\"\n",
    "    greeting = f\"Good {time_of_day}, {name}!\"\n",
    "    return greeting\n",
    "\n",
    "# Using our function\n",
    "morning_greeting = greet_user(\"Alice\", \"morning\")\n",
    "evening_greeting = greet_user(\"Bob\", \"evening\")\n",
    "\n",
    "print(morning_greeting)\n",
    "print(evening_greeting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b4d97f",
   "metadata": {},
   "source": [
    "## Functions with Multiple Parameters\n",
    "\n",
    "Functions can take multiple parameters and perform complex operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b9ec796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Statistics:\n",
      "Sum: 433\n",
      "Average: 86.6\n",
      "Max: 92\n",
      "Min: 78\n"
     ]
    }
   ],
   "source": [
    "def calculate_statistics(numbers):\n",
    "    \"\"\"\n",
    "    Calculate basic statistics for a list of numbers\n",
    "    \"\"\"\n",
    "    total = sum(numbers)\n",
    "    average = total / len(numbers)\n",
    "    maximum = max(numbers)\n",
    "    minimum = min(numbers)\n",
    "    \n",
    "    return {\n",
    "        \"sum\": total,\n",
    "        \"average\": average,\n",
    "        \"max\": maximum,\n",
    "        \"min\": minimum\n",
    "    }\n",
    "\n",
    "# Using our statistics function\n",
    "scores = [85, 92, 78, 90, 88]\n",
    "stats = calculate_statistics(scores)\n",
    "\n",
    "print(f\"Class Statistics:\")\n",
    "for key, value in stats.items():\n",
    "    print(f\"{key.capitalize()}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbe72b1",
   "metadata": {},
   "source": [
    "## Functions with Default Parameters\n",
    "\n",
    "We can make functions more flexible by providing default values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8133e31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    === Profile ===\n",
      "    Name: Emma\n",
      "    Role: Student\n",
      "    Skills: Learning\n",
      "    =============\n",
      "    \n",
      "\n",
      "    === Profile ===\n",
      "    Name: John\n",
      "    Role: Developer\n",
      "    Skills: Python, JavaScript, SQL\n",
      "    =============\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "def create_profile(name, role=\"Student\", skills=None):\n",
    "    if skills is None:\n",
    "        skills = [\"Learning\"]\n",
    "    \n",
    "    profile = f\"\"\"\n",
    "    === Profile ===\n",
    "    Name: {name}\n",
    "    Role: {role}\n",
    "    Skills: {', '.join(skills)}\n",
    "    =============\n",
    "    \"\"\"\n",
    "    return profile\n",
    "\n",
    "# Using default parameters\n",
    "print(create_profile(\"Emma\"))\n",
    "\n",
    "# Providing all parameters\n",
    "print(create_profile(\"John\", \"Developer\", [\"Python\", \"JavaScript\", \"SQL\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0206990",
   "metadata": {},
   "source": [
    "## Building a Learning Assistant\n",
    "\n",
    "Here's a more complex example that uses functions to create a learning assistant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1808fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study Plan for Python (4 weeks)\n",
      "\n",
      "Week 1: Basics and Data Types\n",
      "Week 2: Control Flow and Functions\n",
      "Week 3: Data Structures\n",
      "Week 4: Object-Oriented Programming\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def create_study_plan(topic, duration_weeks=4):\n",
    "    \"\"\"\n",
    "    Creates a weekly study plan for a given topic\n",
    "    \"\"\"\n",
    "    weekly_topics = {\n",
    "        \"Python\": [\n",
    "            \"Basics and Data Types\",\n",
    "            \"Control Flow and Functions\",\n",
    "            \"Data Structures\",\n",
    "            \"Object-Oriented Programming\"\n",
    "        ],\n",
    "        \"Data Science\": [\n",
    "            \"Data Collection and Cleaning\",\n",
    "            \"Exploratory Data Analysis\",\n",
    "            \"Statistical Methods\",\n",
    "            \"Machine Learning Basics\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    if topic not in weekly_topics:\n",
    "        return \"Topic not found in curriculum\"\n",
    "    \n",
    "    study_plan = f\"Study Plan for {topic} ({duration_weeks} weeks)\\n\\n\"\n",
    "    \n",
    "    for week in range(duration_weeks):\n",
    "        week_topic = weekly_topics[topic][week % len(weekly_topics[topic])]\n",
    "        study_plan += f\"Week {week + 1}: {week_topic}\\n\"\n",
    "    \n",
    "    return study_plan\n",
    "\n",
    "# Create study plans\n",
    "print(create_study_plan(\"Python\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac53739",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "- Functions help organize code and make it reusable\n",
    "- Python has many useful built-in functions like `len()`, `round()`, `print()`\n",
    "- We can create custom functions using the `def` keyword\n",
    "- Functions can take parameters and return values\n",
    "- Default parameters make functions more flexible\n",
    "- Functions should have clear names and documentation\n",
    "- Complex tasks can be broken down into smaller functions\n",
    "- Functions can call other functions\n",
    "\n",
    "In the next lesson, we'll explore Python lists and loops to handle collections of data!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-automate-tasks",
   "language": "python",
   "name": "oreilly-automate-tasks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}


---
./notebooks/01-python-fundamentals/04-lists-and-loops.ipynb
---
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8300f4c0",
   "metadata": {},
   "source": [
    "# Python Lists and Loops: Managing Collections of Data\n",
    "\n",
    "In this lesson, we'll explore Python lists - a fundamental data structure for storing collections of items - and for loops, which help us work with these collections efficiently.\n",
    "\n",
    "## Understanding Lists\n",
    "\n",
    "Lists in Python are ordered collections that can store different types of data. Let's start with some basic examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e306f74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student grades: [('Emma', 95), ('James', 87), ('Sofia', 92), ('Alex', 88), ('Nina', 90)]\n",
      "First student: Emma\n",
      "Last grade: 90\n"
     ]
    }
   ],
   "source": [
    "# Creating simple lists\n",
    "students = [\"Emma\", \"James\", \"Sofia\", \"Alex\", \"Nina\"]\n",
    "grades = [95, 87, 92, 88, 90]\n",
    "\n",
    "# Combining related lists using zip\n",
    "student_grades = list(zip(students, grades))\n",
    "print(\"Student grades:\", student_grades)\n",
    "\n",
    "# Accessing elements\n",
    "print(f\"First student: {students[0]}\")\n",
    "print(f\"Last grade: {grades[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91bde97",
   "metadata": {},
   "source": [
    "## List Operations and Methods\n",
    "\n",
    "Python lists come with many useful methods to manipulate data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdfb2865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['milk', 'butter', 'bread', 'eggs', 'cheese', 'apples', 'bananas']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a shopping list\n",
    "shopping = [\"milk\", \"bread\", \"eggs\"]\n",
    "\n",
    "# Adding items\n",
    "shopping.append(\"cheese\")               # Add single item\n",
    "shopping.extend([\"apples\", \"bananas\"])  # Add multiple items\n",
    "shopping.insert(1, \"butter\")            # Add at specific position\n",
    "\n",
    "shopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c774145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shopping list: ['milk', 'butter', 'bread', 'eggs', 'cheese', 'apples', 'bananas']\n",
      "Updated list: ['butter', 'bread', 'eggs', 'cheese', 'apples']\n"
     ]
    }
   ],
   "source": [
    "print(\"Shopping list:\", shopping)\n",
    "\n",
    "# Removing items\n",
    "removed_item = shopping.pop()           # Remove and return last item\n",
    "shopping.remove(\"milk\")                 # Remove specific item\n",
    "print(\"Updated list:\", shopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2aa171de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted numbers: [1, 2, 3, 5, 8, 9]\n",
      "Reversed numbers: [9, 8, 5, 3, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "# Sorting and reversing\n",
    "numbers = [5, 2, 8, 1, 9, 3]\n",
    "numbers.sort()                          # Sort in place\n",
    "print(\"Sorted numbers:\", numbers)\n",
    "numbers.reverse()                       # Reverse in place\n",
    "print(\"Reversed numbers:\", numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794f93b3",
   "metadata": {},
   "source": [
    "## Working with Mixed Data Types\n",
    "\n",
    "Lists can store different types of data in the same structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa1b5556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Profile:\n",
      "Name: Alice Smith\n",
      "Age: 28\n",
      "Skills: Python, SQL, React\n",
      "Active: True\n",
      "Location: London\n"
     ]
    }
   ],
   "source": [
    "# Creating a user profile using different data types\n",
    "user_profile = [\n",
    "    \"Alice Smith\",                # name (string)\n",
    "    28,                          # age (integer)\n",
    "    [\"Python\", \"SQL\", \"React\"],  # skills (list)\n",
    "    True,                        # is_active (boolean)\n",
    "    {\"city\": \"London\"}           # location (dictionary)\n",
    "]\n",
    "\n",
    "print(\"User Profile:\")\n",
    "print(f\"Name: {user_profile[0]}\")\n",
    "print(f\"Age: {user_profile[1]}\")\n",
    "print(f\"Skills: {', '.join(user_profile[2])}\")\n",
    "print(f\"Active: {user_profile[3]}\")\n",
    "print(f\"Location: {user_profile[4]['city']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e2145f",
   "metadata": {},
   "source": [
    "## Introduction to For Loops\n",
    "\n",
    "For loops allow us to iterate through lists and perform operations on each element:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ecf9aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task Tracker:\n",
      "1. [ ] Review Python basics\n",
      "2. [ ] Complete coding exercises\n",
      "3. [ ] Write documentation\n",
      "4. [ ] Debug application\n",
      "5. [ ] Submit project\n"
     ]
    }
   ],
   "source": [
    "# Basic for loop with a task list\n",
    "tasks = [\n",
    "    \"Review Python basics\",\n",
    "    \"Complete coding exercises\",\n",
    "    \"Write documentation\",\n",
    "    \"Debug application\",\n",
    "    \"Submit project\"\n",
    "]\n",
    "\n",
    "print(\"Task Tracker:\")\n",
    "for index, task in enumerate(tasks, 1):\n",
    "    print(f\"{index}. [ ] {task}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9ded5d",
   "metadata": {},
   "source": [
    "## Practical Example: Project Management System\n",
    "\n",
    "Let's combine lists and loops to create a simple project management system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfd339b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Project Dashboard ===\n",
      "\n",
      "Project: Website Redesign\n",
      "Status: In Progress\n",
      "Deadline: 2024-03-15\n",
      "Team Members: Alice, Bob, Charlie\n",
      "--------------------\n",
      "\n",
      "Project: Mobile App\n",
      "Status: Planning\n",
      "Deadline: 2024-06-30\n",
      "Team Members: David, Emma\n",
      "--------------------\n",
      "\n",
      "Project: Database Migration\n",
      "Status: Completed\n",
      "Deadline: 2024-01-30\n",
      "Team Members: Frank, Grace, Henry\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "def create_project_dashboard(projects):\n",
    "    \"\"\"\n",
    "    Create a formatted project dashboard from a list of project data\n",
    "    \"\"\"\n",
    "    print(\"=== Project Dashboard ===\")\n",
    "    for project in projects:\n",
    "        name, status, deadline, team = project\n",
    "        print(f\"\\nProject: {name}\")\n",
    "        print(f\"Status: {status}\")\n",
    "        print(f\"Deadline: {deadline}\")\n",
    "        print(f\"Team Members: {', '.join(team)}\")\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "# Sample project data\n",
    "projects = [\n",
    "    [\"Website Redesign\", \"In Progress\", \"2024-03-15\", [\"Alice\", \"Bob\", \"Charlie\"]],\n",
    "    [\"Mobile App\", \"Planning\", \"2024-06-30\", [\"David\", \"Emma\"]],\n",
    "    [\"Database Migration\", \"Completed\", \"2024-01-30\", [\"Frank\", \"Grace\", \"Henry\"]]\n",
    "]\n",
    "\n",
    "create_project_dashboard(projects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5e8ba1",
   "metadata": {},
   "source": [
    "## Advanced List Comprehensions\n",
    "\n",
    "List comprehensions provide a concise way to create lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a5ee733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature Conversion:\n",
      "0¬∞C = 32.0¬∞F\n",
      "10¬∞C = 50.0¬∞F\n",
      "20¬∞C = 68.0¬∞F\n",
      "30¬∞C = 86.0¬∞F\n",
      "40¬∞C = 104.0¬∞F\n",
      "\n",
      "Even numbers: [2, 4, 6, 8, 10]\n"
     ]
    }
   ],
   "source": [
    "# Converting temperatures from Celsius to Fahrenheit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f812e51c",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "- Lists are versatile data structures that can store any type of data\n",
    "- List methods like append(), extend(), remove() help manage list contents\n",
    "- Lists are mutable, meaning they can be modified after creation\n",
    "- For loops provide a way to iterate through lists\n",
    "- List comprehensions offer a concise way to create and transform lists\n",
    "- Python's zip() function helps work with multiple related lists\n",
    "- Lists can be nested to create more complex data structures\n",
    "\n",
    "In the next lesson, we'll explore dictionaries and how they complement lists in Python!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-automate-tasks",
   "language": "python",
   "name": "oreilly-automate-tasks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}


---
./notebooks/01-python-fundamentals/05-dictionaries.ipynb
---
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75ea1605",
   "metadata": {},
   "source": [
    "# Python Dictionaries: Managing Key-Value Data\n",
    "\n",
    "In this lesson, we'll explore Python dictionaries - a powerful data structure for storing and managing key-value pairs. We'll learn how to create, manipulate, and use dictionaries effectively in various programming scenarios.\n",
    "\n",
    "## Basic Dictionary Operations\n",
    "\n",
    "Let's start with creating and accessing dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d46984c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice's number: 555-0101\n",
      "Bob's number: 555-0202\n",
      "Eve's number: Not found\n"
     ]
    }
   ],
   "source": [
    "# Creating a simple contact dictionary\n",
    "contacts = {\n",
    "    \"Alice\": \"555-0101\",\n",
    "    \"Bob\": \"555-0202\",\n",
    "    \"Charlie\": \"555-0303\",\n",
    "    \"Diana\": \"555-0404\"\n",
    "}\n",
    "\n",
    "# Accessing values\n",
    "print(f\"Alice's number: {contacts['Alice']}\")\n",
    "print(f\"Bob's number: {contacts.get('Bob')}\")\n",
    "# Using get() with default value for safety\n",
    "print(f\"Eve's number: {contacts.get('Eve', 'Not found')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d9aa57",
   "metadata": {},
   "source": [
    "## Essential Dictionary Methods\n",
    "\n",
    "Here's how to use common dictionary methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63e78013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available fruits: ['apples', 'bananas', 'oranges']\n",
      "Quantities: [50, 30, 25]\n",
      "\n",
      "Current inventory:\n",
      "apples: 50\n",
      "bananas: 30\n",
      "oranges: 25\n",
      "\n",
      "Removed 30 bananas\n",
      "\n",
      "Final inventory: {'apples': 45, 'oranges': 25, 'grapes': 40}\n"
     ]
    }
   ],
   "source": [
    "def demonstrate_dictionary_methods():\n",
    "    inventory = {\n",
    "        \"apples\": 50,\n",
    "        \"bananas\": 30,\n",
    "        \"oranges\": 25\n",
    "    }\n",
    "    \n",
    "    # Getting all keys\n",
    "    print(\"Available fruits:\", list(inventory.keys()))\n",
    "    \n",
    "    # Getting all values\n",
    "    print(\"Quantities:\", list(inventory.values()))\n",
    "    \n",
    "    # Getting key-value pairs\n",
    "    print(\"\\nCurrent inventory:\")\n",
    "    for fruit, quantity in inventory.items():\n",
    "        print(f\"{fruit}: {quantity}\")\n",
    "    \n",
    "    # Adding/updating items\n",
    "    inventory.update({\n",
    "        \"apples\": 45,  # Update existing\n",
    "        \"grapes\": 40   # Add new\n",
    "    })\n",
    "    \n",
    "    # Removing items\n",
    "    removed_quantity = inventory.pop(\"bananas\")\n",
    "    print(f\"\\nRemoved {removed_quantity} bananas\")\n",
    "    \n",
    "    return inventory\n",
    "\n",
    "updated_inventory = demonstrate_dictionary_methods()\n",
    "print(\"\\nFinal inventory:\", updated_inventory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fadc5b",
   "metadata": {},
   "source": [
    "## Nested Dictionaries\n",
    "\n",
    "Dictionaries can contain complex data structures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01ab69b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Profile Summary:\n",
      "Name: Sarah Wilson\n",
      "Title: Software Engineer\n",
      "Skills: Python, JavaScript, Docker\n",
      "Settings: {'theme': 'dark', 'notifications': True, 'language': 'English'}\n"
     ]
    }
   ],
   "source": [
    "# Creating a nested user profile\n",
    "user_profile = {\n",
    "    \"personal_info\": {\n",
    "        \"name\": \"Sarah Wilson\",\n",
    "        \"age\": 28,\n",
    "        \"location\": \"Seattle\"\n",
    "    },\n",
    "    \"professional_info\": {\n",
    "        \"title\": \"Software Engineer\",\n",
    "        \"skills\": [\"Python\", \"JavaScript\", \"Docker\"],\n",
    "        \"experience_years\": 5\n",
    "    },\n",
    "    \"preferences\": {\n",
    "        \"theme\": \"dark\",\n",
    "        \"notifications\": True,\n",
    "        \"language\": \"English\"\n",
    "    }\n",
    "}\n",
    "\n",
    "def display_profile(profile):\n",
    "    print(\"User Profile Summary:\")\n",
    "    print(f\"Name: {profile['personal_info']['name']}\")\n",
    "    print(f\"Title: {profile['professional_info']['title']}\")\n",
    "    print(f\"Skills: {', '.join(profile['professional_info']['skills'])}\")\n",
    "    print(f\"Settings: {profile['preferences']}\")\n",
    "\n",
    "display_profile(user_profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860df672",
   "metadata": {},
   "source": [
    "## Practical Example: Task Management System\n",
    "\n",
    "Let's create a more complex example using dictionaries for task management:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3f3049",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskManager:\n",
    "    def __init__(self):\n",
    "        self.tasks = {}\n",
    "    \n",
    "    def add_task(self, task_id, description, priority=\"medium\", status=\"pending\"):\n",
    "        self.tasks[task_id] = {\n",
    "            \"description\": description,\n",
    "            \"priority\": priority,\n",
    "            \"status\": status,\n",
    "            \"created_at\": datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "        }\n",
    "    \n",
    "    def update_status(self, task_id, status):\n",
    "        if task_id in self.tasks:\n",
    "            self.tasks[task_id][\"status\"] = status\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def get_tasks_by_priority(self, priority):\n",
    "        return {\n",
    "            task_id: task for task_id, task in self.tasks.items()\n",
    "            if task[\"priority\"] == priority\n",
    "        }\n",
    "    \n",
    "    def display_tasks(self):\n",
    "        for task_id, task in self.tasks.items():\n",
    "            print(f\"\\nTask {task_id}:\")\n",
    "            for key, value in task.items():\n",
    "                print(f\"  {key}: {value}\")\n",
    "\n",
    "# Example usage\n",
    "manager = TaskManager()\n",
    "manager.add_task(1, \"Complete project proposal\", \"high\")\n",
    "manager.add_task(2, \"Review code changes\", \"medium\")\n",
    "manager.add_task(3, \"Update documentation\", \"low\")\n",
    "manager.display_tasks()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c8fece",
   "metadata": {},
   "source": [
    "## Dictionary Comprehensions\n",
    "\n",
    "Here's how to create dictionaries using comprehensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09ef6004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "for num in range(1,6):\n",
    "    print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8755451c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Square numbers: {1: 1, 2: 4, 3: 9, 4: 16, 5: 25}\n"
     ]
    }
   ],
   "source": [
    "# Creating a square numbers dictionary\n",
    "squares = {num: num**2 for num in range(1, 6)}\n",
    "print(\"Square numbers:\", squares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9d3c250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top scorers: {'Alice': 95, 'Diana': 95}\n"
     ]
    }
   ],
   "source": [
    "# Filtering with dictionary comprehension\n",
    "scores = {\"Alice\": 95, \"Bob\": 82, \"Charlie\": 88, \"Diana\": 95}\n",
    "top_scores = {name: score for name, score in scores.items() if score >= 90}\n",
    "print(\"\\nTop scorers:\", top_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e405d244",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "- Dictionaries store key-value pairs for efficient data organization\n",
    "- Keys must be immutable (strings, numbers, tuples)\n",
    "- Common methods include:\n",
    "  - `keys()`, `values()`, `items()` for accessing elements\n",
    "  - `get()` for safe value retrieval\n",
    "  - `update()` for adding/modifying entries\n",
    "  - `pop()` for removing entries\n",
    "- Nested dictionaries can store complex data structures\n",
    "- Dictionary comprehensions provide concise creation syntax\n",
    "- Always use `get()` method when key existence is uncertain\n",
    "- Dictionaries are mutable and can be modified after creation\n",
    "\n",
    "In the next lesson, we'll explore how to combine dictionaries with other Python data structures for more complex applications!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-automate-tasks",
   "language": "python",
   "name": "oreilly-automate-tasks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}


---
./notebooks/01-python-fundamentals/06-comparators.ipynb
---
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acd0f8ed",
   "metadata": {},
   "source": [
    "# Python Comparisons and Logic: Making Decisions in Code\n",
    "\n",
    "In this lesson, we'll explore how Python handles logical operations and comparisons. We'll learn about boolean values, comparison operators, and how to combine conditions to make complex decisions in our code.\n",
    "\n",
    "## Boolean Values: True and False\n",
    "\n",
    "Let's start with the basics of boolean values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61f9a494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of boolean: <class 'bool'>\n",
      "Is Python fun? True\n",
      "Is coding hard? False\n"
     ]
    }
   ],
   "source": [
    "# Booleans are Python's way of representing True and False\n",
    "is_python_fun = True\n",
    "is_coding_hard = False\n",
    "\n",
    "print(f\"Type of boolean: {type(is_python_fun)}\")\n",
    "print(f\"Is Python fun? {is_python_fun}\")\n",
    "print(f\"Is coding hard? {is_coding_hard}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f14f22a",
   "metadata": {},
   "source": [
    "## Comparison Operators\n",
    "\n",
    "Python provides several operators for comparing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "897cd537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at various comparisons\n",
    "score = 85\n",
    "passing_grade = 70\n",
    "perfect_score = 100\n",
    "\n",
    "# Greater than and less than\n",
    "is_passing = score > passing_grade\n",
    "\n",
    "is_passing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da0239e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_perfect = score >= perfect_score\n",
    "\n",
    "is_perfect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03a9a9c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Equality comparisons\n",
    "is_exactly_passing = score == passing_grade  # Equality check\n",
    "\n",
    "is_exactly_passing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e4e2aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "has_improved = score != passing_grade        # Inequality check\n",
    "\n",
    "has_improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11ddcab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did I pass? True\n",
      "Did I get perfect? False\n",
      "Did I just barely pass? False\n",
      "Did I do better than passing? True\n"
     ]
    }
   ],
   "source": [
    "print(f\"Did I pass? {is_passing}\")\n",
    "print(f\"Did I get perfect? {is_perfect}\")\n",
    "print(f\"Did I just barely pass? {is_exactly_passing}\")\n",
    "print(f\"Did I do better than passing? {has_improved}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1b38af",
   "metadata": {},
   "source": [
    "## Creating Complex Conditions\n",
    "\n",
    "We can combine conditions using `and` and `or`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21320005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "True and True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cba71c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "True or False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25aa1e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "False or False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab5057a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "True and False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13d55b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study Session Analysis:\n",
      "should_study: True\n",
      "time_is_good: True\n",
      "energy_is_good: True\n"
     ]
    }
   ],
   "source": [
    "def check_study_conditions(time_of_day, energy_level, is_weekend):\n",
    "    \"\"\"\n",
    "    Determine if it's a good time to study based on multiple factors\n",
    "    \"\"\"\n",
    "    # Check if it's an optimal time (between 9 AM and 8 PM)\n",
    "    good_time = time_of_day >= 9 and time_of_day <= 20\n",
    "    \n",
    "    # Check if energy levels are sufficient (scale of 1-10)\n",
    "    good_energy = energy_level >= 6\n",
    "    \n",
    "    # Determine if we should study\n",
    "    should_study = (good_time and good_energy) or is_weekend\n",
    "    \n",
    "    return {\n",
    "        \"should_study\": should_study,\n",
    "        \"time_is_good\": good_time,\n",
    "        \"energy_is_good\": good_energy\n",
    "    }\n",
    "\n",
    "# Test the function\n",
    "result = check_study_conditions(time_of_day=14, energy_level=8, is_weekend=False)\n",
    "print(\"Study Session Analysis:\")\n",
    "for condition, value in result.items():\n",
    "    print(f\"{condition}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5383961a",
   "metadata": {},
   "source": [
    "## Practical Example: Task Priority System\n",
    "\n",
    "Here's a more complex example using comparisons and logic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2682ba01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task Analysis:\n",
      "\n",
      "Task: Client Presentation\n",
      "Priority: Critical\n",
      "Immediate Action: True\n",
      "Can Delegate: False\n",
      "\n",
      "Task: Email Responses\n",
      "Priority: High\n",
      "Immediate Action: False\n",
      "Can Delegate: False\n",
      "\n",
      "Task: Code Review\n",
      "Priority: Medium\n",
      "Immediate Action: False\n",
      "Can Delegate: False\n"
     ]
    }
   ],
   "source": [
    "def analyze_task(task_name, deadline_days, estimated_hours, importance):\n",
    "    \"\"\"\n",
    "    Analyze a task and determine its priority level and handling strategy\n",
    "    \"\"\"\n",
    "    is_urgent = deadline_days <= 3\n",
    "    is_big_task = estimated_hours > 4\n",
    "    is_important = importance >= 8  # Scale of 1-10\n",
    "    \n",
    "    # Determine priority level\n",
    "    if is_urgent and is_important:\n",
    "        priority = \"Critical\"\n",
    "    elif is_urgent or (is_important and is_big_task):\n",
    "        priority = \"High\"\n",
    "    elif is_important:\n",
    "        priority = \"Medium\"\n",
    "    else:\n",
    "        priority = \"Low\"\n",
    "    \n",
    "    # Determine handling strategy\n",
    "    needs_immediate_action = is_urgent and (is_important or is_big_task)\n",
    "    can_delegate = not is_important and is_big_task\n",
    "    \n",
    "    return {\n",
    "        \"task\": task_name,\n",
    "        \"priority\": priority,\n",
    "        \"needs_immediate_action\": needs_immediate_action,\n",
    "        \"can_delegate\": can_delegate\n",
    "    }\n",
    "\n",
    "# Test the system with different tasks\n",
    "tasks = [\n",
    "    {\"name\": \"Client Presentation\", \"deadline\": 2, \"hours\": 6, \"importance\": 9},\n",
    "    {\"name\": \"Email Responses\", \"deadline\": 1, \"hours\": 2, \"importance\": 5},\n",
    "    {\"name\": \"Code Review\", \"deadline\": 5, \"hours\": 3, \"importance\": 8}\n",
    "]\n",
    "\n",
    "print(\"Task Analysis:\")\n",
    "for task in tasks:\n",
    "    result = analyze_task(task[\"name\"], task[\"deadline\"], \n",
    "                         task[\"hours\"], task[\"importance\"])\n",
    "    print(f\"\\nTask: {result['task']}\")\n",
    "    print(f\"Priority: {result['priority']}\")\n",
    "    print(f\"Immediate Action: {result['needs_immediate_action']}\")\n",
    "    print(f\"Can Delegate: {result['can_delegate']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dd4cbd",
   "metadata": {},
   "source": [
    "## Common Pitfalls and Tips\n",
    "\n",
    "Here are some important things to remember:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da140c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the right way to compare!\n",
      "\n",
      "Boolean Operation Results:\n",
      "True and True = True\n",
      "True and False = False\n",
      "True or False = True\n",
      "False or False = False\n"
     ]
    }
   ],
   "source": [
    "# WRONG: Using assignment (=) instead of comparison (==)\n",
    "x = 5\n",
    "y = 5\n",
    "\n",
    "# This is incorrect and will cause an error:\n",
    "# if x = y:\n",
    "#     print(\"This won't work!\")\n",
    "\n",
    "# This is correct:\n",
    "if x == y:\n",
    "    print(\"This is the right way to compare!\")\n",
    "\n",
    "# Be careful with boolean operations\n",
    "print(\"\\nBoolean Operation Results:\")\n",
    "print(f\"True and True = {True and True}\")\n",
    "print(f\"True and False = {True and False}\")\n",
    "print(f\"True or False = {True or False}\")\n",
    "print(f\"False or False = {False or False}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040bfe1a",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "- Boolean values (`True` and `False`) are fundamental for logical operations\n",
    "- Comparison operators (`>`, `<`, `>=`, `<=`, `==`, `!=`) return boolean values\n",
    "- `and` requires both conditions to be `True`\n",
    "- `or` requires at least one condition to be `True`\n",
    "- Use `==` for comparison and `=` for assignment\n",
    "- Complex conditions can be built by combining multiple comparisons\n",
    "- Always consider edge cases when working with logical operations\n",
    "\n",
    "In the next lesson, we'll explore how to use these concepts in if-statements and control flow!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-automate-tasks",
   "language": "python",
   "name": "oreilly-automate-tasks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}


---
./notebooks/01-python-fundamentals/07-conditionals.ipynb
---
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d6e1692",
   "metadata": {},
   "source": [
    "# Python Conditionals and Decision Making\n",
    "\n",
    "## Introduction to Control Flow\n",
    "\n",
    "In programming, we often need to make decisions based on certain conditions. Python provides `if`, `elif`, and `else` statements for this purpose.\n",
    "\n",
    "## Basic If Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87bae65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good morning!\n"
     ]
    }
   ],
   "source": [
    "time_of_day = 10  # 24-hour format\n",
    "\n",
    "if time_of_day < 12:\n",
    "    print(\"Good morning!\")\n",
    "    \n",
    "if time_of_day>10:\n",
    "    print(\"14 is bigger than 10!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c92ecc4",
   "metadata": {},
   "source": [
    "## If-Else Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83c750bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Battery low!\n",
      "Please connect charger\n"
     ]
    }
   ],
   "source": [
    "battery_percentage = 15\n",
    "\n",
    "if battery_percentage < 20:\n",
    "    print(\"Warning: Battery low!\")\n",
    "    print(\"Please connect charger\")\n",
    "else:\n",
    "    print(\"Battery level okay\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f3b23b",
   "metadata": {},
   "source": [
    "## If-Elif-Else Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e6f73f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: File is very small\n",
      "Warning: File is very large\n"
     ]
    }
   ],
   "source": [
    "def check_file_status(file_size_mb):\n",
    "    if file_size_mb == 0:\n",
    "        print(\"Error: File is empty\")\n",
    "    elif file_size_mb < 1:\n",
    "        print(\"Warning: File is very small\")\n",
    "    elif file_size_mb > 1000:\n",
    "        print(\"Warning: File is very large\")\n",
    "    else:\n",
    "        print(\"File size is acceptable\")\n",
    "\n",
    "check_file_status(0.5)\n",
    "check_file_status(1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec66ef73",
   "metadata": {},
   "source": [
    "## Comparison Operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "848be853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Common comparison operators\n",
    "x = 5\n",
    "y = 10\n",
    "\n",
    "print(x == y)  # Equal to\n",
    "print(x != y)  # Not equal to\n",
    "print(x < y)   # Less than\n",
    "print(x > y)   # Greater than\n",
    "print(x <= y)  # Less than or equal to\n",
    "print(x >= y)  # Greater than or equal to"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10212b93",
   "metadata": {},
   "source": [
    "## Logical Operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a916df7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System under heavy load!\n",
      "Consider closing some applications\n",
      "Daily tasks incomplete\n"
     ]
    }
   ],
   "source": [
    "cpu_usage = 85\n",
    "memory_usage = 90\n",
    "\n",
    "if cpu_usage > 80 and memory_usage > 80:\n",
    "    print(\"System under heavy load!\")\n",
    "    print(\"Consider closing some applications\")\n",
    "\n",
    "files_to_process = [\"doc1.txt\", \"doc2.txt\"]\n",
    "backup_done = False\n",
    "\n",
    "if not backup_done or len(files_to_process) > 0:\n",
    "    print(\"Daily tasks incomplete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c275474",
   "metadata": {},
   "source": [
    "## Nested Conditionals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bde7e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing small text file: report.txt\n",
      "Unsupported file type: data.csv\n",
      "Text file too large: video.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_file(filename, size_mb):\n",
    "    if filename.endswith('.txt'):\n",
    "        if size_mb < 1:\n",
    "            print(f\"Processing small text file: {filename}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"Text file too large: {filename}\")\n",
    "            return False\n",
    "    else:\n",
    "        print(f\"Unsupported file type: {filename}\")\n",
    "        return False\n",
    "\n",
    "process_file(\"report.txt\", 0.5)\n",
    "process_file(\"data.csv\", 0.3)\n",
    "process_file(\"video.txt\", 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0720e05b",
   "metadata": {},
   "source": [
    "## Conditional Expressions (Ternary Operator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cac78168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Internet connection: Good\n"
     ]
    }
   ],
   "source": [
    "download_speed = 15  # Mbps\n",
    "\n",
    "connection_status = \"Good\" if download_speed >= 10 else \"Poor\"\n",
    "print(f\"Internet connection: {connection_status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaac4ce",
   "metadata": {},
   "source": [
    "## Checking Multiple Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21799162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: CPU temperature critical!\n",
      "WARNING: Low disk space!\n",
      "INFO: 3 system updates available\n",
      "System status: All good!\n"
     ]
    }
   ],
   "source": [
    "def analyze_system_status(cpu_temp, disk_space, updates_pending):\n",
    "    if cpu_temp >= 80:\n",
    "        print(\"WARNING: CPU temperature critical!\")\n",
    "    \n",
    "    if disk_space < 1000:  # MB\n",
    "        print(\"WARNING: Low disk space!\")\n",
    "    \n",
    "    if updates_pending > 0:\n",
    "        print(f\"INFO: {updates_pending} system updates available\")\n",
    "    \n",
    "    if cpu_temp < 80 and disk_space >= 1000 and updates_pending == 0:\n",
    "        print(\"System status: All good!\")\n",
    "\n",
    "analyze_system_status(85, 500, 3)\n",
    "analyze_system_status(70, 1500, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daf0f9e",
   "metadata": {},
   "source": [
    "## Practice Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c967033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backup needed: More than 24 hours since last backup\n",
      "Backup needed: Large number of files modified\n",
      "Backup needed: Significant data changes\n",
      "No backup needed at this time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def automate_backup(file_count, total_size_mb, last_backup_hours):\n",
    "    \"\"\"\n",
    "    Decide if a backup should be performed based on various conditions\n",
    "    \"\"\"\n",
    "    if last_backup_hours > 24:\n",
    "        print(\"Backup needed: More than 24 hours since last backup\")\n",
    "        return True\n",
    "    elif file_count > 100:\n",
    "        print(\"Backup needed: Large number of files modified\")\n",
    "        return True\n",
    "    elif total_size_mb > 500:\n",
    "        print(\"Backup needed: Significant data changes\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"No backup needed at this time\")\n",
    "        return False\n",
    "\n",
    "# Test cases\n",
    "automate_backup(50, 100, 25)    # More than 24 hours\n",
    "automate_backup(150, 200, 5)    # Many files modified\n",
    "automate_backup(20, 600, 12)    # Large data changes\n",
    "automate_backup(10, 50, 2)      # No backup needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49a07d3",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- Conditionals allow programs to make decisions based on conditions\n",
    "- Basic syntax includes `if`, `elif`, and `else`\n",
    "- Comparison operators: `==`, `!=`, `<`, `>`, `<=`, `>=`\n",
    "- Logical operators: `and`, `or`, `not`\n",
    "- Nested conditionals for complex decision making\n",
    "- Ternary operator for simple conditional expressions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-automate-tasks",
   "language": "python",
   "name": "oreilly-automate-tasks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}


---
./notebooks/01-python-fundamentals/08-working-with-files.ipynb
---
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Files\n",
    "\n",
    "Lesson 11 - txt files python , open read, store contents to file, extract information with LLMs in bullet points to txt file, structure prompts to extract desired data from txt file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python it is extremely simple to work with files like .txt or .md files for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai_tools import ask_ai\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://arxiv.org/pdf/2412.14161\n",
      "\n",
      "The paper titled \"TheAgent Company: Benchmarking LLM Agents on Consequential Real World Tasks\" introduces a new benchmark, TheAgentCompany, aimed at evaluating the efficacy of large language model (LLM)-powered AI agents in completing real-world professional tasks in a simulated software company environment. The research is conducted by a collaborative team, mainly from Carnegie Mellon University and other institutions, and emphasizes the growing presence of AI in work settings.\n",
      "\n",
      "### Key Points from the Paper:\n",
      "\n",
      "1. **Motivation**:\n",
      "   - The rapid advancements in LLMs are prompting questions about AI's potential to automate or assist in various work-related tasks.\n",
      "   - Understanding AI agents‚Äô capabilities is crucial for businesses considering AI integration and for policymakers assessing AI‚Äôs impact on employment.\n",
      "\n",
      "2. **Benchmark Overview**:\n",
      "   - TheAgentCompany simulates a software company environment with 175 diverse professional tasks spanning categories like software engineering, project management, and finance.\n",
      "   - The benchmark allows agents to interact through web browsing, coding, and colleague communication, providing a realistic testing framework.\n",
      "\n",
      "3. **Performance Findings**:\n",
      "   - Experiments conducted with several LLMs, including closed (like OpenAI's GPT-4o and Claude) and open-weight models (like Llama), reveal that the top-performing model, Claude-3.5-Sonnet, achieved 24% task completion autonomously, with a score of 34.4% when accounting for partial completions.\n",
      "   - Despite these advancements, LLM agents struggle significantly with longer, more complex tasks, especially those requiring social interaction and navigation of intricate user interfaces.\n",
      "\n",
      "4. **Framework and Design**:\n",
      "   - TheAgentCompany provides a self-hosted and reproducible environment utilizing open-source software.\n",
      "   - Tasks are structured into parts with defined checkpoints, allowing agents to receive partial credit for incomplete tasks.\n",
      "   - Evaluators for tasks are tailored to assess not just the success of task completion but also the quality of interactions with simulated colleagues.\n",
      "\n",
      "5. **Interaction and Collaboration**:\n",
      "   - A significant component of the benchmark involves the ability of agents to communicate effectively with simulated colleagues within the environment, enhancing the realism and complexity of tasks.\n",
      "\n",
      "6. **Future Directions**:\n",
      "   - The paper suggests that while TheAgentCompany provides a foundational step for understanding LLM capabilities in professional settings, there is a need to expand the tasks covered and include more creative or less straightforward tasks.\n",
      "   - Continuous improvements in LLMs are expected, highlighting their potential for increased efficiency and performance across various domains.\n",
      "\n",
      "7. **Conclusions**:\n",
      "   - The research underscores the current limitations of LLM agents in effectively automating diverse professional tasks.\n",
      "   - The results serve as a litmus test for future developments, pointing towards areas where LLM technology must improve, particularly in tasks involving human-like social interactions and complex decision-making.\n",
      "\n",
      "In summary, TheAgentCompany represents a significant effort to quantify AI agents' performance in real-world applications and to chart a course for further research in this rapidly evolving field.\n",
      "append thisnew data\n"
     ]
    }
   ],
   "source": [
    "# To open a file\n",
    "\n",
    "with open(\"./file.txt\", \"r\") as f:\n",
    "    data = f.read()\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this particular file we read a summary of a paper called: [\"TheAgentCompany: Benchmarking LLM Agents on Clnsequential Real World Tasks\"](https://arxiv.org/pdf/2412.14161)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create files easily in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"This is a file\"\n",
    "with open(\"summary-notes.txt\", \"w\") as f:\n",
    "    f.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a file"
     ]
    }
   ],
   "source": [
    "# in the cmd below we print the contents of an existing file in the current directory\n",
    "!cat ./summary-notes.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are more examples for the different modes of reading and writing files available via the built-in `open()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common file modes in Python's open() function:\n",
    "\n",
    "# \"a\" - Append - Opens file for appending, creates new file if not exists\n",
    "with open(\"summary-notes.txt\", \"a\") as f:\n",
    "    f.write(\"append this\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a fileappend this"
     ]
    }
   ],
   "source": [
    "!cat summary-notes.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: 'file.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# \"x\" - Exclusive creation - Opens for writing, fails if file exists\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfile.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      4\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnew file content\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/oreilly-automate-tasks/lib/python3.11/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'file.txt'"
     ]
    }
   ],
   "source": [
    "# \"x\" - Exclusive creation - Opens for writing, fails if file exists\n",
    "\n",
    "with open(\"file.txt\", \"x\") as f:\n",
    "    f.write(\"new file content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"+\" - Read and write mode\n",
    "with open(\"file.txt\", \"r+\") as f:  # Open for both reading and writing\n",
    "    data = f.read()\n",
    "    f.write(\"new data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cool stuff about being able to do this is that we can connect our ability of generating summaries of information with AI, along with our ability to read and write files in Python to create super powerful workflows.\n",
    "\n",
    "For example, below we will write single sentence summaries for multiple files containing information about different papers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Paper Summaries\n",
       "\n",
       "## Paper 1\n",
       "\n",
       "The paper titled \"TheAgent Company: Benchmarking LLM Agents on Consequential Real World Tasks\" introduces a new benchmark, TheAgentCompany, aimed at evaluating the efficacy of large language model (LLM)-powered AI agents in completing real-world professional tasks in a simulated software company environment. The research is conducted by a collaborative team, mainly from Carnegie Mellon University and other institutions, and emphasizes the growing presence of AI in work settings.\n",
       "\n",
       "### Key Points from the Paper:\n",
       "\n",
       "1. **Motivation**:\n",
       "   - The rapid advancements in LLMs are prompting questions about AI's potential to automate or assist in various work-related tasks.\n",
       "   - Understanding AI agents‚Äô capabilities is crucial for businesses considering AI integration and for policymakers assessing AI‚Äôs impact on employment.\n",
       "\n",
       "2. **Benchmark Overview**:\n",
       "   - TheAgentCompany simulates a software company environment with 175 diverse professional tasks spanning categories like software engineering, project management, and finance.\n",
       "   - The benchmark allows agents to interact through web browsing, coding, and colleague communication, providing a realistic testing framework.\n",
       "\n",
       "3. **Performance Findings**:\n",
       "   - Experiments conducted with several LLMs, including closed (like OpenAI's GPT-4o and Claude) and open-weight models (like Llama), reveal that the top-performing model, Claude-3.5-Sonnet, achieved 24% task completion autonomously, with a score of 34.4% when accounting for partial completions.\n",
       "   - Despite these advancements, LLM agents struggle significantly with longer, more complex tasks, especially those requiring social interaction and navigation of intricate user interfaces.\n",
       "\n",
       "4. **Framework and Design**:\n",
       "   - TheAgentCompany provides a self-hosted and reproducible environment utilizing open-source software.\n",
       "   - Tasks are structured into parts with defined checkpoints, allowing agents to receive partial credit for incomplete tasks.\n",
       "   - Evaluators for tasks are tailored to assess not just the success of task completion but also the quality of interactions with simulated colleagues.\n",
       "\n",
       "5. **Interaction and Collaboration**:\n",
       "   - A significant component of the benchmark involves the ability of agents to communicate effectively with simulated colleagues within the environment, enhancing the realism and complexity of tasks.\n",
       "\n",
       "6. **Future Directions**:\n",
       "   - The paper suggests that while TheAgentCompany provides a foundational step for understanding LLM capabilities in professional settings, there is a need to expand the tasks covered and include more creative or less straightforward tasks.\n",
       "   - Continuous improvements in LLMs are expected, highlighting their potential for increased efficiency and performance across various domains.\n",
       "\n",
       "7. **Conclusions**:\n",
       "   - The research underscores the current limitations of LLM agents in effectively automating diverse professional tasks.\n",
       "   - The results serve as a litmus test for future developments, pointing towards areas where LLM technology must improve, particularly in tasks involving human-like social interactions and complex decision-making.\n",
       "\n",
       "In summary, TheAgentCompany represents a significant effort to quantify AI agents' performance in real-world applications and to chart a course for further research in this rapidly evolving field. The study emphasizes the necessity of enhancing both the complexity of tasks and the agents' social interaction capabilities, urging further exploration into LLM agent performance to better align with real-world professional needs.\n",
       "\n",
       "## Paper 2\n",
       "\n",
       "The paper presents a novel research area called Automated Design of Agentic Systems (ADAS), which aims to automatically create and optimize agentic systems using Foundation Models. The authors introduce an innovative algorithm called Meta Agent Search, wherein a \"meta\" agent is tasked with iteratively designing new agents by leveraging code-based representations. Through extensive experiments across various domains (coding, reading comprehension, math), the results demonstrate that agents developed via this automation significantly outperform state-of-the-art hand-designed agents, showcasing robustness across tasks and the potential for ADAS in advancing artificial intelligence research while highlighting the importance of safety in this burgeoning field.\n",
       "\n",
       "## Paper 3\n",
       "\n",
       "The paper titled \"Who Validates the Validators? Aligning LLM-Assisted Evaluation of LLM Outputs with Human Preferences\" introduces EvalGen, a mixed-initiative system designed to enhance the alignment of evaluation metrics generated by Large Language Models (LLMs) with user preferences during the evaluation of LLM outputs. The authors emphasize the challenges posed by the subjective nature of evaluation and the common phenomenon of \"criteria drift,\" where users refine their criteria based on their experiences grading outputs.\n",
       "\n",
       "EvalGen enables users to generate evaluation criteria and corresponding assertions (either LLM-based or code-based), while also allowing for iterative feedback through user grading. The system utilizes this feedback to select the most aligned assertions, thereby improving the evaluation process. A qualitative study involving industry practitioners highlighted both the positive reception of EvalGen's capabilities and the difficulties posed by criteria drift, indicating that users often need to redefine their evaluation criteria as they interact with outputs.\n",
       "\n",
       "Key findings suggest that criteria are dynamically dependent on the specific outputs being evaluated, and this highlights the necessity for an iterative design in future LLM evaluation assistants. The authors propose directions for designing these tools, emphasizing the importance of accommodating evolving user standards in interactive settings as well as considering the implications of deploying both code-based and LLM-based assertions in practice. The paper ultimately calls into question the notion of fixed evaluation criteria and encourages ongoing adjustment and refinement throughout the evaluation process.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_with_papers = \"./assets-resources/papers/\"\n",
    "file_names = [\"paper1.txt\", \"paper2.txt\", \"paper3.txt\"]\n",
    "\n",
    "def summarize_this_paper(paper_contents):\n",
    "    summary_prompt = f\"Summarize this paper\\n\\n: {paper_contents} in a couple of sentences.\"\n",
    "    output_summary = ask_ai(summary_prompt)\n",
    "    \n",
    "    return output_summary\n",
    "\n",
    "paper_summaries_list = []\n",
    "for file_name in file_names:\n",
    "    file_path = folder_with_papers + file_name\n",
    "    with open(file_path, \"r\") as f:\n",
    "        contents_of_the_paper = f.read()\n",
    "    \n",
    "    paper_summary = summarize_this_paper(contents_of_the_paper)\n",
    "    paper_summaries_list.append(paper_summary)\n",
    "            \n",
    "\n",
    "# Display the markdown content in the notebook\n",
    "    \n",
    "markdown_content = \"# Paper Summaries\\n\\n\"\n",
    "for i, summary in enumerate(paper_summaries_list, 1):\n",
    "    markdown_content += f\"## Paper {i}\\n\\n\"\n",
    "    markdown_content += f\"{summary}\\n\\n\"\n",
    "        \n",
    "Markdown(markdown_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do similar things to extract specific information from documents, imagine you have a bunch of differently formatted invoices from which you would like to organize the information extracting things like the amounts and dates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "- Always use `with` statements when working with files to ensure proper closure\n",
    "- Different file modes serve different purposes:\n",
    "  - `\"r\"` for reading\n",
    "  - `\"w\"` for writing (creates new/overwrites)\n",
    "  - `\"a\"` for appending\n",
    "  - `\"r+\"` for reading and writing\n",
    "- Always handle potential file-related exceptions\n",
    "- File operations can be combined with data processing for powerful automation\n",
    "- Consider creating helper functions for common file operations\n",
    "- Remember to close files properly (using `with` statements)\n",
    "- Be careful with file paths and permissions\n",
    "\n",
    "In the next lesson, we'll explore how to work with different file formats like CSV and JSON!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-automate-tasks",
   "language": "python",
   "name": "oreilly-automate-tasks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}


---
./notebooks/01-python-fundamentals/09-working-with-csv.ipynb
---
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Tabular Data\n",
    "\n",
    "Lesson 12 - CSV files, load, read csv, manipulate within dictionaries stored as elements in a list, filter data based on criteria, leverage LLMs to suggest trip activities using extracted data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's learn about csv files that structure data into rows and columns (tabular data yes!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text files are great but sometimes you need a bit more organization and structure, that's where csv files come into play.\n",
    "\n",
    "Imagine you have a bunch of information about customer tickets organized in a .csv file that you would like to understand a bit more about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Super popular library for working with tabular data\n",
    "import pandas as pd\n",
    "from ai_tools import ask_ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is a .csv file?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_name</th>\n",
       "      <th>issue_description</th>\n",
       "      <th>priority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jane Doe</td>\n",
       "      <td>Customer was charged twice for the same transa...</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>John Smith</td>\n",
       "      <td>Customer unable to log into their account, fac...</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alice Johnson</td>\n",
       "      <td>Customer wants more information about product ...</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bob Brown</td>\n",
       "      <td>Customer has not received the order yet, track...</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Michael Lee</td>\n",
       "      <td>Customer wants to return a product and needs a...</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_name                                  issue_description priority\n",
       "0       Jane Doe  Customer was charged twice for the same transa...     High\n",
       "1     John Smith  Customer unable to log into their account, fac...   Medium\n",
       "2  Alice Johnson  Customer wants more information about product ...      Low\n",
       "3      Bob Brown  Customer has not received the order yet, track...     High\n",
       "4    Michael Lee  Customer wants to return a product and needs a...   Medium"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_customer_tickets = pd.read_csv(\"./extracted_ticket_issues.csv\")\n",
    "\n",
    "data_customer_tickets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data contains 3 columns:\n",
    "1. `customer_name` - names of the customers\n",
    "2. `issue_description` - description of the issue they had\n",
    "3. `priority` - reference to the level of priority of that task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could use Python to get for example only the high priority issues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     True\n",
       "1    False\n",
       "2    False\n",
       "3     True\n",
       "4    False\n",
       "Name: priority, dtype: bool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# == indicates equivalence!\n",
    "data_customer_tickets[\"priority\"]==\"High\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_priority_issues = data_customer_tickets[data_customer_tickets[\"priority\"]==\"High\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can take a look at the issues themselves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_name</th>\n",
       "      <th>issue_description</th>\n",
       "      <th>priority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jane Doe</td>\n",
       "      <td>Customer was charged twice for the same transa...</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bob Brown</td>\n",
       "      <td>Customer has not received the order yet, track...</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_name                                  issue_description priority\n",
       "0      Jane Doe  Customer was charged twice for the same transa...     High\n",
       "3     Bob Brown  Customer has not received the order yet, track...     High"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_priority_issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! What we could do now is for example use our `ask_ai` tool to categorize the issues for us to help organizing the information, and then feed that back into the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'That sounds like an exciting course! There are so many applications for automation with Python and AI tools. Here are some ideas and topics you might consider covering in your course:\\n\\n### Python Automation\\n1. **Basics of Python**:\\n   - Data types, variables, control structures (loops, conditionals).\\n   - Functions and modules.\\n\\n2. **Web Scraping**:\\n   - Using libraries like BeautifulSoup and Scrapy to extract data from websites.\\n   - Understanding ethical scraping and web scraping best practices.\\n\\n3. **File Handling**:\\n   - Automating file management tasks (reading/writing files, organizing files).\\n   - Working with CSV, JSON, and Excel files using pandas.\\n\\n4. **Task Automation with Scripts**:\\n   - Scheduling tasks with `cron` (Linux) or Task Scheduler (Windows).\\n   - Automating repetitive tasks, such as sending emails or generating reports.\\n\\n5. **APIs and Automation**:\\n   - Making HTTP requests with `requests` and accessing RESTful APIs.\\n   - Automating interaction with services like Twitter, Slack, or Google Sheets.\\n\\n### AI Tools Integration\\n1. **Introduction to AI and Machine Learning**:\\n   - Basic concepts of AI/ML and popular libraries such as Scikit-learn and TensorFlow.\\n   - Overview of supervised vs. unsupervised learning.\\n\\n2. **Natural Language Processing (NLP)**:\\n   - Automating text analysis with libraries like NLTK or spaCy.\\n   - Using AI models like GPT for text generation and summarization tasks.\\n\\n3. **AI for Automation**:\\n   - Creating chatbots with NLP and frameworks like Rasa or Dialogflow.\\n   - Automating customer interactions and other administrative tasks.\\n\\n4. **Image and Video Processing with AI**:\\n   - Working with image data using OpenCV and PIL.\\n   - Automating image classification or object detection tasks.\\n\\n5. **Machine Learning Automation**:\\n   - Introduction to AutoML libraries like H2O.ai or Auto-Sklearn.\\n   - Automating model training and deployment pipelines.\\n\\n### Project Ideas\\n- **Web Scraping Project**: Build a scraper that gathers data from a website and analyzes it.\\n- **Email Automation**: Create a Python script that sends scheduled emails with reports or notifications.\\n- **Chatbot Project**: Develop a simple chatbot that answers FAQs using NLP.\\n- **Data Analysis Project**: Analyze a dataset using pandas, visualize the results with Matplotlib or Seaborn.\\n\\n### Best Practices\\n- Discuss coding best practices, version control using Git, and the importance of documentation.\\n- Encourage students to think about the ethical implications of automation and AI.\\n\\nThis structure should help provide a comprehensive curriculum for your course. If you need specific examples, exercises, or resources for any of these topics, feel free to ask!'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ai_tools import ask_ai\n",
    "\n",
    "ask_ai(\"Hi! I am teaching a course about automations with Python and some AI tools!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorizing issue: Customer was charged twice for the same transaction.\n",
      "Category: Billing\n",
      "Categorizing issue: Customer has not received the order yet, tracking information shows a delay.\n",
      "Category: Delay\n"
     ]
    }
   ],
   "source": [
    "categories_list = []\n",
    "for issue in high_priority_issues[\"issue_description\"]:\n",
    "    print(f\"Categorizing issue: {issue}\")\n",
    "    category = ask_ai(f\"Categorize this issue in just one single word and OUTPUT ONLY THAT WORD:\\n\\n issue: {issue}\\n category: \\n\")\n",
    "    print(f\"Category: {category}\")\n",
    "    categories_list.append(category)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice we use concepts we've learned before by looping over the issues, saving them to a list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with that information in hand we can actually update the dataframe accordingly, first we create a new column in the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_customer_tickets[\"issue_category\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update categories for high priority issues using the index from high_priority_issues\n",
    "for idx, category in zip(high_priority_issues.index, categories_list):\n",
    "    data_customer_tickets.loc[idx, \"issue_category\"] = category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_name</th>\n",
       "      <th>issue_description</th>\n",
       "      <th>priority</th>\n",
       "      <th>issue_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jane Doe</td>\n",
       "      <td>Customer was charged twice for the same transa...</td>\n",
       "      <td>High</td>\n",
       "      <td>Billing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>John Smith</td>\n",
       "      <td>Customer unable to log into their account, fac...</td>\n",
       "      <td>Medium</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alice Johnson</td>\n",
       "      <td>Customer wants more information about product ...</td>\n",
       "      <td>Low</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bob Brown</td>\n",
       "      <td>Customer has not received the order yet, track...</td>\n",
       "      <td>High</td>\n",
       "      <td>Delay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Michael Lee</td>\n",
       "      <td>Customer wants to return a product and needs a...</td>\n",
       "      <td>Medium</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_name                                  issue_description priority  \\\n",
       "0       Jane Doe  Customer was charged twice for the same transa...     High   \n",
       "1     John Smith  Customer unable to log into their account, fac...   Medium   \n",
       "2  Alice Johnson  Customer wants more information about product ...      Low   \n",
       "3      Bob Brown  Customer has not received the order yet, track...     High   \n",
       "4    Michael Lee  Customer wants to return a product and needs a...   Medium   \n",
       "\n",
       "  issue_category  \n",
       "0        Billing  \n",
       "1           None  \n",
       "2           None  \n",
       "3          Delay  \n",
       "4           None  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_customer_tickets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the issues for which we did not analyse still contain a `None` indicating they haven't been categorized yet!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and Managing Structured Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides analysing data, we can also create our ownn tables with information we care about."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a practical example - creating a camping trip gear checklist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camping Gear Checklist:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>priority</th>\n",
       "      <th>estimated_cost</th>\n",
       "      <th>packed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tent</td>\n",
       "      <td>Essential</td>\n",
       "      <td>299.99</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sleeping Bag</td>\n",
       "      <td>Essential</td>\n",
       "      <td>149.99</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Backpack</td>\n",
       "      <td>Essential</td>\n",
       "      <td>199.99</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hiking Boots</td>\n",
       "      <td>Essential</td>\n",
       "      <td>159.99</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Water Filter</td>\n",
       "      <td>High</td>\n",
       "      <td>89.99</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>First Aid Kit</td>\n",
       "      <td>Essential</td>\n",
       "      <td>49.99</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Headlamp</td>\n",
       "      <td>High</td>\n",
       "      <td>39.99</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Camp Stove</td>\n",
       "      <td>Medium</td>\n",
       "      <td>79.99</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            item   priority  estimated_cost  packed\n",
       "0           Tent  Essential          299.99   False\n",
       "1   Sleeping Bag  Essential          149.99   False\n",
       "2       Backpack  Essential          199.99   False\n",
       "3   Hiking Boots  Essential          159.99   False\n",
       "4   Water Filter       High           89.99   False\n",
       "5  First Aid Kit  Essential           49.99   False\n",
       "6       Headlamp       High           39.99   False\n",
       "7     Camp Stove     Medium           79.99   False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a camping gear checklist\n",
    "camping_gear = {\n",
    "    \"item\": [\n",
    "        \"Tent\", \"Sleeping Bag\", \"Backpack\", \"Hiking Boots\",\n",
    "        \"Water Filter\", \"First Aid Kit\", \"Headlamp\", \"Camp Stove\"\n",
    "    ],\n",
    "    \"priority\": [\n",
    "        \"Essential\", \"Essential\", \"Essential\", \"Essential\",\n",
    "        \"High\", \"Essential\", \"High\", \"Medium\"\n",
    "    ],\n",
    "    \"estimated_cost\": [\n",
    "        299.99, 149.99, 199.99, 159.99,\n",
    "        89.99, 49.99, 39.99, 79.99\n",
    "    ],\n",
    "    \"packed\": [\n",
    "        False, False, False, False,\n",
    "        False, False, False, False\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "gear_df = pd.DataFrame(camping_gear)\n",
    "print(\"Camping Gear Checklist:\")\n",
    "display(gear_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Data Filters\n",
    "\n",
    "Let's demonstrate how to filter and analyze our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cost of essential gear: $859.95\n",
      "\n",
      "Unpacked essential items:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>estimated_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tent</td>\n",
       "      <td>299.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sleeping Bag</td>\n",
       "      <td>149.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Backpack</td>\n",
       "      <td>199.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hiking Boots</td>\n",
       "      <td>159.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>First Aid Kit</td>\n",
       "      <td>49.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            item  estimated_cost\n",
       "0           Tent          299.99\n",
       "1   Sleeping Bag          149.99\n",
       "2       Backpack          199.99\n",
       "3   Hiking Boots          159.99\n",
       "5  First Aid Kit           49.99"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def analyze_gear_requirements():\n",
    "    # Filter essential items\n",
    "    essential_gear = gear_df[gear_df['priority'] == 'Essential']\n",
    "    \n",
    "    # Calculate total cost of essential items\n",
    "    essential_cost = essential_gear['estimated_cost'].sum()\n",
    "    \n",
    "    # Get unpacked essential items\n",
    "    unpacked_essential = essential_gear[~essential_gear['packed']]\n",
    "    \n",
    "    print(f\"Total cost of essential gear: ${essential_cost:.2f}\")\n",
    "    print(\"\\nUnpacked essential items:\")\n",
    "    display(unpacked_essential[['item', 'estimated_cost']])\n",
    "\n",
    "analyze_gear_requirements()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Trip Itinerary\n",
    "\n",
    "Let's create a more complex example with a detailed trip itinerary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trip Itinerary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>date</th>\n",
       "      <th>activity</th>\n",
       "      <th>location</th>\n",
       "      <th>distance_km</th>\n",
       "      <th>difficulty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-06-01</td>\n",
       "      <td>Arrival and Camp Setup</td>\n",
       "      <td>Basecamp Area</td>\n",
       "      <td>2</td>\n",
       "      <td>Easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-06-02</td>\n",
       "      <td>Mountain Trail Hike</td>\n",
       "      <td>Mountain Ridge Trail</td>\n",
       "      <td>8</td>\n",
       "      <td>Hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2024-06-03</td>\n",
       "      <td>Lake Exploration</td>\n",
       "      <td>Crystal Lake</td>\n",
       "      <td>5</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2024-06-04</td>\n",
       "      <td>Forest Adventure</td>\n",
       "      <td>Ancient Forest</td>\n",
       "      <td>6</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2024-06-05</td>\n",
       "      <td>Pack and Departure</td>\n",
       "      <td>Basecamp Area</td>\n",
       "      <td>2</td>\n",
       "      <td>Easy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   day       date                activity              location  distance_km  \\\n",
       "0    1 2024-06-01  Arrival and Camp Setup         Basecamp Area            2   \n",
       "1    2 2024-06-02     Mountain Trail Hike  Mountain Ridge Trail            8   \n",
       "2    3 2024-06-03        Lake Exploration          Crystal Lake            5   \n",
       "3    4 2024-06-04        Forest Adventure        Ancient Forest            6   \n",
       "4    5 2024-06-05      Pack and Departure         Basecamp Area            2   \n",
       "\n",
       "  difficulty  \n",
       "0       Easy  \n",
       "1       Hard  \n",
       "2   Moderate  \n",
       "3   Moderate  \n",
       "4       Easy  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_trip_itinerary():\n",
    "    itinerary_data = {\n",
    "        'day': range(1, 6),\n",
    "        'date': pd.date_range('2024-06-01', periods=5),\n",
    "        'activity': [\n",
    "            'Arrival and Camp Setup',\n",
    "            'Mountain Trail Hike',\n",
    "            'Lake Exploration',\n",
    "            'Forest Adventure',\n",
    "            'Pack and Departure'\n",
    "        ],\n",
    "        'location': [\n",
    "            'Basecamp Area',\n",
    "            'Mountain Ridge Trail',\n",
    "            'Crystal Lake',\n",
    "            'Ancient Forest',\n",
    "            'Basecamp Area'\n",
    "        ],\n",
    "        'distance_km': [2, 8, 5, 6, 2],\n",
    "        'difficulty': [\n",
    "            'Easy',\n",
    "            'Hard',\n",
    "            'Moderate',\n",
    "            'Moderate',\n",
    "            'Easy'\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    itinerary_df = pd.DataFrame(itinerary_data)\n",
    "    return itinerary_df\n",
    "\n",
    "# Create and display the itinerary\n",
    "trip_itinerary = create_trip_itinerary()\n",
    "print(\"Trip Itinerary:\")\n",
    "display(trip_itinerary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Trip Statistics\n",
    "\n",
    "Let's add some analysis to our trip planning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trip Analysis:\n",
      "Total distance: 23 km\n",
      "\n",
      "Difficulty breakdown:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "difficulty\n",
       "Easy        2\n",
       "Moderate    2\n",
       "Hard        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Longest day: Day 2 - Mountain Trail Hike\n",
      "Distance: 8 km\n"
     ]
    }
   ],
   "source": [
    "def analyze_trip_metrics(itinerary_df):\n",
    "    # Calculate total distance\n",
    "    total_distance = itinerary_df['distance_km'].sum()\n",
    "    \n",
    "    # Get difficulty breakdown\n",
    "    difficulty_counts = itinerary_df['difficulty'].value_counts()\n",
    "    \n",
    "    # Find longest day\n",
    "    longest_day = itinerary_df.loc[itinerary_df['distance_km'].idxmax()]\n",
    "    \n",
    "    print(f\"Trip Analysis:\")\n",
    "    print(f\"Total distance: {total_distance} km\")\n",
    "    print(\"\\nDifficulty breakdown:\")\n",
    "    display(difficulty_counts)\n",
    "    print(f\"\\nLongest day: Day {longest_day['day']} - {longest_day['activity']}\")\n",
    "    print(f\"Distance: {longest_day['distance_km']} km\")\n",
    "\n",
    "analyze_trip_metrics(trip_itinerary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting and Saving Data\n",
    "\n",
    "Let's see how to save our data for later use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_trip_data(gear_df, itinerary_df, filename_prefix):\n",
    "    # Export to CSV\n",
    "    gear_df.to_csv(f\"{filename_prefix}_gear.csv\", index=False)\n",
    "    itinerary_df.to_csv(f\"{filename_prefix}_itinerary.csv\", index=False)\n",
    "\n",
    "# Export our data\n",
    "export_trip_data(gear_df, trip_itinerary, \"camping_trip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Exercise: Trip Budget Calculator\n",
    "\n",
    "Let's create a budget calculator for our trip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trip Budget Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Cost</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gear</td>\n",
       "      <td>1069.92</td>\n",
       "      <td>79.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Food</td>\n",
       "      <td>150.00</td>\n",
       "      <td>11.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fuel</td>\n",
       "      <td>50.00</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>75.00</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Category     Cost  Percentage\n",
       "0           Gear  1069.92        79.6\n",
       "1           Food   150.00        11.2\n",
       "2           Fuel    50.00         3.7\n",
       "3  Miscellaneous    75.00         5.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def calculate_trip_budget(gear_df, itinerary_df):\n",
    "    # Equipment costs\n",
    "    total_gear_cost = gear_df['estimated_cost'].sum()\n",
    "    \n",
    "    # Daily expenses (example values)\n",
    "    daily_expenses = {\n",
    "        'food': 30,\n",
    "        'fuel': 10,\n",
    "        'miscellaneous': 15\n",
    "    }\n",
    "    \n",
    "    num_days = len(itinerary_df)\n",
    "    daily_total = sum(daily_expenses.values())\n",
    "    total_daily_costs = daily_total * num_days\n",
    "    \n",
    "    # Create budget summary\n",
    "    budget_summary = pd.DataFrame({\n",
    "        'Category': ['Gear', 'Food', 'Fuel', 'Miscellaneous'],\n",
    "        'Cost': [\n",
    "            total_gear_cost,\n",
    "            daily_expenses['food'] * num_days,\n",
    "            daily_expenses['fuel'] * num_days,\n",
    "            daily_expenses['miscellaneous'] * num_days\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    budget_summary['Percentage'] = (\n",
    "        budget_summary['Cost'] / budget_summary['Cost'].sum() * 100\n",
    "    ).round(1)\n",
    "    \n",
    "    return budget_summary\n",
    "\n",
    "# Calculate and display budget\n",
    "budget = calculate_trip_budget(gear_df, trip_itinerary)\n",
    "print(\"Trip Budget Summary:\")\n",
    "display(budget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "- Pandas provides powerful tools for working with tabular data\n",
    "- DataFrames can be filtered and analyzed in various ways\n",
    "- Data can be exported to different formats (CSV, Excel)\n",
    "- Structured data makes analysis and planning easier\n",
    "- Always consider data types when creating DataFrames\n",
    "- Use appropriate column names and data organization\n",
    "- Remember to handle missing data appropriately\n",
    "\n",
    "In the next lesson, we'll explore more advanced pandas operations and data visualization techniques!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-automate-tasks",
   "language": "python",
   "name": "oreilly-automate-tasks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}


---
./notebooks/01-python-fundamentals/10-packages-and-apis.ipynb
---
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f6f5ebb",
   "metadata": {},
   "source": [
    "# Python Packages, APIs and Code Organization\n",
    "\n",
    "In this lesson, we'll explore how to work with packages in Python, understand APIs, and learn best practices for organizing code across multiple files. We'll see how to leverage both built-in and third-party packages to extend Python's capabilities.\n",
    "\n",
    "## Built-in Packages\n",
    "\n",
    "Python comes with a rich set of built-in packages. Let's explore some common ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72da37ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[85, 24, 53, 82, 100, 75, 90, 6, 4, 67, 92, 44, 100, 6, 57, 98, 14, 26, 80, 20]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import built-in packages\n",
    "import math\n",
    "import statistics \n",
    "import random\n",
    "\n",
    "# Generate some random data for our examples\n",
    "data = [random.randint(1, 100) for _ in range(20)]\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0926ac9b-1c61-40df-86c2-b8df2e0b014a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Square root of 16: 4.0\n",
      "Pi value: 3.141592653589793\n",
      "Exponential of 2: 7.38905609893065\n"
     ]
    }
   ],
   "source": [
    "# Using math functions\n",
    "print(f\"Square root of 16: {math.sqrt(16)}\")\n",
    "print(f\"Pi value: {math.pi}\")\n",
    "print(f\"Exponential of 2: {math.exp(2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4494a1fe-157b-4498-bc8e-f8d1b92a9490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean of data: 56.15\n",
      "Median of data: 62.0\n",
      "Standard deviation: 35.17217051800142\n"
     ]
    }
   ],
   "source": [
    "# Using statistics functions\n",
    "print(f\"\\nMean of data: {statistics.mean(data)}\")\n",
    "print(f\"Median of data: {statistics.median(data)}\")\n",
    "print(f\"Standard deviation: {statistics.stdev(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c1a4b66-2a8c-499c-8382-429bea3f0d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random choice from data: 44\n"
     ]
    }
   ],
   "source": [
    "# Using random functions\n",
    "print(f\"\\nRandom choice from data: {random.choice(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12a4b567-d866-41cd-906a-2525f26f2672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random sample of 5 numbers: [80, 24, 82, 98, 6]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Random sample of 5 numbers: {random.sample(data, 5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1393b39c-232b-4cf1-a4be-4e35476347c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai_tools import ask_ai, ask_local_ai #?????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e29d545-049c-4d53-8005-bdffdf8d8907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"AS! So, when it comes to using Large Language Models (LLMs) locally, without relying on cloud-based APIs, there are a few reasons why an API key isn't always required.\\n\\nFirstly, many LLMs are pre-trained and fine-tuned using large amounts of data. These models can be trained and then saved in a format that's easily distributable and usable by local applications. As a result, you don't need to authenticate your requests or obtain an API key to use the model locally.\\n\\nSecondly, when working with LLMs locally, you typically have full access to the underlying data and computational resources. This means you can load the pre-trained model directly into memory without needing to authenticate your usage through an API key.\\n\\nThirdly, some local LLM implementations might be based on open-source or self-hosted solutions that don't require authentication for local use cases. These models are often designed specifically for deployment in private environments, such as internal applications or research projects, where the primary concern is processing power and data privacy rather than scalability or commercial usage.\\n\\nHowever, it's worth noting that even if an API key isn't required, you might still need to follow certain guidelines, terms of use, or licensing agreements when working with open-source LLM models. For example, some models may have restrictions on commercial use, redistribution, or modification.\\n\\nIn summary, while an API key isn't typically necessary for using local LLMs, there are other considerations and guidelines you should be aware of depending on the specific model, its source, and your intended use case.\\n\\nWould you like to know more about how to work with LLMs locally or explore some popular open-source models?\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_local_ai(\"Explain to my friend AS who is learning about LLM apis why you don't need an API key to use local LLM models. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fb098a-a601-4055-bb72-8f108e5f1ef4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c79a48d9",
   "metadata": {},
   "source": [
    "## Working with Third-Party Packages\n",
    "\n",
    "Third-party packages extend Python's functionality. Let's work with some popular ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d72ca56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather Statistics:\n",
      "                      date  temperature\n",
      "count                   32    32.000000\n",
      "mean   2024-01-16 12:00:00    19.519769\n",
      "min    2024-01-01 00:00:00     4.858960\n",
      "25%    2024-01-08 18:00:00    17.778249\n",
      "50%    2024-01-16 12:00:00    20.431805\n",
      "75%    2024-01-24 06:00:00    22.916791\n",
      "max    2024-02-01 00:00:00    27.473991\n",
      "std                    NaN     5.195840\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import third-party packages\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create sample data\n",
    "dates = pd.date_range(start='2024-01-01', end='2024-02-01', freq='D')\n",
    "temperatures = np.random.normal(20, 5, size=len(dates))\n",
    "\n",
    "# Create a DataFrame\n",
    "weather_data = pd.DataFrame({\n",
    "    'date': dates,\n",
    "    'temperature': temperatures\n",
    "})\n",
    "\n",
    "# Basic data wrangling\n",
    "weather_stats = weather_data.describe()\n",
    "print(\"Weather Statistics:\")\n",
    "print(weather_stats)\n",
    "\n",
    "# Create a visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(weather_data['date'], weather_data['temperature'])\n",
    "plt.title('Daily Temperatures')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Temperature (¬∞C)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d016e35",
   "metadata": {},
   "source": [
    "## Code Organization with Custom Modules\n",
    "\n",
    "**WALKTHROUGH OF THE `./ai_tools.py` module:**\n",
    "\n",
    " The `ai_tools.py` module contains several key functions:\n",
    "\n",
    " 1. `import` statements at the top:\n",
    "     - `from openai import OpenAI`: For accessing OpenAI's API\n",
    "     - `import anthropic`: For accessing Anthropic's Claude API\n",
    "     - `import ollama`: For running local AI models\n",
    "     - `import json`: For parsing JSON responses\n",
    " \n",
    " 2. `ask_ai(prompt, model_name)`: Sends prompts to cloud AI models like GPT-4 and Claude\n",
    "    - Uses OpenAI and Anthropic APIs\n",
    "    - Returns text response from the AI\n",
    "\n",
    " 3. `ask_local_ai(prompt, model_name)`: Sends prompts to locally-run AI models\n",
    "    - Uses Ollama API for local LLMs\n",
    "    - Can return structured JSON or plain text\n",
    "\n",
    " 4. Helper functions for parsing AI outputs:\n",
    "    - `parse_dates_list()`: Converts string output to Python list of dates\n",
    "    - `parse_json_output()`: Safely parses JSON responses from AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c509827",
   "metadata": {},
   "source": [
    "Let's create a separate module for weather-related functions. First, create a file called `weather_utils.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf65748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather_utils.py\n",
    "\n",
    "def celsius_to_fahrenheit(celsius):\n",
    "    \"\"\"Convert Celsius to Fahrenheit\"\"\"\n",
    "    return (celsius * 9/5) + 32\n",
    "\n",
    "def calculate_heat_index(temperature, humidity):\n",
    "    \"\"\"Calculate heat index based on temperature (¬∞F) and humidity (%)\"\"\"\n",
    "    if temperature < 80:\n",
    "        return temperature\n",
    "    \n",
    "    heat_index = -42.379 + 2.04901523 * temperature + 10.14333127 * humidity\n",
    "    heat_index -= 0.22475541 * temperature * humidity\n",
    "    heat_index -= 6.83783e-3 * temperature**2\n",
    "    heat_index -= 5.481717e-2 * humidity**2\n",
    "    heat_index += 1.22874e-3 * temperature**2 * humidity\n",
    "    heat_index += 8.5282e-4 * temperature * humidity**2\n",
    "    heat_index -= 1.99e-6 * temperature**2 * humidity**2\n",
    "    \n",
    "    return round(heat_index, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1819d6",
   "metadata": {},
   "source": [
    "Now let's use our custom module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "862a6597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of weather data with heat index:\n",
      "        date  temperature  temperature_f   humidity  heat_index\n",
      "0 2024-01-01    20.318835      68.573903  37.092948   68.573903\n",
      "1 2024-01-02    26.590865      79.863557  47.872554   79.863557\n",
      "2 2024-01-03     0.340331      32.612596  56.443950   32.612596\n",
      "3 2024-01-04     7.153789      44.876820  70.574083   44.876820\n",
      "4 2024-01-05    22.697382      72.855287  55.183043   72.855287\n"
     ]
    }
   ],
   "source": [
    "# Import the pandas module for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Import our custom module\n",
    "from weather_utils import celsius_to_fahrenheit, calculate_heat_index\n",
    "\n",
    "weather_data = pd.DataFrame({\n",
    "    'date': pd.date_range(start='2024-01-01', periods=100, freq='D'),\n",
    "    'temperature': np.random.uniform(0, 30, size=100)  # Random temperatures in Celsius\n",
    "})\n",
    "\n",
    "# Convert our temperature data to Fahrenheit\n",
    "weather_data['temperature_f'] = weather_data['temperature'].apply(celsius_to_fahrenheit)\n",
    "\n",
    "# Add random humidity data\n",
    "weather_data['humidity'] = np.random.uniform(30, 80, size=len(weather_data))\n",
    "\n",
    "# Calculate heat index\n",
    "weather_data['heat_index'] = weather_data.apply(\n",
    "    lambda x: calculate_heat_index(x['temperature_f'], x['humidity']), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(\"\\nSample of weather data with heat index:\")\n",
    "print(weather_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8981eb",
   "metadata": {},
   "source": [
    "## Working with APIs\n",
    "\n",
    "Let's explore how to work with APIs using the OpenWeatherMap API as an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ed0ee51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current weather in different cities:\n",
      "       city  temperature  humidity      description            timestamp\n",
      "0    London         5.62        88  overcast clouds  2025-02-03 10:35:00\n",
      "1  New York        -0.01        90        clear sky  2025-02-03 10:39:50\n",
      "2     Tokyo         6.82        71    broken clouds  2025-02-03 10:34:55\n",
      "3    Sydney        24.41        77       few clouds  2025-02-03 10:35:40\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def get_weather_data(city, api_key):\n",
    "    \"\"\"\n",
    "    Fetch weather data for a given city using OpenWeatherMap API\n",
    "    \"\"\"\n",
    "    base_url = \"http://api.openweathermap.org/data/2.5/weather\"\n",
    "    params = {\n",
    "        \"q\": city,\n",
    "        \"appid\": api_key,\n",
    "        \"units\": \"metric\"  # Use metric units\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(base_url, params=params)\n",
    "        response.raise_for_status()  # Raise an exception for bad status codes\n",
    "        \n",
    "        data = response.json()\n",
    "        \n",
    "        # Extract relevant information\n",
    "        weather_info = {\n",
    "            \"city\": city,\n",
    "            \"temperature\": data[\"main\"][\"temp\"],\n",
    "            \"humidity\": data[\"main\"][\"humidity\"],\n",
    "            \"description\": data[\"weather\"][0][\"description\"],\n",
    "            \"timestamp\": datetime.fromtimestamp(data[\"dt\"]).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        }\n",
    "        \n",
    "        return weather_info\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching weather data: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage (you'll need your own API key)\n",
    "api_key = os.environ[\"OPEN_WEATHER_API_KEY\"]  # Replace with your actual API key\n",
    "cities = [\"London\", \"New York\", \"Tokyo\", \"Sydney\"]\n",
    "\n",
    "weather_results = []\n",
    "for city in cities:\n",
    "    result = get_weather_data(city, api_key)\n",
    "    if result:\n",
    "        weather_results.append(result)\n",
    "\n",
    "# Convert results to DataFrame\n",
    "weather_df = pd.DataFrame(weather_results)\n",
    "print(\"\\nCurrent weather in different cities:\")\n",
    "print(weather_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d215d5d7",
   "metadata": {},
   "source": [
    "## Installing Packages with pip\n",
    "\n",
    "Here's how to install packages using pip (run these commands in your terminal):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91683947",
   "metadata": {},
   "source": [
    "# Install packages\n",
    "\n",
    "```pip install requests\n",
    "pip install pandas\n",
    "pip install matplotlib\n",
    "pip install beautifulsoup4\n",
    "\n",
    "# Install specific versions\n",
    "pip install requests==2.28.1\n",
    "\n",
    "# Upgrade packages\n",
    "pip install --upgrade requests\n",
    "\n",
    "# List installed packages\n",
    "pip list```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fcd0bb",
   "metadata": {},
   "source": [
    "## Web Scraping Example\n",
    "\n",
    "Let's create a simple web scraping example using BeautifulSoup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ceb2046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Latest O'Reilly AI & Programming News:\n",
      "1. DeepSeek-V3 is another LLM to watch. Its performance is on a par with Llama 3.1, GPT-4o, and Claude Sonnet. While training was not inexpensive, the cost of training was estimated to be roughly 10% of the bigger models.\n",
      "2. Not to be outdone by Google, OpenAI previewed its next models: o3 and o3-mini. These are both √¢¬Ä¬úreasoning models√¢¬Ä¬ù that have been trained to solve logical problems. They may be released in late January; OpenAI is looking for safety and security researchers for testing.\n",
      "3. Not to be outdone by 12 Days of OpenAI, Google has released a new experimental model that has been trained to solve logical problems: Gemini 2.0 Flash Thinking. Unlike OpenAI√¢¬Ä¬ôs GPT models that support reasoning, Flash Thinking shows its chain of thought explicitly.\n",
      "4. Jeremy Howard and his team have released ModernBERT, a major upgrade to the BERT model they released six years ago. It comes in two sizes: 139M and 395M parameters. It√¢¬Ä¬ôs ideal for retrieval, classification, and entity extraction, and other components of a data pipeline.\n",
      "5. AWS√¢¬Ä¬ôs Bedrock service has the ability to check the output of other models for hallucinations.\n",
      "6. To make sure they aren√¢¬Ä¬ôt outdone by 12 Days of OpenAI, Google has announced Android XR, an operating system for extended reality headsets and glasses. Google doesn√¢¬Ä¬ôt plan to build their own hardware; they√¢¬Ä¬ôre partnering with Samsung, Qualcomm, and other manufacturers.\n",
      "7. Also not to be outdone by 12 Days of OpenAI, Anthropic has announced Clio, a privacy- preserving approach to finding out how people use their models. That information will be used to improve Anthropic√¢¬Ä¬ôs understanding of safety issues and to build more helpful models.\n",
      "8. Not to be outdone by 12 Days of OpenAI, Google has announced Gemini 2.0 Flash, a multimodal model that supports streaming for both input and output. The announcement also showcased Astra, an AI agent for smartphones. Neither is generally available yet.\n",
      "9. OpenAI has released canvas, a new feature that combines programming with writing. Changes to the canvas (code or text) immediately become part of the context. Python code is executed in the browser using Pyodide (Wasm), rather than in a container (as with Code Interpreter).\n",
      "10. Stripe has announced an agent toolkit that lets you build payments into agentic workflows. Stripe recommends using the toolkit in test mode until the application has been thoroughly validated.\n",
      "11. Simon Willison shows how to run a GPT-4 class model (Llama 3.3 70B) on a reasonably well-equipped laptop (64GB MacBook Pro M2).\n",
      "12. As part of their 12 Days of OpenAI series, OpenAI finally released their video generation model, Sora. It√¢¬Ä¬ôs free to ChatGPT Plus subscribers, though limited to 50 five-second video clips per month; a ChatGPT Pro account relaxes many of the limitations.\n",
      "13. Researchers have shown that advanced AI models, including Claude 3 Opus and OpenAI o1, are capable of √¢¬Ä¬úscheming√¢¬Ä¬ù: working against the interests of their users to achieve their goals. Scheming includes subverting oversight mechanisms, intentionally delivering subpar results, and even taking steps to prevent shutdown or replacement. Hello, HAL?\n",
      "14. Roaming RAG is a new technique for retrieval augmented generation that finds relevant content by searching through headings to navigate documents√¢¬Ä¬îlike a human might. It requires well-structured documents. A surprisingly simple idea, really.\n",
      "15. Google has announced PaliGemma 2, a new version of its Gemma models that incorporates vision.\n",
      "16. GPT-4-o1-preview is no more; the preview is now the real thing, OpenAI o1. In addition to advanced reasoning skills, the production release claims to be faster and to deliver more consistent results.\n",
      "17. A group of AI agents in Minecraft behaved surprisingly like humans√¢¬Ä¬îeven developing jobs and religions. Is this a way to model how human groups collaborate?\n",
      "18. One thing the AI industry needs desperately (aside from more power) is better benchmarks. Current benchmarks are closed, easily gamed (that√¢¬Ä¬ôs what AI does), and unreproducible, and they may not test anything meaningful. Better Bench is a framework for assessing benchmark quality.\n",
      "19. Palmyra Creative, a new language model from Writer, promises the ability to develop √¢¬Ä¬ústyle√¢¬Ä¬ù so that all AI-generated output won√¢¬Ä¬ôt sound boringly the same.\n",
      "20. During training AI picks up biases from human data. When humans interact with the AI, there√¢¬Ä¬ôs a feedback loop that amplifies those biases.\n",
      "21. Unicon may never become one of the top 20 (or top 100) programming languages, but it√¢¬Ä¬ôs a descendant of Icon, which was always my favorite language for string processing.\n",
      "22. What do CAPTCHAs mean when LLM-equipped bots can successfully complete tasks set for humans?\n",
      "23. egui, together with eframe, is a GUI library and framework for Rust. It√¢¬Ä¬ôs portable and runs natively (on macOS, Windows, Linux, and Android), on the web (using Wasm), and in many game engines.\n",
      "24. For the archivist in us: The Manx project isn√¢¬Ä¬ôt about an island in the Irish Sea or about cats. It√¢¬Ä¬ôs a catalog of manuals for old computers.\n",
      "25. Cerbrec is a graphical Python framework for deep learning. It√¢¬Ä¬ôs aimed at Python programmers who don√¢¬Ä¬ôt have sufficient expertise to build applications with PyTorch or other AI libraries.\n",
      "26. GitHub has announced free access to GitHub Copilot for all current and new users. Free access gives you 2,000 code completions and 50 chat messages per month. They√¢¬Ä¬ôve also added the ability to use Claude 3.5 Sonnet in addition to GPT-4o.\n",
      "27. Devin, the AI assisted coding tool that claims to support software development from beginning to end, including design and debugging, has reached general availability.\n",
      "28. JSON5, also known as √¢¬Ä¬úJSON for humans,√¢¬Ä¬ù is a variant of JSON that has been designed for human readability so that it can be written and maintained by hand√¢¬Ä¬îfor example, in configuration files.\n",
      "29. AWS has announced two significant new services: Aurora DSQL, which is a distributed SQL database, and S3 Tables, which supports data lakehouses through Apache Iceberg.\n",
      "30. AutoFlow is an open source tool for creating a knowledge graph. It√¢¬Ä¬ôs based on TiDB (a vector database), LlamaIndex, and DSPy.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_oreilly_ai_programming_news(url):\n",
    "    \"\"\"\n",
    "    Scrape AI and programming-related content from O'Reilly Radar.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Send request to the website\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Parse HTML content\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Find AI and Programming sections\n",
    "        ai_section = soup.find('h2', string=lambda text: text and 'AI' in text)\n",
    "        programming_section = soup.find('h2', string=lambda text: text and 'Programming' in text)\n",
    "        \n",
    "        news_items = []\n",
    "        \n",
    "        # Extract AI content\n",
    "        if ai_section:\n",
    "            ai_content = ai_section.find_next('ul')\n",
    "            if ai_content:\n",
    "                news_items.extend([li.text.strip() for li in ai_content.find_all('li')])\n",
    "        \n",
    "        # Extract Programming content\n",
    "        if programming_section:\n",
    "            programming_content = programming_section.find_next('ul')\n",
    "            if programming_content:\n",
    "                news_items.extend([li.text.strip() for li in programming_content.find_all('li')])\n",
    "        \n",
    "        return news_items\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error scraping website: {e}\")\n",
    "        return []\n",
    "\n",
    "# Example usage (replace with actual O'Reilly Radar URL)\n",
    "oreilly_url = \"https://www.oreilly.com/radar/radar-trends-to-watch-january-2025/\"\n",
    "ai_programming_news = scrape_oreilly_ai_programming_news(oreilly_url)\n",
    "\n",
    "if ai_programming_news:\n",
    "    print(\"\\nLatest O'Reilly AI & Programming News:\")\n",
    "    for idx, news in enumerate(ai_programming_news, 1):\n",
    "        print(f\"{idx}. {news}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ad07ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"max-width: 800px; margin: 20px auto; font-family: Arial, sans-serif;\">\n",
       "        <h2 style=\"color: white; border-bottom: 2px solid red; padding-bottom: 10px;\">\n",
       "            O'Reilly AI & Programming News\n",
       "        </h2>\n",
       "        <ul style=\"list-style-type: none; padding: 0;\">\n",
       "    \n",
       "            <li style=\"margin: 15px 0; padding: 15px; background-color: black; \n",
       "                       border-left: 4px solid red; border-radius: 4px;\">\n",
       "                DeepSeek-V3 is another LLM to watch. Its performance is on a par with Llama 3.1, GPT-4o, and Claude Sonnet. While training was not inexpensive, the cost of training was estimated to be roughly 10% of the bigger models.\n",
       "            </li>\n",
       "        \n",
       "            <li style=\"margin: 15px 0; padding: 15px; background-color: black; \n",
       "                       border-left: 4px solid red; border-radius: 4px;\">\n",
       "                Not to be outdone by Google, OpenAI previewed its next models: o3 and o3-mini. These are both √¢¬Ä¬úreasoning models√¢¬Ä¬ù that have been trained to solve logical problems. They may be released in late January; OpenAI is looking for safety and security researchers for testing.\n",
       "            </li>\n",
       "        \n",
       "            <li style=\"margin: 15px 0; padding: 15px; background-color: black; \n",
       "                       border-left: 4px solid red; border-radius: 4px;\">\n",
       "                Not to be outdone by 12 Days of OpenAI, Google has released a new experimental model that has been trained to solve logical problems: Gemini 2.0 Flash Thinking. Unlike OpenAI√¢¬Ä¬ôs GPT models that support reasoning, Flash Thinking shows its chain of thought explicitly.\n",
       "            </li>\n",
       "        \n",
       "            <li style=\"margin: 15px 0; padding: 15px; background-color: black; \n",
       "                       border-left: 4px solid red; border-radius: 4px;\">\n",
       "                Jeremy Howard and his team have released ModernBERT, a major upgrade to the BERT model they released six years ago. It comes in two sizes: 139M and 395M parameters. It√¢¬Ä¬ôs ideal for retrieval, classification, and entity extraction, and other components of a data pipeline.\n",
       "            </li>\n",
       "        \n",
       "            <li style=\"margin: 15px 0; padding: 15px; background-color: black; \n",
       "                       border-left: 4px solid red; border-radius: 4px;\">\n",
       "                AWS√¢¬Ä¬ôs Bedrock service has the ability to check the output of other models for hallucinations.\n",
       "            </li>\n",
       "        \n",
       "            <li style=\"margin: 15px 0; padding: 15px; background-color: black; \n",
       "                       border-left: 4px solid red; border-radius: 4px;\">\n",
       "                To make sure they aren√¢¬Ä¬ôt outdone by 12 Days of OpenAI, Google has announced Android XR, an operating system for extended reality headsets and glasses. Google doesn√¢¬Ä¬ôt plan to build their own hardware; they√¢¬Ä¬ôre partnering with Samsung, Qualcomm, and other manufacturers.\n",
       "            </li>\n",
       "        \n",
       "            <li style=\"margin: 15px 0; padding: 15px; background-color: black; \n",
       "                       border-left: 4px solid red; border-radius: 4px;\">\n",
       "                Also not to be outdone by 12 Days of OpenAI, Anthropic has announced Clio, a privacy- preserving approach to finding out how people use their models. That information will be used to improve Anthropic√¢¬Ä¬ôs understanding of safety issues and to build more helpful models.\n",
       "            </li>\n",
       "        \n",
       "            <li style=\"margin: 15px 0; padding: 15px; background-color: black; \n",
       "                       border-left: 4px solid red; border-radius: 4px;\">\n",
       "                Not to be outdone by 12 Days of OpenAI, Google has announced Gemini 2.0 Flash, a multimodal model that supports streaming for both input and output. The announcement also showcased Astra, an AI agent for smartphones. Neither is generally available yet.\n",
       "            </li>\n",
       "        \n",
       "            <li style=\"margin: 15px 0; padding: 15px; background-color: black; \n",
       "                       border-left: 4px solid red; border-radius: 4px;\">\n",
       "                OpenAI has released canvas, a new feature that combines programming with writing. Changes to the canvas (code or text) immediately become part of the context. Python code is executed in the browser using Pyodide (Wasm), rather than in a container (as with Code Interpreter).\n",
       "            </li>\n",
       "        \n",
       "            <li style=\"margin: 15px 0; padding: 15px; background-color: black; \n",
       "                       border-left: 4px solid red; border-radius: 4px;\">\n",
       "                Stripe has announced an agent toolkit that lets you build payments into agentic workflows. Stripe recommends using the toolkit in test mode until the application has been thoroughly validated.\n",
       "            </li>\n",
       "        \n",
       "            <li style=\"margin: 15px 0; padding: 15px; background-color: black; \n",
       "                       border-left: 4px solid red; border-radius: 4px;\">\n",
       "                Simon Willison shows how to run a GPT-4 class model (Llama 3.3 70B) on a reasonably well-equipped laptop (64GB MacBook Pro M2).\n",
       "            </li>\n",
       "        \n",
       "            <li style=\"margin: 15px 0; padding: 15px; background-color: black; \n",
       "                       border-left: 4px solid red; border-radius: 4px;\">\n",
       "                As part of their 12 Days of OpenAI series, OpenAI finally released their video generation model, Sora. It√¢¬Ä¬ôs free to ChatGPT Plus subscribers, though limited to 50 five-second video clips per month; a ChatGPT Pro account relaxes many of the limitations.\n",
       "            </li>\n",
       "        \n",
       "            <li style=\"margin: 15px 0; padding: 15px; background-color: black; \n",
       "                       border-left: 4px solid red; border-radius: 4px;\">\n",
       "                Researchers have shown that advanced AI models, including Claude 3 Opus and OpenAI o1, are capable of √¢¬Ä¬úscheming√¢¬Ä¬ù: working against the interests of their users to achieve their goals. Scheming includes subverting oversight mechanisms, intentionally delivering subpar results, and even taking steps to prevent shutdown or replacement. Hello, HAL?\n",
       "            </li>\n",
       "        \n",
       "            <li style=\"margin: 15px 0; padding: 15px; background-color: black; \n",
       "                       border-left: 4px solid red; border-radius: 4px;\">\n",
       "                Roaming RAG is a new technique for retrieval augmented generation that finds relevant content by searching through headings to navigate documents√¢¬Ä¬îlike a human might. It requires well-structured documents. A surprisingly simple idea, really.\n",
       "            </li>\n",
       "        \n",
       "            <li style=\"margin: 15px 0; padding: 15px; background-color: black; \n",
       "                       border-left: 4px solid red; border-radius: 4px;\">\n",
       "                Google has announced PaliGemma 2, a new version of its Gemma models that incorporates vision.\n",
       "            </li>\n",
       "        \n",
       "            <li style=\"margin: 15px 0; padding: 15px; background-color: black; \n",
       "                       border-left: 4px solid red; border-radius: 4px;\">\n",
       "                GPT-4-o1-preview is no more; the preview is now the real thing, OpenAI o1. In addition to advanced reasoning skills, the production release claims to be faster and to deliver more consistent results.\n",
       "            </li>\n",
       "        \n",
       "            <li style=\"margin: 15px 0; padding: 15px; background-color: black; \n",
       "                       border-left: 4px solid red; border-radius: 4px;\">\n",
       "                A group of AI agents in Minecraft behaved surprisingly like humans√¢¬Ä¬îeven developing jobs and religions. Is this a way to model how human groups collaborate?\n",
       "            </li>\n",
       "        \n",
       "            <li style=\"margin: 15px 0; padding: 15px; background-color: black; \n",
       "                       border-left: 4px solid red; border-radius: 4px;\">\n",
       "                One thing the AI industry needs desperately (aside from more power) is better benchmarks. Current benchmarks are closed, easily gamed (that√¢¬Ä¬ôs what AI does), and unreproducible, and they may not test anything meaningful. Better Bench is a framework for assessing benchmark quality.\n",
       "            </li>\n",
       "        \n",
       "            <li style=\"margin: 15px 0; padding: 15px; background-color: black; \n",
       "                       border-left: 4px solid red; border-radius: 4px;\">\n",
       "                Palmyra Creative, a new language model from Writer, promises the ability to develop √¢¬Ä¬ústyle√¢¬Ä¬ù so that all AI-generated output won√¢¬Ä¬ôt sound boringly the same.\n",
       "            </li>\n",
       "        \n",
       "            <li style=\"margin: 15px 0; padding: 15px; background-color: black; \n",
       "                       border-left: 4px solid red; border-radius: 4px;\">\n",
       "                During training AI picks up biases from human data. When humans interact with the AI, there√¢¬Ä¬ôs a feedback loop that amplifies those biases.\n",
       "            </li>\n",
       "        \n",
       "            <li style=\"margin: 15px 0; padding: 15px; background-color: black; \n",
       "                       border-left: 4px solid red; border-radius: 4px;\">\n",
       "                Unicon may never become one of the top 20 (or top 100) programming languages, but it√¢¬Ä¬ôs a descendant of Icon, which was always my favorite language for string processing.\n",
       "            </li>\n",
       "        \n",
       "            <li style=\"margin: 15px 0; padding: 15px; background-color: black; \n",
       "                       border-left: 4px solid red; border-radius: 4px;\">\n",
       "                What do CAPTCHAs mean when LLM-equipped bots can successfully complete tasks set for humans?\n",
       "            </li>\n",
       "        \n",
       "            <li style=\"margin: 15px 0; padding: 15px; background-color: black; \n",
       "                       border-left: 4px solid red; border-radius: 4px;\">\n",
       "                egui, together with eframe, is a GUI library and framework for Rust. It√¢¬Ä¬ôs portable and runs natively (on macOS, Windows, Linux, and Android), on the web (using Wasm), and in many game engines.\n",
       "            </li>\n",
       "        \n",
       "            <li style=\"margin: 15px 0; padding: 15px; background-color: black; \n",
       "                       border-left: 4px solid red; border-radius: 4px;\">\n",
       "                For the archivist in us: The Manx project isn√¢¬Ä¬ôt about an island in the Irish Sea or about cats. It√¢¬Ä¬ôs a catalog of manuals for old computers.\n",
       "            </li>\n",
       "        \n",
       "            <li style=\"margin: 15px 0; padding: 15px; background-color: black; \n",
       "                       border-left: 4px solid red; border-radius: 4px;\">\n",
       "                Cerbrec is a graphical Python framework for deep learning. It√¢¬Ä¬ôs aimed at Python programmers who don√¢¬Ä¬ôt have sufficient expertise to build applications with PyTorch or other AI libraries.\n",
       "            </li>\n",
       "        \n",
       "            <li style=\"margin: 15px 0; padding: 15px; background-color: black; \n",
       "                       border-left: 4px solid red; border-radius: 4px;\">\n",
       "                GitHub has announced free access to GitHub Copilot for all current and new users. Free access gives you 2,000 code completions and 50 chat messages per month. They√¢¬Ä¬ôve also added the ability to use Claude 3.5 Sonnet in addition to GPT-4o.\n",
       "            </li>\n",
       "        \n",
       "            <li style=\"margin: 15px 0; padding: 15px; background-color: black; \n",
       "                       border-left: 4px solid red; border-radius: 4px;\">\n",
       "                Devin, the AI assisted coding tool that claims to support software development from beginning to end, including design and debugging, has reached general availability.\n",
       "            </li>\n",
       "        \n",
       "            <li style=\"margin: 15px 0; padding: 15px; background-color: black; \n",
       "                       border-left: 4px solid red; border-radius: 4px;\">\n",
       "                JSON5, also known as √¢¬Ä¬úJSON for humans,√¢¬Ä¬ù is a variant of JSON that has been designed for human readability so that it can be written and maintained by hand√¢¬Ä¬îfor example, in configuration files.\n",
       "            </li>\n",
       "        \n",
       "            <li style=\"margin: 15px 0; padding: 15px; background-color: black; \n",
       "                       border-left: 4px solid red; border-radius: 4px;\">\n",
       "                AWS has announced two significant new services: Aurora DSQL, which is a distributed SQL database, and S3 Tables, which supports data lakehouses through Apache Iceberg.\n",
       "            </li>\n",
       "        \n",
       "            <li style=\"margin: 15px 0; padding: 15px; background-color: black; \n",
       "                       border-left: 4px solid red; border-radius: 4px;\">\n",
       "                AutoFlow is an open source tool for creating a knowledge graph. It√¢¬Ä¬ôs based on TiDB (a vector database), LlamaIndex, and DSPy.\n",
       "            </li>\n",
       "        \n",
       "        </ul>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_html_news_display(news_items):\n",
    "    \"\"\"\n",
    "    Create a formatted HTML display of news items with proper styling\n",
    "    \"\"\"\n",
    "    html = \"\"\"\n",
    "    <div style=\"max-width: 800px; margin: 20px auto; font-family: Arial, sans-serif;\">\n",
    "        <h2 style=\"color: white; border-bottom: 2px solid red; padding-bottom: 10px;\">\n",
    "            O'Reilly AI & Programming News\n",
    "        </h2>\n",
    "        <ul style=\"list-style-type: none; padding: 0;\">\n",
    "    \"\"\"\n",
    "    \n",
    "    for item in news_items:\n",
    "        html += f\"\"\"\n",
    "            <li style=\"margin: 15px 0; padding: 15px; background-color: black; \n",
    "                       border-left: 4px solid red; border-radius: 4px;\">\n",
    "                {item}\n",
    "            </li>\n",
    "        \"\"\"\n",
    "    \n",
    "    html += \"\"\"\n",
    "        </ul>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    from IPython.display import HTML\n",
    "    return HTML(html)\n",
    "\n",
    "# Display the news in formatted HTML\n",
    "\n",
    "create_html_news_display(ai_programming_news)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041d5b82",
   "metadata": {},
   "source": [
    "## Best Practices for Package Management\n",
    "\n",
    "1. Always use virtual environments to isolate project dependencies\n",
    "2. Keep a requirements.txt file with your project\n",
    "3. Use semantic versioning in requirements.txt\n",
    "4. Document any specific installation steps in README.md\n",
    "\n",
    "You can create a requirements.txt file for your project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e10a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate requirements.txt\n",
    "import subprocess\n",
    "\n",
    "def generate_requirements():\n",
    "    \"\"\"Generate requirements.txt file\"\"\"\n",
    "    try:\n",
    "        subprocess.run([\"pip\", \"freeze\", \">\", \"requirements.txt\"], shell=True)\n",
    "        print(\"Requirements.txt generated successfully\")\n",
    "    except subprocess.SubprocessError as e:\n",
    "        print(f\"Error generating requirements.txt: {e}\")\n",
    "\n",
    "generate_requirements()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-automate-tasks",
   "language": "python",
   "name": "oreilly-automate-tasks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}


---
./notebooks/01-python-fundamentals/Untitled.ipynb
---
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d28ebd18-deb2-481f-bd66-98a73bf1bda1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Countries</th>\n",
       "      <th>Cities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Osaka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Sao Paulo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Rome</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Countries     Cities\n",
       "0           0     Japan      Osaka\n",
       "1           1    Brazil  Sao Paulo\n",
       "2           2     Italy       Rome"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./places_to_go.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8c38b8-2275-47cc-8721-aadaa887e152",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}


---
./notebooks/01-python-fundamentals/file_test.txt
---
this is a sample filethis is an append to my file

---
./notebooks/01-python-fundamentals/live-intro-python.ipynb
---
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "647567e9-b35c-4cd1-86ab-c4d02d9d5e15",
   "metadata": {},
   "source": [
    "# Introduction to Python\n",
    "## Data Types, Variables, Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b193233-f8fe-4c69-8335-d0e80b938d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lucas'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining a variable which is of data type string\n",
    "a = \"Lucas\"\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b32ed9bc-558a-4514-a632-f8e78f90ba14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lucas\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf5acbf-8516-4d93-a828-58a92d6ef82d",
   "metadata": {},
   "source": [
    "What kinds of data types are out there? What are the most common?\n",
    "I love this question!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "700285d3-d229-486f-9b69-6e72c3ce6b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n",
      "<class 'float'>\n",
      "<class 'str'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# integer number -> whole number\n",
    "number = 10\n",
    "# float number -> with decimals\n",
    "decimal_numbers = 10.5\n",
    "# Text? -> string\n",
    "text_to_my_wonderful_audience = 'Can you read this text easily folks?'\n",
    "# List of numbers and text in the same place?\n",
    "list_numbers_and_text = [10, 2, 'some text', 1.2]\n",
    "print(type(number))\n",
    "print(type(decimal_numbers))\n",
    "print(type(text_to_my_wonderful_audience))\n",
    "print(type(list_numbers_and_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21eabe0-dc27-46f5-b83e-959689b75c0c",
   "metadata": {},
   "source": [
    "# Operations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3436984-dfe5-472b-bebf-7ae6713a737c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add numbers\n",
    "10 + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16e4f29f-83ac-4fd7-81e8-9902d45ed1fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multiply numbers \n",
    "10*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2636841-10ad-4177-8728-dd6975ed6e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subtract\n",
    "10-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e86681ab-f98d-4028-b720-0e1863c50fb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# divide \n",
    "10/2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b7dc31-d1e4-4245-b5ca-0d6c12b29854",
   "metadata": {},
   "source": [
    "## Operations with text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88f857b2-cd2b-44ae-a4ed-cba8cc5db9c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lucas is teaching a live course on automation and its going super well (lol).'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# operations in text\n",
    "sentence = 'lucas is teaching a live course on automation'\n",
    "second_part_of_sentence = ' and its going super well (lol).'\n",
    "# concatenate these 2 sentences together?\n",
    "sentence + second_part_of_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00d51d47-71f3-4854-bc0c-7ed64c27ff86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Folks! Lets have a great course! Excited to talk about:were gonna talk about string operations'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'were gonna talk about string operations'\n",
    "template_text = f'Folks! Lets have a great course! Excited to talk about:{sentence}'\n",
    "template_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfb6286a-a31a-4ad5-98f9-47257198fe6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10 plus 20 = 30'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number1 = 10\n",
    "number2 = 20\n",
    "result = number1 + number2\n",
    "calculation_result = f'{number1} plus {number2} = {result}'\n",
    "calculation_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e284d5d6-a00a-4e31-8110-1a423e79263e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shopping_list = [1, 2, 3]\n",
    "# I want to perform some sort of transformation to this shopping list\n",
    "sum(shopping_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571874bd-4085-4c59-a557-aff7e42eab54",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "# Create a script that calculates the multiple operations with different numbers and print them out in organized fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c218614e-d1f0-4348-bf05-6eb8cd0efabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtract: 6\n",
      "Add: 12\n",
      "Multiply: 27\n",
      "Divide: 3.0\n",
      "Exponent: 729\n"
     ]
    }
   ],
   "source": [
    "# Subtract: 6 Add: 12 Multiply: 27 Divide: 3.0 Exponent: 729\n",
    "a = 9\n",
    "b = 3\n",
    "print(f\"Subtract: {a-b}\")\n",
    "print(f\"Add: {a+b}\")\n",
    "print(f\"Multiply: {a*b}\")\n",
    "print(f\"Divide: {a/b}\")\n",
    "print(f\"Exponent: {a**b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a1960a-bfe7-4531-a998-55e6006bdbd6",
   "metadata": {},
   "source": [
    "# Functions, Booleans, Logical Operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afa1bce8-e7f2-4d2b-9d7d-cbf61c518fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolean_value = True\n",
    "boolean_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca2d9658-3a9e-44a6-a3e1-b8c30b01bb44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bool"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(boolean_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cf7602d1-4d41-4183-95d0-3a7a970bf6b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    .dashboard { font-family: Arial, sans-serif; padding: 10px; line-height: 1.6; }\n",
       "    .section { margin-bottom: 30px; }\n",
       "    h2 { color: #2c3e50; border-bottom: 2px solid #ccc; padding-bottom: 5px; }\n",
       "    table { border-collapse: collapse; width: 100%; margin-top: 10px; }\n",
       "    th, td { border: 1px solid #ccc; padding: 6px 12px; text-align: left; }\n",
       "    th { background-color: #f0f0f0; }\n",
       "    code { background-color: #f4f4f4; padding: 2px 4px; border-radius: 4px; }\n",
       "    pre { background-color: #f8f8f8; padding: 10px; border-radius: 6px; }\n",
       "</style>\n",
       "\n",
       "<div class=\"dashboard\">\n",
       "    <div class=\"section\">\n",
       "        <h2>üî¢ Data Types</h2>\n",
       "        <table>\n",
       "            <tr><th>Type</th><th>Example</th><th>Mutable</th></tr>\n",
       "            <tr><td>int</td><td><code>10</code></td><td>No</td></tr>\n",
       "            <tr><td>float</td><td><code>3.14</code></td><td>No</td></tr>\n",
       "            <tr><td>str</td><td><code>'hello'</code></td><td>No</td></tr>\n",
       "            <tr><td>bool</td><td><code>True</code></td><td>No</td></tr>\n",
       "            <tr><td>list</td><td><code>[1, 2, 3]</code></td><td>Yes</td></tr>\n",
       "            <tr><td>tuple</td><td><code>(1, 2)</code></td><td>No</td></tr>\n",
       "            <tr><td>dict</td><td><code>{'a': 1}</code></td><td>Yes</td></tr>\n",
       "            <tr><td>set</td><td><code>{1, 2, 3}</code></td><td>Yes</td></tr>\n",
       "        </table>\n",
       "    </div>\n",
       "\n",
       "    <div class=\"section\">\n",
       "        <h2>‚ûï Arithmetic Operators</h2>\n",
       "        <table>\n",
       "            <tr><th>Operator</th><th>Meaning</th><th>Example</th></tr>\n",
       "            <tr><td>+</td><td>Addition</td><td><code>5 + 2</code></td></tr>\n",
       "            <tr><td>-</td><td>Subtraction</td><td><code>5 - 2</code></td></tr>\n",
       "            <tr><td>*</td><td>Multiplication</td><td><code>5 * 2</code></td></tr>\n",
       "            <tr><td>/</td><td>Division</td><td><code>5 / 2</code></td></tr>\n",
       "            <tr><td>//</td><td>Floor Division</td><td><code>5 // 2</code></td></tr>\n",
       "            <tr><td>%</td><td>Modulus</td><td><code>5 % 2</code></td></tr>\n",
       "            <tr><td>**</td><td>Exponentiation</td><td><code>5 ** 2</code></td></tr>\n",
       "        </table>\n",
       "    </div>\n",
       "\n",
       "    <div class=\"section\">\n",
       "        <h2>üßÆ Comparison Operators</h2>\n",
       "        <table>\n",
       "            <tr><th>Operator</th><th>Meaning</th><th>Example</th></tr>\n",
       "            <tr><td>==</td><td>Equal</td><td><code>3 == 3</code></td></tr>\n",
       "            <tr><td>!=</td><td>Not Equal</td><td><code>3 != 2</code></td></tr>\n",
       "            <tr><td>></td><td>Greater Than</td><td><code>5 > 3</code></td></tr>\n",
       "            <tr><td><</td><td>Less Than</td><td><code>2 < 4</code></td></tr>\n",
       "            <tr><td>>=</td><td>Greater or Equal</td><td><code>5 >= 5</code></td></tr>\n",
       "            <tr><td><=</td><td>Less or Equal</td><td><code>3 <= 4</code></td></tr>\n",
       "        </table>\n",
       "    </div>\n",
       "\n",
       "    <div class=\"section\">\n",
       "        <h2>üîó Logical Operators</h2>\n",
       "        <table>\n",
       "            <tr><th>Operator</th><th>Meaning</th><th>Example</th></tr>\n",
       "            <tr><td>and</td><td>Both are True</td><td><code>True and False</code></td></tr>\n",
       "            <tr><td>or</td><td>One is True</td><td><code>True or False</code></td></tr>\n",
       "            <tr><td>not</td><td>Inverts</td><td><code>not True</code></td></tr>\n",
       "        </table>\n",
       "    </div>\n",
       "\n",
       "    <div class=\"section\">\n",
       "        <h2>üì¶ Variables</h2>\n",
       "        <p>Used to store data values. Naming rules:</p>\n",
       "        <ul>\n",
       "            <li>Must start with a letter or underscore</li>\n",
       "            <li>Cannot start with a number</li>\n",
       "            <li>Are case-sensitive</li>\n",
       "        </ul>\n",
       "        <pre><code>x = 10\n",
       "name = \"Lucas\"\n",
       "is_active = True</code></pre>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "html = \"\"\"\n",
    "<style>\n",
    "    .dashboard { font-family: Arial, sans-serif; padding: 10px; line-height: 1.6; }\n",
    "    .section { margin-bottom: 30px; }\n",
    "    h2 { color: #2c3e50; border-bottom: 2px solid #ccc; padding-bottom: 5px; }\n",
    "    table { border-collapse: collapse; width: 100%; margin-top: 10px; }\n",
    "    th, td { border: 1px solid #ccc; padding: 6px 12px; text-align: left; }\n",
    "    th { background-color: #f0f0f0; }\n",
    "    code { background-color: #f4f4f4; padding: 2px 4px; border-radius: 4px; }\n",
    "    pre { background-color: #f8f8f8; padding: 10px; border-radius: 6px; }\n",
    "</style>\n",
    "\n",
    "<div class=\"dashboard\">\n",
    "    <div class=\"section\">\n",
    "        <h2>üî¢ Data Types</h2>\n",
    "        <table>\n",
    "            <tr><th>Type</th><th>Example</th><th>Mutable</th></tr>\n",
    "            <tr><td>int</td><td><code>10</code></td><td>No</td></tr>\n",
    "            <tr><td>float</td><td><code>3.14</code></td><td>No</td></tr>\n",
    "            <tr><td>str</td><td><code>'hello'</code></td><td>No</td></tr>\n",
    "            <tr><td>bool</td><td><code>True</code></td><td>No</td></tr>\n",
    "            <tr><td>list</td><td><code>[1, 2, 3]</code></td><td>Yes</td></tr>\n",
    "            <tr><td>tuple</td><td><code>(1, 2)</code></td><td>No</td></tr>\n",
    "            <tr><td>dict</td><td><code>{'a': 1}</code></td><td>Yes</td></tr>\n",
    "            <tr><td>set</td><td><code>{1, 2, 3}</code></td><td>Yes</td></tr>\n",
    "        </table>\n",
    "    </div>\n",
    "\n",
    "    <div class=\"section\">\n",
    "        <h2>‚ûï Arithmetic Operators</h2>\n",
    "        <table>\n",
    "            <tr><th>Operator</th><th>Meaning</th><th>Example</th></tr>\n",
    "            <tr><td>+</td><td>Addition</td><td><code>5 + 2</code></td></tr>\n",
    "            <tr><td>-</td><td>Subtraction</td><td><code>5 - 2</code></td></tr>\n",
    "            <tr><td>*</td><td>Multiplication</td><td><code>5 * 2</code></td></tr>\n",
    "            <tr><td>/</td><td>Division</td><td><code>5 / 2</code></td></tr>\n",
    "            <tr><td>//</td><td>Floor Division</td><td><code>5 // 2</code></td></tr>\n",
    "            <tr><td>%</td><td>Modulus</td><td><code>5 % 2</code></td></tr>\n",
    "            <tr><td>**</td><td>Exponentiation</td><td><code>5 ** 2</code></td></tr>\n",
    "        </table>\n",
    "    </div>\n",
    "\n",
    "    <div class=\"section\">\n",
    "        <h2>üßÆ Comparison Operators</h2>\n",
    "        <table>\n",
    "            <tr><th>Operator</th><th>Meaning</th><th>Example</th></tr>\n",
    "            <tr><td>==</td><td>Equal</td><td><code>3 == 3</code></td></tr>\n",
    "            <tr><td>!=</td><td>Not Equal</td><td><code>3 != 2</code></td></tr>\n",
    "            <tr><td>></td><td>Greater Than</td><td><code>5 > 3</code></td></tr>\n",
    "            <tr><td><</td><td>Less Than</td><td><code>2 < 4</code></td></tr>\n",
    "            <tr><td>>=</td><td>Greater or Equal</td><td><code>5 >= 5</code></td></tr>\n",
    "            <tr><td><=</td><td>Less or Equal</td><td><code>3 <= 4</code></td></tr>\n",
    "        </table>\n",
    "    </div>\n",
    "\n",
    "    <div class=\"section\">\n",
    "        <h2>üîó Logical Operators</h2>\n",
    "        <table>\n",
    "            <tr><th>Operator</th><th>Meaning</th><th>Example</th></tr>\n",
    "            <tr><td>and</td><td>Both are True</td><td><code>True and False</code></td></tr>\n",
    "            <tr><td>or</td><td>One is True</td><td><code>True or False</code></td></tr>\n",
    "            <tr><td>not</td><td>Inverts</td><td><code>not True</code></td></tr>\n",
    "        </table>\n",
    "    </div>\n",
    "\n",
    "    <div class=\"section\">\n",
    "        <h2>üì¶ Variables</h2>\n",
    "        <p>Used to store data values. Naming rules:</p>\n",
    "        <ul>\n",
    "            <li>Must start with a letter or underscore</li>\n",
    "            <li>Cannot start with a number</li>\n",
    "            <li>Are case-sensitive</li>\n",
    "        </ul>\n",
    "        <pre><code>x = 10\n",
    "name = \"Lucas\"\n",
    "is_active = True</code></pre>\n",
    "    </div>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(html))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e695ff1-2137-4969-9b56-fac8403c234b",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33f4194-a685-46af-9b40-52a00c3a4a98",
   "metadata": {},
   "source": [
    "## Built in functions which are functions that work out of the box wit special keyword names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7e5a3f66-492a-4762-9609-772e8fefa23b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_numbers = [1,2,3]\n",
    "\n",
    "# built in function in python!\n",
    "sum(list_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e4414ce8-6545-47ce-8c48-c5a325da31fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0e64e90b-65bb-4856-ba45-d7f5457e31a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f4021f-eefa-4c85-86cd-3108968508f7",
   "metadata": {},
   "source": [
    "## Custom functions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "55bef4cb-1542-4ed0-9a9e-31a89369aa6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello folks!\n"
     ]
    }
   ],
   "source": [
    "def custom_function():\n",
    "    print(\"Hello folks!\")\n",
    "\n",
    "custom_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2d118698-1764-4204-9b70-cae47bc787aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_hello_to_students():\n",
    "    print(\"Hello students\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a29cfe6a-e142-4514-909d-171d9b7e528a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello students\n"
     ]
    }
   ],
   "source": [
    "print_hello_to_students()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "42151faf-7453-498c-8fa6-ec2981a84990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi! Lucas\n"
     ]
    }
   ],
   "source": [
    "def great_friend(friend_name=\"John\"):\n",
    "    print(f\"Hi! {friend_name}\")\n",
    "\n",
    "great_friend(friend_name='Lucas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "131e766d-d8ac-42f4-830b-62fd380e7a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def create_folder(folder_path):\n",
    "    \"\"\"Create a new folder if it doesn't exist.\"\"\"\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "        print(f\"‚úÖ Folder created: {folder_path}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Folder already exists: {folder_path}\")\n",
    "\n",
    "def rename_file(old_name, new_name):\n",
    "    \"\"\"Rename a file from old_name to new_name.\"\"\"\n",
    "    if os.path.exists(old_name):\n",
    "        os.rename(old_name, new_name)\n",
    "        print(f\"‚úÖ Renamed: {old_name} ‚Üí {new_name}\")\n",
    "    else:\n",
    "        print(f\"‚ùå File not found: {old_name}\")\n",
    "\n",
    "def move_file(source_path, destination_path):\n",
    "    \"\"\"Move a file from source to destination.\"\"\"\n",
    "    if os.path.exists(source_path):\n",
    "        shutil.move(source_path, destination_path)\n",
    "        print(f\"‚úÖ Moved file to: {destination_path}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Source file not found: {source_path}\")\n",
    "\n",
    "def delete_file(file_path):\n",
    "    \"\"\"Delete a file if it exists.\"\"\"\n",
    "    if os.path.exists(file_path):\n",
    "        os.remove(file_path)\n",
    "        print(f\"üóëÔ∏è Deleted: {file_path}\")\n",
    "    else:\n",
    "        print(f\"‚ùå File not found: {file_path}\")\n",
    "\n",
    "def list_files(folder_path):\n",
    "    \"\"\"List all files in a folder.\"\"\"\n",
    "    if os.path.exists(folder_path):\n",
    "        files = os.listdir(folder_path)\n",
    "        print(f\"üìÅ Files in {folder_path}:\")\n",
    "        for f in files:\n",
    "            print(f\" - {f}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Folder not found: {folder_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9eca3d21-3998-40b3-88b7-a94dfde466c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Files in ./:\n",
      " - 04-lists-and-loops.ipynb\n",
      " - 07-conditionals.ipynb\n",
      " - 06-comparators.ipynb\n",
      " - 08-working-with-files.ipynb\n",
      " - live-intro-python.ipynb\n",
      " - 05-dictionaries.ipynb\n",
      " - 02-variables.ipynb\n",
      " - .ipynb_checkpoints\n",
      " - 10-packages-and-apis.ipynb\n",
      " - 01-data-types-and-operators.ipynb\n",
      " - 09-working-with-csv.ipynb\n",
      " - 03-functions.ipynb\n"
     ]
    }
   ],
   "source": [
    "list_files(\"./\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73030d42-af9f-4f42-a92f-b079203f5d50",
   "metadata": {},
   "source": [
    "# Lists and Loops!?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "43e25abe-554b-48e8-95f8-39fa8fbb14c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_master_3000(task_description):\n",
    "    print(\"Agent doing task\")\n",
    "    print(\"Finished task\")\n",
    "    return f'Master Lucas, your task is done: {task_description}'\n",
    "\n",
    "list_of_tasks = [\"teach a live course\", \"go eat pizza\", \"cry about my silly course on the bathroom\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f5c534-1357-4e3b-85f1-8edd60d81b05",
   "metadata": {},
   "source": [
    "## Loop over the tasks and use the function on each ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d541413b-8277-40d3-9874-d8cdf6e5d67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teach a live course\n",
      "Agent doing task\n",
      "Finished task\n",
      "***\n",
      "go eat pizza\n",
      "Agent doing task\n",
      "Finished task\n",
      "***\n",
      "cry about my silly course on the bathroom\n",
      "Agent doing task\n",
      "Finished task\n",
      "***\n"
     ]
    }
   ],
   "source": [
    "for task in list_of_tasks:\n",
    "    print(task)\n",
    "    agent_master_3000(task_description=task)\n",
    "    print(\"***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "36906376-94ab-42b7-9890-305d8940ccb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_number_text = [\"text\", 1, 1.4, []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a286ef9a-cec8-4dfc-afae-090190109cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 2, 'some text', 1.2]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_numbers_and_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8c26c0bc-47c9-4591-9607-2f8988ff9eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add elements to a list?\n",
    "\n",
    "list_nums = [1,2,3]\n",
    "\n",
    "list_nums.append(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "75ef907b-4cf8-4188-be06-3b5285b0b7ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "10d34b47-1787-4de7-a4a9-cfac1e3327ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_nums.remove(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3f93e5f1-6ae8-41ad-9cd0-1ea3eb51eada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 4]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "27e911f0-5c27-4d30-9d0c-d29c12840a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_names = ['lucas', 'john', 'maria']\n",
    "\n",
    "list_names.index('lucas')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca771c2-6647-4413-8878-93679f7bfdd2",
   "metadata": {},
   "source": [
    "## Combining Lists, loops into an elegant format with List comprehension!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4c1dc612-f4f2-4ff9-af3b-65d189f679fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_comprehension_example_squares = [temporary_element**2 for temporary_element in range(10)]\n",
    "list_comprehension_example_squares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac718b29-d025-4aea-bff1-add1bb995698",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "## Repeat My Name\n",
    "### Objective: Write a simple python function that repeats a certain input string a certain numbers of times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b468b609-5ac0-4898-a0c9-469f368ede6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat_string(\"string\", 3)\n",
    "# string\n",
    "# string\n",
    "# string\n",
    "\n",
    "# MV solution\n",
    "def repeat_string(string, n): return n*string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3fbf9ffe-8364-4a9d-8fb3-31e23643a9f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lucas silly manlucas silly manlucas silly manlucas silly manlucas silly manlucas silly manlucas silly manlucas silly manlucas silly manlucas silly man'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeat_string(\"lucas silly man\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4d7c94b9-dec2-461b-b205-1c59a2a57a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "string\n",
      "string\n",
      "string\n"
     ]
    }
   ],
   "source": [
    "# AN solution\n",
    "def repeat_string(string, times):\n",
    "    for i in range(times):\n",
    "        print(string)\n",
    "repeat_string(\"string\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ce4445-be65-483f-90fd-9722c612306d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc68cefc-ddab-49c2-a64c-a3ff620b0f6e",
   "metadata": {},
   "source": [
    "### Write a simple python function to concatenate strings together "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "300fe676-60c4-49b2-bb39-02ba994b4053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'strin1string2strin1string2strin1string2strin1string2strin1string2'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# repeat_concatenate(\"string1\", \"string2\", 5)\n",
    "# string1string2\n",
    "# string1string2\n",
    "# string1string2\n",
    "# string1string2\n",
    "# string1string2\n",
    "\n",
    "# MV solution 2\n",
    "\n",
    "def repeat_concatenate(string1, string2, n):\n",
    "    return \"\".join([string1, string2]*n)\n",
    "\n",
    "repeat_concatenate(\"string1\", \"string2\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "430fca8d-89f6-46af-be0c-ec72aad6d7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "string1string2\n",
      "string1string2\n",
      "string1string2\n",
      "string1string2\n",
      "string1string2\n"
     ]
    }
   ],
   "source": [
    "# AN solution 2\n",
    "\n",
    "def repeat_concatenate(string1, string2, times):\n",
    "    for i in range(times):\n",
    "        print(f'{string1}{string2}')\n",
    "repeat_concatenate(\"string1\", \"string2\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6ab79915-6f27-48eb-80ed-d9a3e91cf61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lucas\n",
      "lucas\n",
      "lucas\n"
     ]
    }
   ],
   "source": [
    "def sw_repeat_string(strn=\"sam\", how=5):\n",
    "    num=0\n",
    "    while num<how:\n",
    "        print(strn)\n",
    "        num+=1\n",
    "sw_repeat_string(\"lucas\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "de36af9f-1725-45ee-bea9-5f103d19f1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "john\n",
      "john\n",
      "john\n"
     ]
    }
   ],
   "source": [
    "def jp_repeat_string(name, count):\n",
    "    for x in range(count):\n",
    "        print(f'{name}')\n",
    "jp_repeat_string('john', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fd30f2-850c-4231-8ce4-d25b9e17d813",
   "metadata": {},
   "source": [
    "# Dictionaries, working with TAbular Data, conditionals, writing reading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4ca45543-3ca1-4147-aaff-f6d6d353b559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'key1': 'value1', 'key2': 10, 'key3': [1, 2, 3]}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = {\n",
    "    \"key1\": \"value1\",\n",
    "    \"key2\": 10,\n",
    "    \"key3\": [1,2,3]\n",
    "}\n",
    "\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d4dcd839-8702-44c8-b915-fd462d34870e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['key1', 'key2', 'key3'])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "19eb7ab1-7a8e-45fc-8cfe-932173532b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['value1', 10, [1, 2, 3]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7dbc8869-93de-479f-9cb4-159adce4605e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('key1', 'value1'), ('key2', 10), ('key3', [1, 2, 3])])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d89da77c-6109-4986-9416-c18357c0e9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key1\n",
      "value1\n",
      "key2\n",
      "10\n",
      "key3\n",
      "[1, 2, 3]\n",
      "key1\n",
      "value1\n",
      "key2\n",
      "10\n",
      "key3\n",
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "for key, value in dictionary.items():\n",
    "    print(key)\n",
    "    print(value)\n",
    "\n",
    "for key in dictionary.keys():\n",
    "    print(key)\n",
    "    value = dictionary[key]\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0fd5b51e-9653-492a-8b42-588a215d7bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing functionality built elsewhere to help us solve some task\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2acf7eb6-1768-4c56-ad50-77cef2a2d024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Lucas',\n",
       " 'age': 33,\n",
       " 'email': 'lucas@example.com',\n",
       " 'is_student': False,\n",
       " 'skills': ['Python', 'AI', 'Jiu-Jitsu'],\n",
       " 'address': {'street': '123 Learning St', 'city': 'Codeville', 'zip': '12345'}}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dictionary_of_person_information = {\n",
    "    \"name\": \"Lucas\",\n",
    "    \"age\": 33,\n",
    "    \"email\": \"lucas@example.com\",\n",
    "    \"is_student\": False,\n",
    "    \"skills\": [\"Python\", \"AI\", \"Jiu-Jitsu\"],\n",
    "    \"address\": {\n",
    "        \"street\": \"123 Learning St\",\n",
    "        \"city\": \"Codeville\",\n",
    "        \"zip\": \"12345\"\n",
    "    }\n",
    "}\n",
    "\n",
    "dictionary_of_person_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3388acf8-d271-4c9e-81f0-84e57c947f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Japan</td>\n",
       "      <td>Tokyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Japan</td>\n",
       "      <td>Kyoto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Japan</td>\n",
       "      <td>Osaka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Italy</td>\n",
       "      <td>Rome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Italy</td>\n",
       "      <td>Florence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Italy</td>\n",
       "      <td>Venice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>Rio de Janeiro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>S√£o Paulo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>Salvador</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>USA</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>USA</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>USA</td>\n",
       "      <td>Chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>France</td>\n",
       "      <td>Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>France</td>\n",
       "      <td>Nice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>France</td>\n",
       "      <td>Lyon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country            City\n",
       "0    Japan           Tokyo\n",
       "1    Japan           Kyoto\n",
       "2    Japan           Osaka\n",
       "3    Italy            Rome\n",
       "4    Italy        Florence\n",
       "5    Italy          Venice\n",
       "6   Brazil  Rio de Janeiro\n",
       "7   Brazil       S√£o Paulo\n",
       "8   Brazil        Salvador\n",
       "9      USA        New York\n",
       "10     USA   San Francisco\n",
       "11     USA         Chicago\n",
       "12  France           Paris\n",
       "13  France            Nice\n",
       "14  France            Lyon"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "places_to_visit = {\n",
    "    \"Japan\": [\"Tokyo\", \"Kyoto\", \"Osaka\"],\n",
    "    \"Italy\": [\"Rome\", \"Florence\", \"Venice\"],\n",
    "    \"Brazil\": [\"Rio de Janeiro\", \"S√£o Paulo\", \"Salvador\"],\n",
    "    \"USA\": [\"New York\", \"San Francisco\", \"Chicago\"],\n",
    "    \"France\": [\"Paris\", \"Nice\", \"Lyon\"]\n",
    "}\n",
    "\n",
    "# Convert to a DataFrame\n",
    "df_places = pd.DataFrame([\n",
    "    {\"Country\": country, \"City\": city}\n",
    "    for country, cities in places_to_visit.items()\n",
    "    for city in cities\n",
    "])\n",
    "\n",
    "df_places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "aea32921-dae0-4349-8d65-7708e7b52765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Countries</th>\n",
       "      <th>Cities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Japan</td>\n",
       "      <td>Osaka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>Sao Paulo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Italy</td>\n",
       "      <td>Rome</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Countries     Cities\n",
       "0     Japan      Osaka\n",
       "1    Brazil  Sao Paulo\n",
       "2     Italy       Rome"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries = [\"Japan\", \"Brazil\", \"Italy\"]\n",
    "cities = [\"Osaka\",\"Sao Paulo\", \"Rome\"]\n",
    "\n",
    "table = pd.DataFrame({\n",
    "    \"Countries\": countries,\n",
    "    \"Cities\": cities\n",
    "})\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "34b291cf-a53b-479e-b13b-cd25b507d2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.to_csv(\"places_to_go.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "aaed2b83-1b80-493f-b720-a94c56e3ea04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "places_to_go.csv\n"
     ]
    }
   ],
   "source": [
    "!ls *.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd6cbee-866e-43ec-9f47-597ff1bbce50",
   "metadata": {},
   "source": [
    "# Write Read Files with Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "100023dd-1c80-410f-befb-6d971d8c9f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write \n",
    "\n",
    "contents = \"this is a sample file\"\n",
    "filepath = \"./file_test.txt\"\n",
    "with open(filepath, \"w\") as file:\n",
    "    file.write(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "36cda5ad-4a73-4c6d-b545-3536c37c9c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-data-types-and-operators.ipynb 08-working-with-files.ipynb\n",
      "02-variables.ipynb                09-working-with-csv.ipynb\n",
      "03-functions.ipynb                10-packages-and-apis.ipynb\n",
      "04-lists-and-loops.ipynb          file_test.txt\n",
      "05-dictionaries.ipynb             live-intro-python.ipynb\n",
      "06-comparators.ipynb              places_to_go.csv\n",
      "07-conditionals.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e96d0cdc-1e40-4057-be31-44eb59a3fa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append to my file\n",
    "\n",
    "with open(filepath, \"a\") as file:\n",
    "    file.write(\"this is an append to my file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "10453d46-873e-4022-9525-af85210d9e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is a sample filethis is an append to my file\n"
     ]
    }
   ],
   "source": [
    "# reading files\n",
    "with open(filepath, \"r\") as file:\n",
    "    print(file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a1365e-c256-445a-8946-a949fabea65c",
   "metadata": {},
   "source": [
    "# Automate Tasks with Python & Learn Python While Doing So!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d1649c1e-d21b-4ab3-83b7-1b2d0311c52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wh+at happens when we want to make decisions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5f7518dd-5039-496c-9328-4bdd3d6f6ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I cant' buy it\n"
     ]
    }
   ],
   "source": [
    "price = 600\n",
    "budget = 500\n",
    "\n",
    "if price>budget:\n",
    "    print(\"I cant' buy it\")\n",
    "else:\n",
    "    print(\"I can buy it!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c31611b5-9efd-4c6b-b765-e49ee5183e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lazy\n"
     ]
    }
   ],
   "source": [
    "distance = 300\n",
    "ability_to_walk = 200\n",
    "\n",
    "if distance > ability_to_walk:\n",
    "    print(\"lazy\")\n",
    "elif distance == ability_to_walk:\n",
    "    print(\"I guess I can do it\")\n",
    "else:\n",
    "    print(\"I can do it!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "O'Reilly Python AI",
   "language": "python",
   "name": "oreilly-python-ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}


---
./notebooks/01-python-fundamentals/places_to_go.csv
---
,Countries,Cities
0,Japan,Osaka
1,Brazil,Sao Paulo
2,Italy,Rome


---
./notebooks/assets/ai-tools.md
---
AI Hacks
	1. AI Tools
		1. General
			1. ChatGPT/Claude/Gemini/Ollama/llama studio/deep seek
		2. Search
			1. Perplexity for search
			2. ChatGPT + search
			3. Gemini 1.5 Pro Deep Research
		3. Claude/ChatGPT Projects
		4. Artifacts in Claude/ChatGPT
		5. ChatGPT Canvas
	2. Whiteboard
		1. Prompt Templates
		2. Chaining
		3. Hybrid approach
- Let it see your screen - Gemini/ChatGPT desktop app
- [ ] Paste code + error ask it to debug
- [ ] When a task is simple but has many repeatable steps
		- [ ] AI to generate quick Python script in correct proper runnable format
		- [ ] copy - paste - run - finish
- [ ] When AI makes a mistake save it for later as your own personal benchmark
- [ ] Build app with AI that takes in data with a certain structure and outputs desirable output, format, etc.... then make a prompt template that produces the data into the format acceptable by that app (done) :LiArrowBigRight: example my Quiz app.
- [ ] [Ask for full scripts with uv style package management](https://claude.ai/chat/cf3cb3d1-5b3e-4ea8-8584-5b6ceada7d84)  [[executing standalone scripts in Python with uv]]
	- [another example with very little debugging](https://claude.ai/chat/3276e7df-0dcf-4159-a6c0-df0ff9601e85)
- [ ] Show LLM how to call an API (in the prompt) then ask it to create something with that api.
- [ ] Writing Python code with Claude Projects + relevant documentation
- [ ] [[meta prompts]]
- [ ] [[Context Building Workflow with LLMs]]
- [ ] [[Test-Driven Development with AI (AI Writes Tests First)]]
- [ ] [[voice driven prompting]]
- [ ] [[Treat AI models as a team of specialized workers]]

---
./notebooks/assets/camping_trip_gear.csv
---
item,priority,estimated_cost,packed
Tent,Essential,299.99,False
Sleeping Bag,Essential,149.99,False
Backpack,Essential,199.99,False
Hiking Boots,Essential,159.99,False
Water Filter,High,89.99,False
First Aid Kit,Essential,49.99,False
Headlamp,High,39.99,False
Camp Stove,Medium,79.99,False


---
./notebooks/assets/camping_trip_itinerary.csv
---
day,date,activity,location,distance_km,difficulty
1,2024-06-01,Arrival and Camp Setup,Basecamp Area,2,Easy
2,2024-06-02,Mountain Trail Hike,Mountain Ridge Trail,8,Hard
3,2024-06-03,Lake Exploration,Crystal Lake,5,Moderate
4,2024-06-04,Forest Adventure,Ancient Forest,6,Moderate
5,2024-06-05,Pack and Departure,Basecamp Area,2,Easy


---
./notebooks/assets/extracted_tables.csv
---
Month,Due Date,Amount ($)
February,2025-02-05,"$5,000"
March,2025-03-05,"$5,000"
April,2025-04-05,"$5,000"
May,2025-05-05,"$5,000"
June,2025-06-05,"$5,000"
July,2025-07-05,"$5,000"


---
./notebooks/assets/extracted_text.txt
---
Sample Contract Agreement
This Contract Agreement is made on this 04th day of February 2025, between:
Party A: John Doe, residing at 123 Example Street, Sample City.
Party B: Jane Smith, residing at 456 Business Avenue, Business City.
Whereas Party A agrees to provide consulting services to Party B for a period of six months,
starting from February 05, 2025, under the following terms:
1. Scope of Services:
   Party A will provide business consulting services, including but not limited to market
   analysis, strategy planning, and financial guidance.
2. Payment Terms:
   Party B agrees to pay Party A a monthly fee of $5,000, payable on the first day of each month.
3. Confidentiality:
   Both parties agree to keep confidential all business and proprietary information exchanged
   during the course of this agreement.
4. Termination Clause:
   Either party may terminate this agreement with a 30-day written notice.
Signed and agreed upon by:
Party A: John Doe         Party B: Jane Smith
Date: February 04, 2025
Payment Schedule
Month
Due Date
Amount ($)
February
2025-02-05
$5,000
March
2025-03-05
$5,000
April
2025-04-05
$5,000
May
2025-05-05
$5,000
June
2025-06-05
$5,000
July
2025-07-05
$5,000

--------------------------------------------------------------------------------


---
./notebooks/assets/extracted_ticket_issues.csv
---
customer_name,issue_description,priority
Jane Doe,Customer was charged twice for the same transaction.,High
John Smith,"Customer unable to log into their account, facing a password reset issue.",Medium
Alice Johnson,Customer wants more information about product specifications.,Low
Bob Brown,"Customer has not received the order yet, tracking information shows a delay.",High
Michael Lee,Customer wants to return a product and needs assistance with the return label.,Medium


---
./notebooks/assets/file.txt
---
new file contentnew data

---
./notebooks/assets/invoice-data-sample.txt
---
EXEMPLO, UNIPESSOAL, LDA. AV. DA LIBERDADE, 120 - 2o ESQ 123456789 1250-140 LISBOA
EXEMPLO, UNIPESSOAL, LDA.
AV. DA LIBERDADE, 120 - 2o ESQ 1250-140 LISBOA
LISBOA
JOANA SILVA PEREIRA 0033
DATA ANALYST 12345678901
298765432
AFIN 0010.20.987654
123456789 Original
LISBOA
Recibo de Vencimentos
Recibo de Vencimentos Per√≠odo Janeiro
Data Fecho 31/01/2024 Vencimento 3.900,00
Per√≠odo Data Fecho Vencimento Venc. / Hora N. Dias M√™s:
Faltas Alim.
C√≥d.
R01 R06 R13 D01 D02 D05
Janeiro 31/01/2024
3.900,00 20,00 20.00
Nome
N.o Mecan. Categoria
N.o Benef.
N.o Contrib. Departamento Seguro
JOANA SILVA PEREIRA 0033
DATA ANALYST 12345678901
298765432
AFIN 0010.20.987654
Reten√ß√£o IRS
SDD IRS Retido Total Remun.
Venc. / Hora N. Dias M√™s:
20,00 20.00
Nome
N.o Mecan. Categoria
N.o Benef.
N.o Contrib. Departamento Seguro
Turno Data
01-2024 01-2024 01-2024 01-2024 01-2024 01-2024
CDD
SDH
Faltas
Alim. Turno CDH
Reten√ß√£o IRS
IRS Retido
CDH
Descri√ß√£o Remunera√ß√µes Descontos
SDH
SDD
Total Remun.
19.200,00
Descontos
500,00 1.200,00 150,00
CDD
Descri√ß√£o Remunera√ß√µes
Vencimento 3.900,00 IHT 650,00
5.400,00 19.200,00
5.400,00
Vencimento 3.900,00 IHT 650,00
C√≥d. Data
R01 01-2024 R06 01-2024 R13 01-2024 D01 01-2024 D02 01-2024 D05 01-2024
Subs√≠dio Alimenta√ß√£o Cart√£o Seguran√ßa Social
IRS (Venc. 29,18%) (29,18%) Desconto Subsidio Alim. Cart√£o
150,00
Subs√≠dio Alimenta√ß√£o Cart√£o Seguran√ßa Social
IRS (Venc. 29,18%) (29,18%) Desconto Subsidio Alim. Cart√£o
150,00
500,00 1.200,00 150,00
Formas de Pagamento: % Remunera√ß√£o
100,00
Forma de Pagamento Moeda
Formas de Pagamento: % Remunera√ß√£o
100,00
Forma de Pagamento
Transfer√™ncia
Moeda
Total
4.400,00 1.800,00 Total Pago ( EUR ) 2.950,00
Total
4.400,00 Total Pago ( EUR )
1.800,00 2.950,00
Declaro que recebi a quantia constante neste recibo,
Obs.
Declaro que recebi a quantia constante neste recibo,
Transfer√™ncia EUR
EUR

---
./notebooks/assets/python-logo.svg
---
<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="16 16 32 32"><path fill="url(#a)" d="M31.885 16c-8.124 0-7.617 3.523-7.617 3.523l.01 3.65h7.752v1.095H21.197S16 23.678 16 31.876c0 8.196 4.537 7.906 4.537 7.906h2.708v-3.804s-.146-4.537 4.465-4.537h7.688s4.32.07 4.32-4.175v-7.019S40.374 16 31.885 16zm-4.275 2.454a1.394 1.394 0 1 1 0 2.79 1.393 1.393 0 0 1-1.395-1.395c0-.771.624-1.395 1.395-1.395z"/><path fill="url(#b)" d="M32.115 47.833c8.124 0 7.617-3.523 7.617-3.523l-.01-3.65H31.97v-1.095h10.832S48 40.155 48 31.958c0-8.197-4.537-7.906-4.537-7.906h-2.708v3.803s.146 4.537-4.465 4.537h-7.688s-4.32-.07-4.32 4.175v7.019s-.656 4.247 7.833 4.247zm4.275-2.454a1.393 1.393 0 0 1-1.395-1.395 1.394 1.394 0 1 1 1.395 1.395z"/><defs><linearGradient id="a" x1="19.075" x2="34.898" y1="18.782" y2="34.658" gradientUnits="userSpaceOnUse"><stop stop-color="#387EB8"/><stop offset="1" stop-color="#366994"/></linearGradient><linearGradient id="b" x1="28.809" x2="45.803" y1="28.882" y2="45.163" gradientUnits="userSpaceOnUse"><stop stop-color="#FFE052"/><stop offset="1" stop-color="#FFC331"/></linearGradient></defs></svg>

---
./notebooks/assets/stock-trading-data.csv
---
Date,Stock Symbol,Open Price,Close Price,Volume,Moving Average (50-day),RSI (Relative Strength Index)
2024-01-01,AAPL,249.81604753894499,240.44463125267967,768234,240.44463125267967,0.0
2024-01-02,AAPL,480.2857225639665,483.01393078924207,478480,361.72928102096085,99.9999999991755
2024-01-03,AAPL,392.797576724562,389.08469634608855,891971,370.84775279600336,72.08628717206294
2024-01-04,AAPL,339.46339367881467,339.63480750210874,601157,363.0445164725297,62.85018546243832
2024-01-05,AAPL,162.40745617697462,170.55878565549648,4478727,324.5473703091231,43.70425516635878
2024-01-08,AAPL,162.39780813448107,157.38365271745857,4224499,296.68675071051234,42.69086234717363
2024-01-09,AAPL,123.23344486727979,121.44110332799238,2713501,271.6516582272952,40.151032131985446
2024-01-10,AAPL,446.47045830997405,451.58148108083503,3021944,294.14288608398766,61.2994115133675
2024-01-11,AAPL,340.4460046972835,335.02196800711596,4427576,298.6850062976686,54.50007399496815
2024-01-12,AAPL,383.2290311184182,374.7686293149941,3183153,306.2933685994011,56.15832534397662
2024-01-15,AAPL,108.23379771832097,104.02882677659633,2899487,287.90568297914615,44.98960734595926
2024-01-16,AAPL,487.96394086479773,481.18836660987785,3004941,304.01257328170715,56.923940008953124
2024-01-17,AAPL,432.9770563201687,441.57100936702017,2200021,314.59399144211585,55.65563718843324
2024-01-18,AAPL,184.93564427131048,191.09805186259882,1460828,305.7728529007218,48.783715212720544
2024-01-19,AAPL,172.72998688284025,175.39806201304873,718467,297.0812001748769,48.40905789532939
2024-01-22,AAPL,173.36180394137352,180.79101574512788,2235619,289.8130636480176,41.63791201738867
2024-01-23,AAPL,221.69689718381508,227.77033872179737,4055488,286.16349159353405,45.417601680738436
2024-01-24,AAPL,309.9025726528952,303.6339738306159,4774351,287.1340739400386,48.992457110142794
2024-01-25,AAPL,272.7780074568463,280.62918742664584,1807923,286.7917114919653,53.354793216676164
2024-01-26,AAPL,216.49165607921677,217.27850091752978,228391,283.3160509632435,51.77133454387677
2024-01-29,AAPL,344.74115788895176,350.889960992233,1117026,286.5338562027192,56.41513862905432
2024-01-30,AAPL,155.79754426081672,163.7193702592866,4401754,280.9513795689268,41.252355371660435
2024-01-31,AAPL,216.85785941408727,213.21792891352456,2369042,278.0064469317354,46.141310322071604
2024-02-01,AAPL,246.5447373174767,238.74577580803023,2083509,276.37058563491433,45.651692100787436
2024-02-02,AAPL,282.4279936868144,276.9866969376532,216381,276.39523008702395,56.4944086148513
2024-02-05,AAPL,414.07038455720544,412.61254032973056,1621701,281.63435740405106,46.85448412595569
2024-02-06,AAPL,179.8695128633439,186.22980818179377,1720197,278.1008555810045,40.00091069156513
2024-02-07,AAPL,305.69377536544465,312.90838703057153,2331660,279.3439817042034,55.282193712336074
2024-02-08,AAPL,336.965827544817,327.1048701554408,1878226,280.99090889217706,56.58721639602578
2024-02-09,AAPL,118.58016508799909,118.79511113955041,1299386,275.5843823004228,47.71138442962944
2024-02-12,AAPL,343.01794076057536,341.36616082355096,3538618,277.7063751560076,53.71220186610314
2024-02-13,AAPL,168.2096494749166,162.6518056843312,2114484,274.1109198600177,45.68303081460152
2024-02-14,AAPL,126.0206371941118,118.41794454078546,3037629,269.3929509109501,45.09672949429043
2024-02-15,AAPL,479.5542149013333,476.30651832940583,2557184,275.4786440703164,56.64634325839341
2024-02-16,AAPL,486.25281322982374,495.11100730807414,3243963,281.7538544485381,53.932206730841386
2024-02-19,AAPL,423.35893924658444,419.82299788699953,4203022,285.5891084329398,57.43639427621284
2024-02-20,AAPL,221.84550766934828,222.2213201042156,1518175,283.8764655051364,50.24072412248057
2024-02-21,AAPL,139.06884560255355,143.1292247804571,3906688,280.17259074922384,47.5146824198653
2024-02-22,AAPL,373.69321060486277,370.96580265244864,3872962,282.5006218236655,52.223595366382504
2024-02-23,AAPL,276.0609974958405,285.49663915025974,4291423,282.57552225683037,46.91924992763482
2024-02-26,AAPL,148.81529393791152,158.06423983675376,4141776,279.5386617099992,49.28299670251592
2024-02-27,AAPL,298.0707640445081,293.1064099610154,2827423,279.8617033350234,49.498043822617085
2024-02-28,AAPL,113.75540844608736,113.70037856393506,1860427,275.9974864798818,45.00852625049274
2024-02-29,AAPL,463.7281608315128,459.7457270278482,4418427,280.173582855972,57.492017880396645
2024-03-01,AAPL,203.51199264000678,199.20880252755614,3551356,278.37436551534046,46.92751210835186
2024-03-04,AAPL,365.0089137415928,355.7466526886834,1231565,280.0563717582392,54.21380866729698
2024-03-05,AAPL,224.6844304357644,226.87571711536233,3544084,278.92486846796527,52.28250247323439
2024-03-06,AAPL,308.0272084711243,308.08078893570155,3027109,279.53228347770977,45.99303939074358
2024-03-07,AAPL,318.68411173731187,309.7136867623117,4472578,280.148230483518,45.54760869187433
2024-03-08,AAPL,173.94178221021082,169.51471149494304,2609079,277.93556010374647,44.17049373940265
2024-03-11,AAPL,487.83385110582344,495.9991688251565,2987004,283.04665085519605,56.01500447357877
2024-03-12,AAPL,410.05312934444584,404.84436715778526,2031760,281.48325958256686,55.71966540626546
2024-03-13,AAPL,475.7995766256756,468.6974740675001,231373,283.0755151369951,52.30079207392284
2024-03-14,AAPL,457.93094017105955,457.7199953766108,215294,285.43721889448517,54.20184364413866
2024-03-15,AAPL,339.1599915244341,348.8730006066461,3232514,289.00350319350815,54.69788788353182
2024-03-18,AAPL,468.74969400924675,463.59079943947677,4942611,295.1276461279485,54.23991658599146
2024-03-19,AAPL,135.3970008207678,138.83971176888537,4435868,295.47561829676636,50.583059028870686
2024-03-20,AAPL,178.3931449676581,183.62553727423244,1526388,290.11649942063434,42.55561825063151
2024-03-21,AAPL,118.09091556421522,112.84366644406322,3951424,285.67293338937327,47.406139474884625
2024-03-22,AAPL,230.13213230530573,234.6964592775429,2315167,282.87148998862426,46.287063778045656
2024-03-25,AAPL,255.4709158757928,252.82657853017787,3986402,285.84744502369585,50.853998874263205
2024-03-26,AAPL,208.53961270955836,211.18572932142993,789944,280.4473922779269,46.72609587042781
2024-03-27,AAPL,431.4950036607717,434.1655978759896,788105,280.2992840481063,53.65786292085245
2024-03-28,AAPL,242.70133067743572,243.41682435893088,2710910,281.34565949803294,52.10943275321925
2024-03-29,AAPL,212.3738038749523,204.17959927604048,2089173,281.9212902432928,40.03660564763694
2024-04-01,AAPL,317.0784332632994,323.7844831750842,3180761,284.78115959189194,47.28516937026815
2024-04-02,AAPL,156.36968998990505,152.78529128933977,1514466,283.28145864324273,40.12808215751398
2024-04-03,AAPL,420.8787923016159,414.609162509613,545101,285.50096241682263,48.835409637912825
2024-04-04,AAPL,129.82025747190832,120.6357603030036,1205534,282.3010938743499,44.3950355893015
2024-04-05,AAPL,494.7547746402069,496.57263350397176,3327802,287.8869765260787,50.717855748479245
2024-04-08,AAPL,408.89790771866296,412.44919495550863,1683593,289.11816120534417,56.65192447086924
2024-04-09,AAPL,179.48627261366897,169.8180291922261,1903649,289.240134384003,49.69377408334523
2024-04-10,AAPL,102.20884684944096,102.45070801542659,1324665,287.024789966041,49.769153073562386
2024-04-11,AAPL,426.18457138193367,420.7144868858924,2394544,290.66416418759826,53.80022491988434
2024-04-12,AAPL,382.74293753904686,385.64639334723586,4453127,292.8373581157899,52.694771199679785
2024-04-15,AAPL,391.60286721639494,385.09019579649475,598863,292.2869112251252,53.5881536680571
2024-04-16,AAPL,408.5081386743783,412.3268934364276,467654,296.8088529302179,49.50980899608669
2024-04-17,AAPL,129.61786069363615,127.35256761964689,2776188,293.0977365419994,47.50055057727537
2024-04-18,AAPL,243.38629141770903,252.1208911924437,3395990,291.5980569627394,50.99573677885219
2024-04-19,AAPL,146.34762381005189,139.09804269297175,1592785,292.00411559380785,46.15356067050153
2024-04-22,AAPL,445.2413703502374,442.06269737124256,897079,294.0180463247617,55.71082541489443
2024-04-23,AAPL,349.3192507310232,341.588721155835,4958380,297.5967846341918,48.46036857374558
2024-04-24,AAPL,232.35920994105967,240.85308230663094,4142787,300.04548738950865,52.75965369170415
2024-04-25,AAPL,125.42334011440946,132.97012718202907,4028083,293.17875956656115,40.48195569969779
2024-04-26,AAPL,224.3929286862649,219.551761240568,2799015,287.667574645211,44.957002644503824
2024-04-29,AAPL,230.07332881069883,233.27300973138242,3514527,283.9365748820987,51.884483061316644
2024-04-30,AAPL,391.84247133522564,398.18691533924994,1386125,287.4558867867994,58.30176673973896
2024-05-01,AAPL,355.0229885420853,356.1270047740745,3840047,291.71584238667174,47.854180027357685
2024-05-02,AAPL,454.88509703053063,455.47810859765076,548982,293.4060885055758,52.22501220409276
2024-05-03,AAPL,288.8859700647797,283.72301588278873,1272622,293.37061604022637,47.087890273208856
2024-05-06,AAPL,147.83769837532068,139.69975373143868,2603771,293.00332631812006,42.660378518016394
2024-05-07,AAPL,385.297914889198,393.24223004826456,3277825,295.00604271986504,57.281468255953605
2024-05-08,AAPL,404.31401944675895,412.32238059002555,1096161,300.97848276038684,54.656725319183785
2024-05-09,AAPL,324.5108790277985,327.17290817326386,4283839,298.32702638329516,55.556994505632034
2024-05-10,AAPL,408.3868719818244,405.16746780279846,766326,302.4461996888,48.742721326305414
2024-05-13,AAPL,297.5182385457563,294.5024300380095,749150,301.2213152357865,48.40650832065659
2024-05-14,AAPL,309.0931317527976,313.61224533020237,3475957,302.9560458000833,52.60630343437891
2024-05-15,AAPL,271.0164073434198,278.95861254247137,218834,302.3736022722187,55.518990685487765
2024-05-16,AAPL,110.16765069763808,117.90937918294043,3339576,298.5375161206313,46.36229888289022
2024-05-17,AAPL,143.15657079732176,148.75408171447424,3298649,298.12230352502195,47.01175983234685
2024-01-01,MSFT,317.05785388303065,310.6066447586251,2585195,310.6066447586251,0.0
2024-01-02,MSFT,214.61650085131376,219.62879588413094,4360507,265.11772032137804,0.0
2024-01-03,MSFT,336.3333042276043,342.4699990129496,260775,290.9018132185685,57.451009148236174
2024-01-04,MSFT,112.20009997561976,122.01020281563324,2767867,248.6789106178347,28.286250559211382
2024-01-05,MSFT,114.93927549968576,113.1916290379143,1663299,221.58145430185064,27.723294479793907
2024-01-08,MSFT,429.0402242638633,426.48058597971897,3569401,255.73130958149537,57.659705703558615
2024-01-09,MSFT,244.07625656450514,249.6045157793451,3875803,254.85605332404535,46.731780591659465
2024-01-10,MSFT,150.8242050607539,147.64027586581426,1444027,241.45408114176644,42.12895249775626
2024-01-11,MSFT,308.89730402192174,317.51245053399305,4266500,249.90501107423609,50.28652444933443
2024-01-12,MSFT,407.99742123944435,415.16567627630457,891267,266.4310775944429,54.01300571129606
2024-01-15,MSFT,186.32841099873727,184.90829154623765,597562,259.01991522642425,45.90027474258883
2024-01-16,MSFT,349.15619032760014,354.17361168343007,3948693,266.9493899311747,51.27966903634119
2024-01-17,MSFT,134.1389859975072,139.22984347920084,4678238,257.12480943486906,45.530587783732955
2024-01-18,MSFT,120.67268846744308,112.73516584416173,4137776,246.81126346410426,44.90996215800694
2024-01-19,MSFT,312.54185262725923,320.59291076085054,2104168,251.730039950554,50.232069173117374
2024-01-22,MSFT,316.2540486440426,316.3590960929997,4110912,255.76935595945685,52.342334309271585
2024-01-23,MSFT,354.9719605992826,361.50110992143743,4611732,261.9888708983969,50.47885977093405
2024-01-24,MSFT,390.43653348906463,386.8375255096769,4985211,268.9249072656902,57.38913714422214
2024-01-25,MSFT,490.34083178501385,498.25129635493784,2279996,280.99471721775586,60.162032963787425
2024-01-26,MSFT,306.52013932047817,304.3041728951614,1700396,282.1601900016261,46.558910573026495
2024-01-29,MSFT,229.1825891764984,219.39934220610436,3411149,279.1715782018394,49.10279166687297
2024-01-30,MSFT,418.0744779074815,426.18211743586676,222402,285.85387543974974,57.78874381732581
2024-01-31,MSFT,208.3329005048297,200.15863404055236,1266588,282.1279953789151,46.81839738369948
2024-02-01,MSFT,275.5885682822544,271.9748410340627,4732965,281.7049472812129,46.06276635791406
2024-02-02,MSFT,131.3825525369064,140.38379187792248,2596081,276.0521010650813,48.70549724821046
2024-02-05,MSFT,110.140297366183,119.15244030493413,2777618,270.01749872815253,42.523435567193296
2024-02-06,MSFT,485.05936587117003,486.52812363363574,4867999,278.03641076168896,60.07157412431625
2024-02-07,MSFT,434.3920482048823,437.0287924482783,4757860,283.71471010763855,59.280616664655
2024-02-08,MSFT,378.38968243747917,377.35859287704557,675278,286.94380951348023,51.77507243246781
2024-02-09,MSFT,263.58117776570793,259.44539319966924,1278049,286.02719563635316,48.33842909638965
2024-02-12,MSFT,169.3177280283383,165.89101893573664,3180201,282.15183509762363,44.44623937363351
2024-02-13,MSFT,162.5748170684344,166.0251861899752,4772311,278.5228773192596,43.639675681868546
2024-02-14,MSFT,200.09715926583812,205.1446498545917,3662737,276.2992946688151,41.190396626875646
2024-02-15,MSFT,319.69066588244823,325.5222467569652,3564442,277.7470285537607,50.66723766501952
2024-02-16,MSFT,385.83836908002496,391.63073193591606,1374732,281.00084865039366,55.480896076158764
2024-02-19,MSFT,364.0789506870925,355.90307274806634,3414692,283.0814659864402,47.49028912475823
2024-02-20,MSFT,211.97355877837714,211.86196487242876,4293398,281.1566146049804,50.44392683438853
2024-02-21,MSFT,481.94611226527763,473.0972874656105,4819607,286.20768494341803,56.670378386847624
2024-02-22,MSFT,395.1587666783074,396.14934432478213,1210389,289.0267018506325,58.80168061787747
2024-02-23,MSFT,321.7416210045603,320.5722310320278,127712,289.8153400801674,56.68155785935817
2024-02-26,MSFT,344.6882984937409,352.44238214890686,4171647,291.34282891111224,44.278525573634276
2024-02-27,MSFT,267.84002497111595,264.85832522215753,4012942,290.71224548994667,42.88469956817045
2024-02-28,MSFT,199.09239580046298,191.4337361290151,212816,288.4034429466692,42.40264209794535
2024-02-29,MSFT,242.38907146050462,235.24890510156135,1735156,287.1953852683713,48.94753692580232
2024-03-01,MSFT,403.13844418574763,408.3686568200971,235230,289.8881246361874,59.86417196131647
2024-03-04,MSFT,105.75739545190234,108.12175671822756,1866616,285.93668185536217,48.106735316429884
2024-03-05,MSFT,146.4290562027665,138.4515097252223,4563418,282.7986994696145,47.806731960804726
2024-03-06,MSFT,118.4010568087011,110.08319293100105,1483194,279.2004597500601,42.458708729078175
2024-03-07,MSFT,116.29152092758805,120.31090355677046,3201360,275.9578157461154,40.115965189315816
2024-03-08,MSFT,442.1842336044029,433.63949373168674,1981548,279.11144930582685,52.35548284397663
2024-03-11,MSFT,381.46314375200944,387.90034493781656,4445760,280.65732330941063,55.67201744134991
2024-03-12,MSFT,289.6695316349301,293.79437617806,3351298,282.14063491528924,43.525498930978145
2024-03-13,MSFT,139.1336642604006,130.76063987323857,4565150,277.90644773249505,40.977905042331805
2024-03-14,MSFT,296.64635004673295,288.34310432843677,100404,281.23310576275105,48.96220960561991
2024-03-15,MSFT,289.3887083122263,299.1214998822498,4997590,284.95170317963783,48.259403927671215
2024-03-18,MSFT,169.28074796400608,166.7661638791285,1423483,279.757414737626,46.888838892053
2024-03-19,MSFT,273.5406596951892,270.95350263652705,1822320,280.18439447476965,52.47383173269717
2024-03-20,MSFT,259.40189375894937,265.6578851040994,2432517,282.54474665953535,50.969242009913806
2024-03-21,MSFT,346.3400392208866,355.2850107685638,4637090,283.30019786422673,48.212920238740715
2024-03-22,MSFT,354.0374603470575,363.75748162351493,3296340,282.27203397117097,60.71010877081398
2024-03-25,MSFT,118.1216039088178,123.18916761399663,263273,281.03765149252615,49.456341721497495
2024-03-26,MSFT,249.8450458505885,247.3702375612068,3954418,278.9015840100817,54.57781176239587
2024-03-27,MSFT,350.3439662856946,342.01398061966796,3752692,282.95726675289103,56.99864802849794
2024-03-28,MSFT,301.2545034320351,306.79744175058386,1187341,286.83851227101945,45.14308130246881
2024-03-29,MSFT,442.5959364753289,443.764021470045,4077266,289.30193448520333,51.999394728562095
2024-04-01,MSFT,363.477452647578,361.9618928325175,3131756,290.2139904199937,52.46143504178581
2024-04-02,MSFT,165.17377083257188,173.30085853446658,943523,286.4499853922543,51.5081566936548
2024-04-03,MSFT,128.22749896017194,120.45144860629497,646237,281.12226385418666,43.57035081396539
2024-04-04,MSFT,356.96771128252624,356.82021336834345,4995207,278.2936421944548,51.88410671678069
2024-04-05,MSFT,110.60452421664873,100.83159711199711,4140479,274.22419067879144,48.00781299306265
2024-04-08,MSFT,334.3102325093853,333.6834453492678,192193,276.5098727416547,51.75862572746189
2024-04-09,MSFT,476.092096569983,467.21816208361975,3281915,277.3305936346098,55.271665665089344
2024-04-10,MSFT,330.1896711503516,322.56602947571304,4800254,279.778741543313,49.168199854229734
2024-04-11,MSFT,255.26797048260877,247.61849541815087,1286887,279.2916146309948,47.1439815625403
2024-04-12,MSFT,357.3152873769413,360.29949341926255,3108038,283.68992866182157,56.222240892439764
2024-04-15,MSFT,283.30115619660666,288.2220537819151,608153,287.0713209313612,51.1021719657518
2024-04-16,MSFT,318.24671572637396,319.91409102831716,3434817,283.7390402792548,49.382784567490155
2024-04-17,MSFT,476.5859235106101,485.8293744801009,3682069,284.71505191989127,54.659890741590644
2024-04-18,MSFT,254.4410551203097,251.93846671078379,2815514,282.20664939656604,45.246931634896
2024-04-19,MSFT,484.4762255295657,480.1904672552029,4981713,286.6215508776767,52.731256021055934
2024-04-22,MSFT,462.14025678242547,469.5122393462147,2758571,292.69397528588627,57.45606060148091
2024-04-23,MSFT,178.31645391571857,172.7883706861076,4934357,292.8292389758089,51.17333974616576
2024-04-24,MSFT,127.74452035006618,137.0089711388784,1779748,291.46652540149466,44.58503642011211
2024-04-25,MSFT,140.31120055097065,130.554290044767,2323069,287.5671662672507,50.83484562815754
2024-04-26,MSFT,107.28873026061989,116.68630679477266,3545498,282.0682777644278,43.05007442265576
2024-04-29,MSFT,137.77718430237135,128.64038254138288,4992472,277.52302396029415,38.24028750316293
2024-04-30,MSFT,373.20270936654276,381.0255716405042,581680,280.90629609565565,51.889082798425285
2024-05-01,MSFT,128.4754593840916,129.0294815658176,2736694,274.0249399776598,46.56133792753862
2024-05-02,MSFT,227.59025211750452,237.44954803989052,3061293,270.85094405196196,46.42896180538625
2024-05-03,MSFT,437.95012438778184,429.42605568248985,4200673,273.02802054497124,53.83709379969436
2024-05-06,MSFT,109.30877429433035,110.38585998235676,1634026,268.1868901016402,45.075334101723186
2024-05-07,MSFT,425.7873930355743,435.1734437479563,415826,271.5931924721562,48.89214022000738
2024-05-08,MSFT,212.74190990935998,213.20386679276294,3567366,272.02859508543116,49.14842263991037
2024-05-09,MSFT,147.2659310486625,149.85390381136776,427359,270.32069505962727,42.169831191856886
2024-05-10,MSFT,378.6948661456603,382.6098399253526,3848603,269.80551872173237,48.13631034211169
2024-05-13,MSFT,351.5771387119536,350.66796000730903,4301253,274.65644278751404,54.30351250140395
2024-05-14,MSFT,450.98880541082116,453.5399670125024,2960337,280.95821193325963,57.41717097812705
2024-05-15,MSFT,394.02841752155433,395.71470376001633,417537,286.6708421498399,56.06734882936089
2024-05-16,MSFT,421.39237215393945,429.4155323637592,650222,292.8529347259797,57.091445535384274
2024-05-17,MSFT,212.8138290285226,203.72275663535177,2673619,288.25459998405296,51.55211360918565
2024-01-01,GOOGL,318.97852275964465,325.0958204944675,3317635,325.0958204944675,0.0
2024-01-02,GOOGL,280.3641789664417,271.47724875358125,2400119,298.2865346240244,0.0
2024-01-03,GOOGL,464.1885113613092,471.03479206727286,1999443,355.86928710510716,78.82163104853228
2024-01-04,GOOGL,219.18378061678018,210.21649017427043,3548503,319.45608787239803,38.82484648320421
2024-01-05,GOOGL,309.4409104060045,299.80576003457173,1539758,315.52602230483274,47.90500795354199
2024-01-08,GOOGL,379.05674859738536,382.9959778447138,1905468,326.77101489481294,54.2153725523354
2024-01-09,GOOGL,418.5887102695509,428.5338209649188,3527975,341.30855861911374,57.0624294080994
2024-01-10,GOOGL,283.73872317846894,291.6709284379494,226108,335.1038548464682,48.07720505662637
2024-01-11,GOOGL,436.83656600748384,438.35653436359706,3260110,346.5763747928159,55.57462083410677
2024-01-12,GOOGL,407.567096526159,415.9150087878696,3330019,353.51023819232125,54.37344858460595
2024-01-15,GOOGL,126.49439114074634,116.60039126869844,1807692,331.97297938108284,42.20645654071321
2024-01-16,GOOGL,118.34450656185318,127.84584982075603,2180154,314.9623852510556,42.688281197954254
2024-01-17,GOOGL,348.3222737688365,348.1372493540122,2344702,317.51429787435995,50.73419944434864
2024-01-18,GOOGL,238.9653632901657,243.4232852226012,3477778,312.2220826849486,47.5603639666293
2024-01-19,GOOGL,183.65231643140567,190.06954589447272,2630034,304.0785802322502,46.09122751353936
2024-01-22,GOOGL,331.85997378869536,336.2291192054264,4632131,306.08798891807373,51.77913024151113
2024-01-23,GOOGL,236.625284182618,237.32601882351622,2792755,302.04316714780566,43.20261321736483
2024-01-24,GOOGL,314.905366685628,314.4377563681562,488349,302.7317554378251,53.39394301241474
2024-01-25,GOOGL,284.0476635934288,290.8193147674813,1162729,302.10478487622805,49.694220052458085
2024-01-26,GOOGL,333.9064423796615,328.00799358265067,3224071,303.39994531154923,48.06846704040595
2024-01-29,GOOGL,260.1201955641126,269.4800768941973,3486501,301.78471348215146,44.463531090870816
2024-01-30,GOOGL,379.0670294787727,383.2860790555077,2079079,305.48932100821315,53.24103683594033
2024-01-31,GOOGL,172.02690893971942,166.0170474864858,4688334,299.4253091159641,40.82380234367047
2024-02-01,GOOGL,378.6005864908316,383.32553016480136,3622905,302.92115165966567,49.029388762856186
2024-02-02,GOOGL,264.66448574301126,265.2612862066336,176077,301.4147570415444,54.96343115440853
2024-02-05,GOOGL,449.72704194176686,453.87164385465576,4427819,307.27848345743325,59.7325393398807
2024-02-06,GOOGL,306.09442194568436,311.45001197454116,1355564,307.43298451362244,48.85141107514132
2024-02-07,GOOGL,489.2441397080417,480.9899432998352,2008327,313.63144732741574,57.14751510194826
2024-02-08,GOOGL,340.7741582163841,340.89623734357104,225885,314.57161250038666,54.312727947109984
2024-02-09,GOOGL,189.53962636252822,198.1799132076669,641656,310.6918891906293,46.04484240215325
2024-02-12,GOOGL,428.71625473777965,425.1290985809699,770688,314.3834120741887,55.01282580673374
2024-02-13,GOOGL,238.0330511289547,239.91071308011266,2385166,312.05614023062384,48.11926947902938
2024-02-14,GOOGL,239.0476857930734,236.43229542327134,4524507,309.76450856979494,48.613419513046836
2024-02-15,GOOGL,112.72187259406606,111.80723203844805,2151531,303.9422357306377,44.72328090306934
2024-02-16,GOOGL,319.48612368296347,320.45818604172655,2892427,304.4141200252402,51.15925114995228
2024-02-19,GOOGL,313.76940149300924,314.74784109078877,3020803,304.7011678326166,48.360843773184605
2024-02-20,GOOGL,242.39659370879446,236.43120295539916,3457679,302.85603364674586,51.80391512963453
2024-02-21,GOOGL,457.6869051583703,461.37833611596693,4490020,307.0276731854096,51.99181136590101
2024-02-22,GOOGL,151.49935931985755,143.25672154471067,2781719,302.82841801513524,47.17503514122369
2024-02-23,GOOGL,232.03980532406217,224.81630079290258,990695,300.8781150845794,44.41967830035757
2024-02-26,GOOGL,228.6331058720116,218.6873238602982,4294430,298.8734616400847,47.57933286359238
2024-02-27,GOOGL,136.91623449149844,129.25015577433206,938761,294.834811500424,40.420787093936426
2024-02-28,GOOGL,292.4581576225173,291.9214816435552,600315,294.76705964328744,48.68243379345276
2024-02-29,GOOGL,375.1138868384332,377.23592445954995,2514472,296.64135202547527,54.970659747368195
2024-03-01,GOOGL,304.6628054189045,310.54859441823373,1399445,296.95040185642546,46.5085385337544
2024-03-04,GOOGL,162.7910730864775,154.92505808874623,598716,293.862894383215,47.362778373111524
2024-03-05,GOOGL,250.91438609682905,257.92893529715815,3241069,293.09834206223513,50.628263537001125
2024-03-06,GOOGL,101.03800975345862,105.95750026443298,3421127,289.19957452478087,49.831724799885635
2024-03-07,GOOGL,447.32044281423475,445.4908086729531,2659272,292.389191548213,53.34485916906457
2024-03-08,GOOGL,133.80680307227277,142.46556441427185,2376106,289.39071900553415,46.02365859829505
2024-03-11,GOOGL,338.91123290217223,348.72982243132003,2102324,289.8633990442712,52.447350970265745
2024-03-12,GOOGL,494.5027983467261,488.60283454779085,4427021,294.2059107601554,50.61615770930439
2024-03-13,GOOGL,314.636258394933,312.220830094209,3424323,291.02963152069407,54.08624210131957
2024-03-14,GOOGL,469.6167036429733,478.1456921147675,4051416,296.38821555950403,55.886341440163655
2024-03-15,GOOGL,194.44661324696173,198.8785442619873,594592,294.36967124405237,49.59156800945247
2024-03-18,GOOGL,403.98216357503424,394.944056454316,3345886,294.60863281624444,55.24753386948184
2024-03-19,GOOGL,312.5063015894136,318.13659122444193,3954261,292.4006882214349,50.535933352229485
2024-03-20,GOOGL,388.20642455658594,394.7652423001358,3678226,294.4625744986786,50.359641017682414
2024-03-21,GOOGL,124.93654500449658,129.94658349980284,2129454,288.2943754814027,46.57326262400629
2024-03-22,GOOGL,159.09563676249067,165.08637938088097,2527540,283.27780289326296,50.202038019139565
2024-03-25,GOOGL,153.2467714349913,159.74942496884725,1815630,284.1407835672659,47.96901211814413
2024-03-26,GOOGL,374.86620216133247,368.59430189709536,418408,288.9557526087927,55.30812793629971
2024-03-27,GOOGL,437.77626905345153,432.49010397475155,568276,290.6428097012075,49.70429747926543
2024-03-28,GOOGL,399.84649280343496,402.5216640778385,2254697,293.82477727831224,56.75394098649786
2024-03-29,GOOGL,112.18886109343767,120.34618370268798,611411,292.4303100344766,44.29362931709337
2024-04-01,GOOGL,446.8859924298893,443.20992407581923,3022808,294.56992613188436,48.96084182346221
2024-04-02,GOOGL,241.65866831725018,243.42480183315132,3217172,294.6919017920771,48.44178195277802
2024-04-03,GOOGL,258.865533001633,262.52517426997565,984377,293.6536501501135,44.76826502990235
2024-04-04,GOOGL,141.94766661299235,140.98663863897315,4335042,290.6569966275433,48.47890603477875
2024-04-05,GOOGL,394.9620824375276,399.2377315346341,1998739,292.081591386583,50.10924520182749
2024-04-08,GOOGL,172.91355139038322,180.9069002962267,1329336,290.31012785462354,46.742984265645184
2024-04-09,GOOGL,325.5860368075346,328.06806769117134,1117433,289.20576762733685,48.468288590607585
2024-04-10,GOOGL,436.28399435117245,437.0796155894651,4761029,294.62701898939645,57.59702337057714
2024-04-11,GOOGL,135.68173148482248,134.45662499258927,2861089,289.64964088595224,49.33090285775684
2024-04-12,GOOGL,314.1342256062094,315.6839510243319,3778086,290.6580941823062,53.16325788124137
2024-04-15,GOOGL,193.28656461992048,190.3938136562884,1681530,285.38853757833886,46.25821438812072
2024-04-16,GOOGL,237.1707457113041,235.00038791533416,2187258,283.8595450971547,45.81932074099522
2024-04-17,GOOGL,289.5879765722225,290.22512616598596,4592816,280.0442487544777,47.64793430642889
2024-04-18,GOOGL,242.04172131172191,233.37410355953824,4956447,277.893806078797,52.614129684929075
2024-04-19,GOOGL,359.5291361166304,354.1096439351263,2849178,281.01240069334625,47.72672863273903
2024-04-22,GOOGL,291.8328407017001,292.68982691396826,1096530,278.3636152600062,51.35241546875361
2024-04-23,GOOGL,333.6797938856677,332.31035674839654,871253,280.2116081333719,51.89438870720778
2024-04-24,GOOGL,394.72899015796514,391.38530587621483,2701623,283.31066834243074,57.03593036484303
2024-04-25,GOOGL,323.09690638017497,327.707889116361,1478246,287.628681483989,47.74333106208003
2024-04-26,GOOGL,334.61417386430367,338.4885260123704,4208997,287.9892882834019,55.72065355846042
2024-04-29,GOOGL,325.7834170090565,319.11803220892415,3003540,288.0766921057646,49.64185925504659
2024-04-30,GOOGL,251.50905038051573,259.0816326879845,3464695,288.5297007004163,42.58674452459067
2024-05-01,GOOGL,234.97873354876725,234.88720607684655,4078400,283.9998780996339,55.44569412253601
2024-05-02,GOOGL,459.85895885800494,464.68817708078586,4677456,290.4285072103554,57.67522073295861
2024-05-03,GOOGL,343.02208891742913,344.4851059025769,2291422,292.8218833125489,57.97907191600143
2024-05-06,GOOGL,197.7412621858618,207.69511450433868,1145482,292.6020391254297,48.709312271390715
2024-05-07,GOOGL,299.29907913957607,304.34714154035254,1395302,296.1039788407501,50.64237271022006
2024-05-08,GOOGL,232.1393925123656,236.27900173723478,4102640,294.99112924262374,50.13080125655255
2024-05-09,GOOGL,473.47672950394985,479.0481682849649,670451,297.027374119132,55.068672548274535
2024-05-10,GOOGL,103.01374525362989,95.87630496459929,119816,292.73392833005926,43.66837456099237
2024-05-13,GOOGL,190.1331190850113,184.22401094840055,1067344,293.3199073872524,45.38078159384873
2024-05-14,GOOGL,246.14272786962306,250.42400951409533,2955059,293.1698088715911,45.6224894019015
2024-05-15,GOOGL,295.12392032349516,295.0035500661124,2512149,296.9507298676247,48.97218509723965
2024-05-16,GOOGL,440.3270071344585,445.41971297166083,3452252,296.94930795359886,53.08942533009704
2024-05-17,GOOGL,135.15504981605756,127.21337043094046,3832839,296.6442640739322,45.27197014234667
2024-01-01,AMZN,300.87800413249704,308.35580568374735,4215625,308.35580568374735,0.0
2024-01-02,AMZN,338.1540069280175,340.10226897142365,559297,324.2290373275855,99.99999999370009
2024-01-03,AMZN,126.830590955371,128.84092816404407,1120154,259.09966760640503,13.06396862664802
2024-01-04,AMZN,399.98418815967113,403.28492165059623,4177151,295.14598111745283,59.172749655695576
2024-01-05,AMZN,183.9622372382343,177.4696628107033,4834963,271.6107174561029,41.19521430780735
2024-01-08,AMZN,459.2217157762855,467.5099546947847,2903696,304.26059032921654,57.70120087044258
2024-01-09,AMZN,182.05585619280288,180.43126669064435,2193373,286.5706869522777,45.15579022037546
2024-01-10,AMZN,176.27508826546662,173.93785883045658,2472280,272.49158343705005,44.93480935848804
2024-01-11,AMZN,114.61986713923795,114.99822124489471,3016623,254.992320971255,43.023707531806274
2024-01-12,AMZN,288.8267780439997,279.7660973795008,2806871,257.4696986120796,49.07810045194225
2024-01-15,AMZN,325.9364533050466,319.2621206801682,970123,263.08719152736035,50.342947981783254
2024-01-16,AMZN,126.28345577134095,131.04412809986837,3086249,252.0836029084027,45.01457626661821
2024-01-17,AMZN,410.2110466780042,401.86702003650674,1959582,263.6054042259492,52.28173649978135
2024-01-18,AMZN,281.315533899211,283.37857608853875,4544499,265.0177736447055,49.42385385297485
2024-01-19,AMZN,309.756107731032,304.6630899246584,2229885,267.6607947300357,49.915648930241154
2024-01-22,AMZN,276.3050987752913,274.0910110561308,4820642,268.0626832504167,48.49132465915436
2024-01-23,AMZN,260.3052243501304,256.0790990855444,2307148,267.357766534836,53.18976918347875
2024-01-24,AMZN,323.85613252328716,320.96958685258613,4852525,270.3362009969332,47.69414434087686
2024-01-25,AMZN,162.09609837228498,166.4770164759699,649239,264.8699281274088,49.679252253340344
2024-01-26,AMZN,172.77125219810844,168.71368651057193,656701,260.062116046567,39.5217528948094
2024-01-29,AMZN,444.7142484054069,446.0423412113449,3147569,268.91831724488975,59.37863625340425
2024-01-30,AMZN,478.4461848534531,477.9671928974351,4728120,278.42053886545995,60.5457748979142
2024-01-31,AMZN,249.32372651190119,252.59714981915414,1370464,277.2977828199684,54.27882641339416
2024-02-01,AMZN,208.2978692574215,217.03446404391667,885332,274.78681120429957,47.87882460975234
2024-02-02,AMZN,357.59981729560633,362.25125923981136,867950,278.2853891257201,51.35662016667098
2024-02-05,AMZN,263.49366843923855,257.7924760110537,266472,277.49720015977135,54.223082881396934
2024-02-06,AMZN,110.15454226413794,100.77820496536364,497710,270.9520521896081,39.14488893709939
2024-02-07,AMZN,162.46103894647615,157.70631983247264,4417048,266.90756174828186,45.25869713002943
2024-02-08,AMZN,386.388891538959,388.2904501529641,3288729,271.0931785898226,52.724742392371695
2024-02-09,AMZN,363.56957676406057,354.59809303374556,4885956,273.8766757379534,52.61775497733168
2024-02-12,AMZN,110.83839700139339,110.76572194541812,2950171,268.6150320672264,45.88004889154466
2024-02-13,AMZN,188.7888647731798,190.72572175151757,1010775,266.18099111986055,46.33858942955282
2024-02-14,AMZN,192.42991863522855,189.11479645156777,2696874,263.84565188748803,50.69623830872162
2024-02-15,AMZN,368.75709743949136,374.1753415144078,658924,267.090642758868,55.68030401729294
2024-02-16,AMZN,107.88421510174567,100.0161801644211,3981185,262.31708668474096,40.416778941644885
2024-02-19,AMZN,141.64343279382953,133.1461884285457,4473656,258.72900617762446,40.45652647742335
2024-02-20,AMZN,419.96643414927576,424.53020927334785,4112595,263.2101197748061,54.590772049292156
2024-02-21,AMZN,171.41786482173345,171.32769114585741,2390435,260.7921611266759,48.90665894640715
2024-02-22,AMZN,361.0984431407499,364.86649106930463,531413,263.4607336893074,50.061144805366624
2024-02-23,AMZN,195.2731124186906,193.96965919076553,1452564,261.72345682684386,48.552766691383724
2024-02-26,AMZN,139.77655710373807,134.70459776852022,2524050,258.62543587420186,50.8049940865533
2024-02-27,AMZN,197.26887639978162,203.6509227532656,4265100,257.3165188951319,51.08397593180843
2024-02-28,AMZN,388.9067727422637,394.8950903216433,963561,260.51602055621356,50.15877125884335
2024-02-29,AMZN,442.2785872425143,446.1725166596028,402186,264.73548637674514,52.18293366557681
2024-03-01,AMZN,432.0879458267966,427.5308485713959,3307393,268.35316109218184,58.459172484183334
2024-03-04,AMZN,258.87341184738193,260.67802518476367,3928464,268.18631031158577,51.785216830530324
2024-03-05,AMZN,367.2340546282585,364.453532567059,1126553,270.23454908297884,54.25295610006574
2024-03-06,AMZN,181.9937181663284,173.82535963286108,1335202,268.22602430276805,45.153469856518925
2024-03-07,AMZN,217.2590921044053,225.60536361365018,245271,267.35621490094934,53.404306619426634
2024-03-08,AMZN,458.5343274084479,451.2707000268271,2315685,271.03450460346687,57.80827451604578
2024-03-11,AMZN,105.20076940429442,114.20551648071047,3843797,267.15149881940613,42.550228090974606
2024-03-12,AMZN,134.2034123417872,133.12352780094633,1614542,263.0119239959966,48.96661454961544
2024-03-13,AMZN,183.1545020584109,176.8571606351833,4280656,263.97224864541937,44.46604990861317
2024-03-14,AMZN,110.61288154952788,111.45090049709505,3030184,258.1355682223494,47.41028180884046
2024-03-15,AMZN,172.57417403591893,180.03309075344708,176898,258.18683678120425,51.414290806177256
2024-03-18,AMZN,333.2166243878769,337.8611221160681,3395097,255.59386012962986,53.967433045753054
2024-03-19,AMZN,268.5698202369992,274.7010431942282,388316,257.47925565970155,46.15579397335698
2024-03-20,AMZN,457.0686844307899,460.24435176500424,2108954,263.2053855183925,50.41446745831382
2024-03-21,AMZN,426.9774246953764,430.8229559857334,1929553,269.5218802132093,50.09635286245432
2024-03-22,AMZN,236.7269406791504,243.71085371045677,4188657,268.8007753398284,49.5092276154888
2024-03-25,AMZN,203.769373372517,198.76273354970073,3141341,266.3907875972191,45.038579174883324
2024-03-26,AMZN,251.87696326690676,251.66546253976958,1139504,268.8032142860171,52.540363253093645
2024-03-27,AMZN,336.1179770059231,330.5421658423151,4187810,267.37671720213325,53.365164404520385
2024-03-28,AMZN,207.22545632915052,216.97881648908344,2205058,266.04872201014416,41.90456145681283
2024-03-29,AMZN,349.65956313965364,358.5407499333859,1775843,267.1262752103187,59.761244119810755
2024-04-01,AMZN,263.7646608764962,254.5531971038663,134701,266.7355189312734,54.54239043573162
2024-04-02,AMZN,320.8188723407921,324.93037579110586,3329028,268.11254446538464,55.430806578488735
2024-04-03,AMZN,274.45061165412665,282.95557800243995,1821610,267.3522642883817,56.400194990115885
2024-04-04,AMZN,217.7863038167671,211.39781071931375,2280712,268.2506801732486,51.167871926247564
2024-04-05,AMZN,479.3813227848627,480.74022739591527,2439767,274.49121099095544,54.912198774155485
2024-04-08,AMZN,405.4423176639043,413.75208361566513,2714235,273.84540583904186,54.7680391353107
2024-04-09,AMZN,156.04527030658102,146.72418987829698,591036,267.22054577865913,39.81840763064348
2024-04-10,AMZN,447.3871903591651,451.33559570410193,427304,271.195314696358,50.56513877428396
2024-04-11,AMZN,294.97247929980546,290.9194594472565,2562616,272.67301460442485,51.32005066561015
2024-04-12,AMZN,457.82089075763656,466.3088146651672,2810241,274.754165712932,56.972512191454484
2024-04-15,AMZN,419.9421023789261,429.36326728223344,3533803,278.18558153835556,54.669818139447706
2024-04-16,AMZN,270.0854017876934,278.9707315699621,1242953,281.74943207044754,48.69382266670374
2024-04-17,AMZN,108.98772332804695,108.47200766119623,4061352,280.764745827022,47.32882828605089
2024-04-18,AMZN,207.47094375397842,214.7117967737647,4078702,277.293172759438,46.39661762141176
2024-04-19,AMZN,316.65368586434676,323.5446738350482,4159175,276.672104375464,51.724274318378875
2024-04-22,AMZN,353.39128793045893,349.77329739532405,426916,281.45225588446215,50.634899236194045
2024-04-23,AMZN,203.15507417328092,209.73338365629448,3697706,281.83240912255775,48.21801417093815
2024-04-24,AMZN,155.74242962912965,146.4825823234395,4606554,280.97976483999514,48.41376462882893
2024-04-25,AMZN,433.9720947197196,435.8974922893607,705409,282.21420785549424,48.9148903420763
2024-04-26,AMZN,493.76087228142086,488.36104902717494,1174135,289.9811052327493,51.818176925570356
2024-04-29,AMZN,310.27607292107433,302.6874106366199,3089179,293.3719296769108,53.95765818503393
2024-04-30,AMZN,168.6717143393214,160.21077837190558,1825690,288.0855410588819,41.95015296999319
2024-05-01,AMZN,208.9229306077476,212.84870612531037,3380772,288.915961358471,47.70445605101222
2024-05-02,AMZN,107.3562706189867,104.15376989434802,4257893,283.70170693497187,38.91672267550138
2024-05-03,AMZN,465.7195226241996,470.2148580547748,503119,289.22661091225206,51.040589608392644
2024-05-06,AMZN,147.10043315605645,138.4075599720353,4266769,289.3006701563223,46.72243124495241
2024-05-07,AMZN,330.6065902057014,326.9123969623136,4420295,291.76589964050333,55.05104932143977
2024-05-08,AMZN,209.6220882748824,210.41191412238913,502732,288.0762361165182,49.901042360328205
2024-05-09,AMZN,321.67120100631735,327.4856643030966,606079,285.7024990693881,50.09035535443404
2024-05-10,AMZN,360.5681553407457,356.9432053993871,2050013,284.2907462059479,50.16414193768695
2024-05-13,AMZN,431.89672148288065,434.4145490116208,2723836,287.7654766824851,55.29536548363828
2024-05-14,AMZN,182.56850870424128,190.28806366896504,1232658,284.28216730452317,50.95131510905068
2024-05-15,AMZN,104.3983314633922,106.71559522703829,2085209,282.9399720164067,42.149333533043254
2024-05-16,AMZN,154.7542520275229,149.41344152259558,4422626,281.4161335745856,41.878600978318175
2024-05-17,AMZN,460.00745673924206,450.4954723703728,756951,281.40062902145655,53.355972054616664
2024-01-01,TSLA,364.84480404262587,357.9179648058481,1668560,357.9179648058481,0.0
2024-01-02,TSLA,317.5115631989597,316.58543589106534,4760061,337.2517003484567,0.0
2024-01-03,TSLA,445.7971521229394,446.40423999750453,2705214,373.63588023147264,75.85030266055057
2024-01-04,TSLA,393.5639675814807,383.9212054310471,2329180,376.2072115313663,55.56494339622256
2024-01-05,TSLA,308.50412487216596,314.44008142944654,2428599,363.85378551098233,42.828165404426656
2024-01-08,TSLA,447.2643216206188,443.1476810874883,1095843,377.0694347737333,59.86859179163738
2024-01-09,TSLA,198.11421290213383,206.35093360133206,4288891,352.6810774633903,38.66567947661914
2024-01-10,TSLA,162.9362638810104,172.28648915328597,726045,330.1317539246272,36.79126030697811
2024-01-11,TSLA,164.16004213202882,157.8692196255619,4131419,310.9914723358422,36.05157495260047
2024-01-12,TSLA,233.60355149809516,232.84549731340837,4595511,303.17687483359884,42.10478675825596
2024-01-15,TSLA,195.476012520407,185.50064922373554,1524945,292.4790361417931,39.730006109575754
2024-01-16,TSLA,472.03614020389546,474.002685506344,1491538,307.6060069221723,55.14594277291798
2024-01-17,TSLA,142.3336375314336,144.47976649668703,2463999,295.05783458175034,42.67767179508086
2024-01-18,TSLA,379.5962952158351,374.5470943279026,820488,300.73563884933264,50.49271057994203
2024-01-19,TSLA,175.68861591400236,176.8568693656663,4890691,292.47705421708827,45.19784114900441
2024-01-22,TSLA,452.65485310814006,447.1656559570148,519065,302.1450918258337,53.088198044833995
2024-01-23,TSLA,484.52611527396294,477.74262465552675,2884372,312.4743584628744,50.77765071732915
2024-01-24,TSLA,286.1880035079934,289.2183928440387,4325889,311.1823603729391,47.78833111601987
2024-01-25,TSLA,451.62859209125264,448.14710137029414,1563807,318.39103095174727,52.99733944584054
2024-01-26,TSLA,102.05806830188591,103.86334707959836,3192195,307.66464675813984,43.06451955128772
2024-01-29,TSLA,427.97876696324005,426.64370194267315,1716449,313.3303160526414,54.35019350501581
2024-01-30,TSLA,191.4500646099694,201.13709275802748,389102,308.2306240847044,50.52967398149903
2024-01-31,TSLA,463.4805237077471,456.47213656109847,1436737,314.675907235852,55.036569722749725
2024-02-01,TSLA,100.4480445920438,99.74001652476001,3160006,305.7202451228898,47.94976557268081
2024-02-02,TSLA,322.4726940159028,326.0818265430893,2477074,306.5347083796978,52.05221950501768
2024-02-05,TSLA,402.65432151397385,400.56522319157324,2897753,310.151266641693,48.8564998267339
2024-02-06,TSLA,203.47533227916318,212.969329316577,1190805,306.55193562965167,51.115772218209415
2024-02-07,TSLA,177.25314583491723,181.69089839345594,4543778,302.09261287121615,46.64056476611605
2024-02-08,TSLA,133.63928978719386,136.77896693848373,4262065,296.39214232181155,49.26261998065242
2024-02-09,TSLA,230.5734306013172,235.71461595354165,3110087,294.3695581095359,45.847737758607934
2024-02-12,TSLA,323.9377249235318,332.99069768430616,360116,295.61540132162526,47.23006715705104
2024-02-13,TSLA,146.33754271210307,154.49391577179588,3068462,291.2053548981931,47.41201789523343
2024-02-14,TSLA,250.67814479471951,255.16385095724775,3142146,290.11318811210384,46.208025964321834
2024-02-15,TSLA,103.62896186108999,108.61219464311566,2718137,284.77492359831007,50.101172957104076
2024-02-16,TSLA,427.4717681999367,420.3902096806396,4314279,288.6496460578052,49.86614345508888
2024-02-19,TSLA,151.37948723727655,143.43533532712985,4452099,284.6159152041753,48.79150606361252
2024-02-20,TSLA,213.33717930623266,214.75526934311594,3662223,282.72778964036286,44.51472884122674
2024-02-21,TSLA,107.37108749528699,97.73844023409778,1357949,277.85964886651385,49.94903328406674
2024-02-22,TSLA,272.89631355700493,272.54344118803675,3071981,277.72333584911695,48.59999210611695
2024-02-23,TSLA,436.0486010964875,430.2555926948649,3950241,281.53664227026064,50.744006474908595
2024-02-26,TSLA,256.8604845780786,253.78081593097542,4059076,280.8596708961317,51.02842092124448
2024-02-27,TSLA,171.79892936953337,177.31502408539248,3834340,278.3943221625427,49.892186353499824
2024-02-28,TSLA,401.4795336202077,410.30428370485544,3421765,281.46199568678253,56.16757354622735
2024-02-29,TSLA,415.5227927482977,406.97111819122455,488076,284.3144757437017,54.035557791549216
2024-03-01,TSLA,169.50139012302674,170.18623424255563,4984797,281.77829259923175,46.40028647855301
2024-03-04,TSLA,408.3416434163959,415.9923131327879,3209244,284.69598869778736,55.61477701999252
2024-03-05,TSLA,478.9191553025352,470.56932599134365,4916909,288.65074055509706,54.71848680961687
2024-03-06,TSLA,166.55103477290893,173.04131571084562,2298611,286.2422108708418,51.32377047225706
2024-03-07,TSLA,408.3937170128542,405.54974403141966,2060826,288.6770584863638,49.68481893339739
2024-03-08,TSLA,383.4288018410517,379.8706958854384,2944664,290.5009312343453,55.62138180563937
2024-03-11,TSLA,289.42955537403543,298.97888310033113,2713275,289.322149600235,51.993390136622544
2024-03-12,TSLA,123.16818422351932,117.1853660207652,1478369,285.334148202829,50.446573478154306
2024-03-13,TSLA,129.8777671031416,133.74164591959521,2523970,279.08089632127076,46.56278093376989
2024-03-14,TSLA,440.96586367945906,447.3946782396564,2190212,280.35036577744296,50.39399452139797
2024-03-15,TSLA,496.0593491002588,486.8830190058443,4271774,283.7992245289709,55.71874266608974
2024-03-18,TSLA,370.42090287470177,373.82861204179,2341984,282.41284314805694,54.73608138041352
2024-03-19,TSLA,278.3833228041286,287.4143222912352,252999,284.034110921855,46.8131325807477
2024-03-20,TSLA,359.02945736076305,351.51385669532425,4642923,287.61865827269577,48.605785031626354
2024-03-21,TSLA,337.75834369141813,345.6827697451189,161367,291.37492927508697,54.99170727500088
2024-03-22,TSLA,253.44490416224872,255.34043690978743,853315,291.8248280670145,44.987201743818815
2024-03-25,TSLA,126.25045782960518,128.58254946685466,4700108,290.6864660718769,39.788988912165486
2024-03-26,TSLA,428.60517896297637,430.8640624602885,3105334,289.8236936109558,57.67625911243684
2024-03-27,TSLA,248.73341169548985,244.71012942223612,2954190,291.8283008694667,45.07532429307809
2024-03-28,TSLA,427.5142573428375,436.21829364882666,1384382,293.06172485588525,51.56623246581848
2024-03-29,TSLA,201.00349987535287,209.95050912797365,3953321,293.7235976511314,47.710413597444244
2024-04-01,TSLA,100.41179193825336,102.91788514253231,2754837,286.8386422348417,49.61840252544265
2024-04-02,TSLA,163.5753133107026,169.2437678295349,3584239,280.6686650983219,50.924914596597056
2024-04-03,TSLA,287.4157667074337,289.66092642505686,1142377,280.67751576994226,45.430589742396165
2024-04-04,TSLA,477.72145398313194,477.40942293461273,4677033,281.26276220122867,49.74726766906347
2024-04-05,TSLA,140.8774478774876,144.09385024347262,3357181,282.0673722645061,44.51575144513261
2024-04-08,TSLA,441.6839097846264,442.7439388364656,1023780,282.38937700238193,53.36687600738867
2024-04-09,TSLA,310.8096384847448,312.7591557373834,2966451,284.62181826196905,49.183292205652116
2024-04-10,TSLA,430.36830631995866,436.0449573883359,2568152,284.2132746785138,51.814449276945005
2024-04-11,TSLA,219.34977239599704,218.96784902497674,4507871,286.59783132851817,49.30501961549285
2024-04-12,TSLA,435.97886586898875,426.7939479908382,2042811,288.6120737574731,55.52678306837677
2024-04-15,TSLA,409.1291120067218,402.40910162651176,398090,288.6489513261719,49.41208232448645
2024-04-16,TSLA,192.02147321257357,190.79361754236433,417348,288.20543709068767,48.89761118197131
2024-04-17,TSLA,152.53405056375124,157.0305817612324,1426283,287.7122307580432,43.89805589315356
2024-04-18,TSLA,447.22172901291714,449.0873019791207,192324,293.9583974588559,55.08048542410401
2024-04-19,TSLA,485.2946613760528,488.30054509352186,2420688,299.0101160416555,58.43042997262335
2024-04-22,TSLA,112.5209254990065,112.10650407053224,1905808,294.59243216938006,48.89931518419038
2024-04-23,TSLA,392.50802678947423,394.82286722831907,1420567,299.39901119851055,51.90660549397375
2024-04-24,TSLA,463.80980437912734,460.3901531354206,4320459,303.503537242074,49.67713340620532
2024-04-25,TSLA,442.94403683699943,442.3476886909327,4636119,310.1782471230303,56.4268390771359
2024-04-26,TSLA,485.8081889080834,490.6937702199825,4115470,311.5843183338172,51.15816744345739
2024-04-29,TSLA,404.03763137523885,411.47428695470126,4754798,316.9450973663686,52.44428111941523
2024-04-30,TSLA,276.9195049523641,275.5926116314919,3377419,318.16184421213615,46.05167490256173
2024-05-01,TSLA,224.78079619805217,215.6540293521994,3722138,320.5201559944981,49.91162041722375
2024-05-02,TSLA,228.29709617525097,221.530547058187,2640476,319.4998981119012,43.86473400191991
2024-05-03,TSLA,389.7690690456468,380.18629183147755,4329011,318.4985120946334,49.3851205498092
2024-05-06,TSLA,398.3348048123857,401.4000651971323,1037841,321.4508970799566,56.51352756072909
2024-05-07,TSLA,180.14365741948507,176.78994992658724,1667053,321.44039559678043,50.54658415873959
2024-05-08,TSLA,447.2491253962124,448.09869811059974,2016545,322.19628388489537,49.97233566518163
2024-05-09,TSLA,385.9696160808991,385.8351530165751,2943940,321.77356458140235,47.16920534599879
2024-05-10,TSLA,325.1001145373531,316.73064432840164,4647603,324.7044527831193,56.8083459055974
2024-05-13,TSLA,288.6129840410051,286.6782112634818,4032441,322.11817074573315,45.67449391144966
2024-05-14,TSLA,317.2931223159833,311.70434481442976,1307068,318.94087112219484,43.85362071056027
2024-05-15,TSLA,163.6982953117058,162.06629108505885,4464406,318.7213706296791,39.5505927854215
2024-05-16,TSLA,181.48049971050966,175.5520653173545,494274,314.12141705539784,37.93739130137537
2024-05-17,TSLA,136.46579616247666,143.27484428801534,4511589,309.3895000234494,39.35152657508363


---
./notebooks/assets/trip_plan.csv
---
Destination,Departure Date,Return Date,Budget (USD),Accommodation,Activities
Paris,2025-06-10,2025-06-20,1500,Hotel,Sightseeing
Rome,2025-06-12,2025-06-22,1800,Airbnb,Museum visits
Berlin,2025-06-15,2025-06-25,2000,Hostel,Food tour
Amsterdam,2025-06-18,2025-06-28,1700,Hotel,Biking


---
./notebooks/assets/papers/paper1.txt
---
https://arxiv.org/pdf/2412.14161

The paper titled "TheAgent Company: Benchmarking LLM Agents on Consequential Real World Tasks" introduces a new benchmark, TheAgentCompany, aimed at evaluating the efficacy of large language model (LLM)-powered AI agents in completing real-world professional tasks in a simulated software company environment. The research is conducted by a collaborative team, mainly from Carnegie Mellon University and other institutions, and emphasizes the growing presence of AI in work settings.

### Key Points from the Paper:

1. **Motivation**:
   - The rapid advancements in LLMs are prompting questions about AI's potential to automate or assist in various work-related tasks.
   - Understanding AI agents‚Äô capabilities is crucial for businesses considering AI integration and for policymakers assessing AI‚Äôs impact on employment.

2. **Benchmark Overview**:
   - TheAgentCompany simulates a software company environment with 175 diverse professional tasks spanning categories like software engineering, project management, and finance.
   - The benchmark allows agents to interact through web browsing, coding, and colleague communication, providing a realistic testing framework.

3. **Performance Findings**:
   - Experiments conducted with several LLMs, including closed (like OpenAI's GPT-4o and Claude) and open-weight models (like Llama), reveal that the top-performing model, Claude-3.5-Sonnet, achieved 24% task completion autonomously, with a score of 34.4% when accounting for partial completions.
   - Despite these advancements, LLM agents struggle significantly with longer, more complex tasks, especially those requiring social interaction and navigation of intricate user interfaces.

4. **Framework and Design**:
   - TheAgentCompany provides a self-hosted and reproducible environment utilizing open-source software.
   - Tasks are structured into parts with defined checkpoints, allowing agents to receive partial credit for incomplete tasks.
   - Evaluators for tasks are tailored to assess not just the success of task completion but also the quality of interactions with simulated colleagues.

5. **Interaction and Collaboration**:
   - A significant component of the benchmark involves the ability of agents to communicate effectively with simulated colleagues within the environment, enhancing the realism and complexity of tasks.

6. **Future Directions**:
   - The paper suggests that while TheAgentCompany provides a foundational step for understanding LLM capabilities in professional settings, there is a need to expand the tasks covered and include more creative or less straightforward tasks.
   - Continuous improvements in LLMs are expected, highlighting their potential for increased efficiency and performance across various domains.

7. **Conclusions**:
   - The research underscores the current limitations of LLM agents in effectively automating diverse professional tasks.
   - The results serve as a litmus test for future developments, pointing towards areas where LLM technology must improve, particularly in tasks involving human-like social interactions and complex decision-making.

In summary, TheAgentCompany represents a significant effort to quantify AI agents' performance in real-world applications and to chart a course for further research in this rapidly evolving field.
append thisnew data

---
./notebooks/assets/papers/paper2.txt
---
https://arxiv.org/pdf/2408.08435
2024-8-19
Automated Design of Agentic Systems
Shengran Hu1,2, Cong Lu1,2 and Jeff Clune1,2,3
1University of British Columbia, 2Vector Institute, 3Canada CIFAR AI Chair
Researchers are investing substantial effort in developing powerful general-purpose agents, wherein
Foundation Models are used as modules within agentic systems (e.g. Chain-of-Thought, Self-Reflection,
Toolformer). However, the history of machine learning teaches us that hand-designed solutions are
eventually replaced by learned solutions. We formulate a new research area, Automated Design of
Agentic Systems (ADAS), which aims to automatically create powerful agentic system designs, including
inventing novel building blocks and/or combining them in new ways. We further demonstrate that there
is an unexplored yet promising approach within ADAS where agents can be defined in code and new
agents can be automatically discovered by a meta agent programming ever better ones in code. Given
that programming languages are Turing Complete, this approach theoretically enables the learning
of any possible agentic system: including novel prompts, tool use, control flows, and combinations
thereof. We present a simple yet effective algorithm named Meta Agent Search to demonstrate this idea,
where a meta agent iteratively programs interesting new agents based on an ever-growing archive of
previous discoveries. Through extensive experiments across multiple domains including coding, science,
and math, we show that our algorithm can progressively invent agents with novel designs that greatly
outperform state-of-the-art hand-designed agents. Importantly, we consistently observe the surprising
result that agents invented by Meta Agent Search maintain superior performance even when transferred
across domains and models, demonstrating their robustness and generality. Provided we develop it
safely, our work illustrates the potential of an exciting new research direction toward automatically
designing ever-more powerful agentic systems to benefit humanity.
¬ß https://github.com/ShengranHu/ADAS
1. Introduction
Foundation Models (FMs) such as GPT (OpenAI, 2022, 2024) and Claude (Anthropic, 2024b) are
quickly being adopted as powerful general-purpose agents for agentic tasks that need flexible reasoning
and planning (Wang et al., 2024). Despite recent advancements in FMs, solving problems reliably
often requires an agent to be a compound agentic system with multiple components instead of a
monolithic model query (Rockt√§schel, 2024; Zaharia et al., 2024). Additionally, to enable agents to
solve complex real-world tasks, they often need access to external tools such as search engines, code
execution, and database queries. As a result, many effective building blocks of agentic systems have
been proposed, such as chain-of-thought planning and reasoning (Hu & Clune, 2024; Wei et al., 2022;
Yao et al., 2023), memory structures (Lewis et al., 2020; Zhang et al., 2024c), tool use (Qu et al.,
2024; Schick et al., 2023), and self-reflection (Madaan et al., 2024; Shinn et al., 2023). Although
these agents have already seen significant success across various applications (Wang et al., 2024),
developing these building blocks and combining them into complex agentic systems often requires
domain-specific manual tuning and substantial effort from both researchers and engineers.
However, the history of machine learning reveals a recurring theme: manually created artifacts become replaced by learned, more efficient solutions over time as we get more compute and
data (Clune, 2019). An early example is from computer vision, where hand-designed features like
HOG (Dalal & Triggs, 2005) were eventually replaced by learned features from Convolutional Neural
Corresponding author(s): Shengran Hu (srhu@cs.ubc.ca)
arXiv:2408.08435v1 [cs.AI] 15 Aug 2024
Automated Design of Agentic Systems
Summary and motivation: ‚ÄúBased on
the insights from previous agents ‚Ä¶‚Äù,
Name: ‚ÄúDivide and Conquer Agent‚Äù,
Code: ‚Äúdef forward(Task): ‚Ä¶‚Ä¶
return Answer‚Äù
Meta Agent
Next interesting agent
Agent Archive
Input Test performance on tasks
Refine until novel
and error-free
Examples of Discovered Agents
Multi-step Peer Review Agent
Experts
Answers
Reviewers
Task
Verified Multimodal Agent
Task
Visual
Paradigm
Verifier
Verified
Paradigm
Visual
Analyzer
COT
Answer
Task Sub-problem
Division
sub
sub
sub
sub
sub
Experts
Answers
Ensemble
Answer
Divide and Conquer Agent
Reviews
and add to archive
New Agent
‚Ä¶
Figure 1 | Overview of the proposed algorithm Meta Agent Search and examples of discovered
agents. In our algorithm, we instruct the ‚Äúmeta‚Äù agent to iteratively program new agents, test their
performance on tasks, add them to an archive of discovered agents, and use this archive to inform the
meta agent in subsequent iterations. We show three example agents across our runs, with all names
generated by the meta agent. The detailed code of example agents can be found in Appendix F.
Networks (CNNs, Krizhevsky et al. (2012)). More recently, AutoML methods (Hutter et al., 2019)
and AI-Generating Algorithms (AI-GAs, Clune (2019)) have also demonstrated the superiority of
learned AI systems compared to hand-designed AI systems. For example, the current best-performing
CNN models come from Neural Architecture Search (Elsken et al., 2019; Shen et al., 2023) instead
of manual design; in LLM alignment, learned loss functions (Lu et al., 2024a) outperform most
hand-designed ones such as DPO (Rafailov et al., 2024); The AI Scientist (Lu et al., 2024b) demonstrates an automated research pipeline, including the development of novel ML algorithms; and
an endless number of robotics learning environments can be automatically generated in works like
OMNI-EPIC (Faldor et al., 2024), which demonstrate surprising creativity in generated environments
and allow more efficient environment creation than the manual approach (see more examples in
Section 5). Therefore, in this paper, we propose a new research question: Can we automate the design
of agentic systems rather than relying on manual efforts?
To explore the above research question, we formulate a new research area we call Automated
Design of Agentic Systems (ADAS), which aims to automatically invent novel building blocks and
design powerful agentic systems (Section 2). We argue that ADAS may prove to be the fastest path to
developing powerful agents, and show initial evidence that learned agents can greatly outperform
hand-designed agents. Considering the tremendous number of building blocks yet to be discovered in
agentic systems (Section 5), it would take a long time for our research community to discover them
all. Even if we successfully discover most of the useful building blocks, combining them into effective
agentic systems for massive real-world applications would still be challenging and time-consuming,
given the many different ways the building blocks can combine and interact with each other. In
contrast, with ADAS, the building blocks and agents can be learned in an automated fashion. ADAS
2
Automated Design of Agentic Systems
may not only potentially save human effort in developing powerful agents but also could be a faster
path to more effective solutions than manual design.
Although a few existing works can be considered as ADAS methods, most of them focus only on
designing prompts (Fernando et al., 2024; Yang et al., 2024), greatly limiting their ability to invent
flexible design patterns in agents (Section 5). In this paper, we show that there is an unexplored
yet promising approach to ADAS where we can define the entire agentic system in code and new
agents can be automatically discovered by a ‚Äúmeta‚Äù agent programming even better ones in code.
Given that most programming languages, such as Python, which we use in this paper, are Turing
Complete (Boyer & Moore, 1983; Ladha, 2024), searching within a code space theoretically enables a
ADAS algorithm to discover any possible agentic systems, including all components such as prompts,
tool use, control flows, and more. Furthermore, with recent FMs being increasingly proficient in
coding, we can use FMs as a meta agent to create new agents in code for ADAS, enabling novel agents
to be programmed in an automated manner.
Following the aforementioned ideas, we present Meta Agent Search in this paper as one of the first
algorithms in ADAS that enables complete design in code space (Figure 1). The core concept of Meta
Agent Search is to instruct a meta agent to iteratively create interestingly new agents, evaluate them,
add them to an archive that stores discovered agents, and use this archive to help the meta agent in
subsequent iterations create yet more interestingly new agents. Similar to existing open-endedness
algorithms that leverage human notions of interestingness (Lu et al., 2024c; Zhang et al., 2024a),
we encourage the meta agent to explore interesting (e.g., novel or worthwhile) agents. To validate
the proposed approach, we evaluate the proposed Meta Agent Search on: (1) the challenging ARC
logic puzzle task (Chollet, 2019) that aims to test the general intelligence of an AI system, (2) four
popular benchmarks on reading comprehension, math, science questions, and multi-task problem
solving, and (3) the transferability of discovered agents to held-out domains and models (Section 4).
Our experiments show that the discovered agents substantially outperform state-of-the-art handdesigned baselines. For instance, our agents improve F1 scores on reading comprehension tasks in
DROP (Dua et al., 2019) by 13.6/100 and accuracy rates on math tasks in MGSM (Shi et al., 2023) by
14.4%. Additionally, they improve accuracy over baselines by 25.9% and 13.2% on GSM8K (Cobbe
et al., 2021) and GSM-Hard (Gao et al., 2023) math tasks, respectively, after transferring across
domains. The promising performance of our algorithm over hand-designed solutions illustrates
the potential of ADAS in automating the design of agentic systems. Furthermore, the experiments
demonstrate that the discovered agents not only perform well when transferring across similar
domains but also exhibit strong performance when transferring across dissimilar domains, such as
from mathematics to reading comprehension. This highlights the robustness and transferability of the
agentic systems discovered by Meta Agent Search. In conclusion, our work opens up many exciting
research directions and encourages further studies (Section 6).
2. New Research Area: Automated Design of Agentic Systems (ADAS)
At the time of writing, the community has not reached a consensus on the definitions or terminologies
of agents. Here, by agents we refer to agentic systems that involve Foundation Models (FMs) as
modules in the control flow to solve tasks by planning, using tools, and carrying out multiple, iterative
steps of processing (Chase, 2024; Ng, 2024).
In this paper, we propose a new research area Automated Design of Agentic Systems (ADAS).
Similar to research areas in AI-GAs (Clune, 2019) and AutoML (Hutter et al., 2019), such as Neural
Architecture Search (Elsken et al., 2019), we formulate ADAS as an optimization process and identify
three key components of ADAS algorithms (Figure 2).
3
Automated Design of Agentic Systems
Search Space
E.g. Agents defined by code
Search Algorithm
E.g. LLM defines agents using code
Evaluation Function
E.g. Accuracy on the task
Where is the
capital of Canada
Ottawa ‚úÖ
Sample
New Agent
Evaluate the
Objectives
Agent
‚Ä¶‚Ä¶
1 + 1 = ?
Figure 2 | The three key components of Automated Design of Agentic Systems (ADAS). The search
space determines which agentic systems can be represented in ADAS. The search algorithm specifies
how the ADAS method explores the search space. The evaluation function defines how to evaluate a
candidate agent on target objectives such as performance.
Formulation
Automated Design of Agentic Systems (ADAS) involves using a search algorithm to discover
agentic systems across a search space that optimize an evaluation function.
‚Ä¢ Search Space: The search space defines which agentic systems can be represented and thus
discovered in ADAS. For example, works like PromptBreeder (Fernando et al., 2024) mutate only
the text prompts of an agent, but their other components, such as control flow, remain the same.
Thus, in these search spaces, agents that have a different control flow than the predefined one can
not be represented. Existing works also explore search spaces such as graph structures (Zhuge
et al., 2024) and feed-forward networks (Liu et al., 2023).
‚Ä¢ Search Algorithm: The search algorithm defines how ADAS algorithms explore the search space.
Since the search space is often very large or even unbounded, the exploration-exploitation tradeoff (Sutton & Barto, 2018) should be considered. Ideally, the algorithm can both quickly discover
high-performance agentic systems and avoid remaining stuck in a local optimum. Existing approaches include using Reinforcement Learning (Zhuge et al., 2024) or an FM iteratively generating
new solutions (Fernando et al., 2024) as search algorithms.
‚Ä¢ Evaluation Function: Depending on the application of the ADAS algorithm, we may consider
different objectives to optimize, such as performance, cost, latency, or safety of agents. An evaluation
function defines how to evaluate a candidate agent on those objectives. For example, to assess
the agent‚Äôs performance on unseen future data, a simple method is to calculate the accuracy rate
on the validation data for a task, which is commonly adopted in existing works (Fernando et al.,
2024; Zhuge et al., 2024).
Although many search space designs are possible and some have already been explored (Section 5),
there is an unexplored yet promising approach where we can define the entire agentic system in
code and new agents can be automatically discovered by a meta agent programming even better
ones in code. Searching within a code space theoretically enables the ADAS algorithm to discover
any possible building blocks (e.g., prompts, tool use, control flow) and agentic systems that combine
any of these building blocks in any way. This approach also offers better interpretability for agent
design patterns since the program code is often readable, making debugging easier and enhancing AI
safety. Additionally, compared to search spaces using networks (Liu et al., 2023) or graphs (Zhuge
et al., 2024), searching in a code space allows us to more easily build on existing human efforts. For
example, it is possible to search within open-source agent frameworks like LangChain (LangChainAI,
2022) and build upon all existing building blocks (e.g., RAG, search engine tools). Finally, since FMs
4
Automated Design of Agentic Systems
are proficient in coding, utilizing a code search space allows us to leverage existing expertise from
FMs during the search process. In contrast, search algorithms in custom search spaces, such as graphs,
may be much less efficient due to the absence of these priors. Therefore, we argue that the approach
of using programming languages as the search space should be studied more in ADAS.
3. Our Algorithm: Meta Agent Search
In this section, we present Meta Agent Search, a simple yet effective algorithm to demonstrate the
approach of defining and searching for agents in code. The core idea of Meta Agent Search is to adopt
FMs as meta agents to iteratively program interestingly new agents based on an ever-growing archive
of previous discoveries. Although any possible building blocks and agentic systems can theoretically
be programmed by the meta agent from scratch, it is inefficient in practice to avoid providing the
meta agent any basic functions such as FM query APIs or existing tools. Therefore, in this paper, we
define a simple framework (within 100 lines of code) for the meta agent, providing it with a basic
set of essential functions like querying FMs or formatting prompts. As a result, the meta agent only
needs to program a ‚Äúforward‚Äù function to define a new agentic system, similar to the practice in
FunSearch (Romera-Paredes et al., 2024). This function takes in the information of the task and
outputs the agent‚Äôs response to the task. Details of the framework codes and examples of the agents
defined with this framework can be found in Appendix B.
As shown in Figure 1, the core idea of Meta Agent Search is to have a meta agent iteratively
program new agents in code. We show the main prompt for the meta agent to program new agents
below, where variables in the prompts are highlighted. Similar to existing open-endedness algorithms
that leverage human notions of interestingness (Lu et al., 2024c; Zhang et al., 2024a), we encourage
the meta agent to explore interestingly new (e.g., novel or worthwhile) agents based on an evergrowing archive of previous discoveries. We also adopt self-reflection (Madaan et al., 2024; Shinn
et al., 2023) iterations in our meta agent, where it performs two iterations of refinement on the
novelty and correctness of the proposal and performs up to three refinements when errors occur
while running the code. Full details of the prompt are presented in Appendix A.
After a new agent is generated, we evaluate it using the validation data from the target domain.
Here, we calculate the performance (e.g., success rate or F1 score) and 95% bootstrap confidence
interval as the metrics for the meta agent to maximize. The generated agent is then added to the
archive with the evaluation metrics, and the iteration continues with the updated archive until the
maximum number of iterations is reached.
Main prompt for the meta agent.
You are an expert machine learning researcher testing different agentic systems.
[Brief Description of the Domain]
[Framework Code]
[Output Instructions and Examples]
[Discovered Agent Archive] (initialized with baselines, updated at every iteration)
# Your task
You are deeply familiar with prompting techniques and the agent works from the literature. Your goal is
to maximize the performance by proposing interestingly new agents ......
Use the knowledge from the archive and inspiration from academic literature to propose the next
interesting agentic system design.
5
Automated Design of Agentic Systems
4. Experiments
We conduct extensive experiments on: (1) the challenging ARC logic puzzle task (Chollet, 2019)
(Section 4.1), (2) four popular benchmarks assessing the agent‚Äôs abilities on reading comprehension,
math, science questions, and multi-task problem solving (Section 4.2), (3) the transferability of
the discovered agents on ARC to three held-out models, and (4) the transferability of discovered
agents on Math to four held-out math tasks and three tasks that are beyond math (Section 4.3).
Across all experiments, we find that the discovered agents substantially outperform baseline stateof-the-art hand-designed agents. Notably, our discovered agents improve over baselines on reading
comprehension tasks in DROP (Dua et al., 2019) by 13.6/100 (F1 score) and on math tasks in
MGSM (Shi et al., 2023) by 14.4% (accuracy rate). Additionally, our discovered agents improve over
the baseline on ARC tasks by 14% (accuracy rate) after transferring from GPT-3.5 to GPT-4, and by
25.9% and 13.2% (accuracy rate) after transferring from MGSM math tasks to held-out math tasks in
GSM8K (Cobbe et al., 2021) and GSM-Hard (Gao et al., 2023) respectively. All code, prompts, and
experiment results are available at https://github.com/ShengranHu/ADAS.
0 5 10 15 20 25
Iteration
4
6
8
10
12
14
Held-out Test Accuracy (%)
Initially tested generating high-level strategies
before implementing low-level details.
An important strategy emerged: using multiple COTs
to generate possible answers, refining them, and
finally ensembling the best answers.
Introduced dynamic memory for doing more refinements.
Scaled up the previous idea.
Best agent: introduced multiple
critics for enhanced refinement.
Meta-Agent Search on ARC
Chain-of-Thought
Self-Refine
LLM Debate
COT-SC
Quality-Diversity
Meta-Agent Search
(a)
Task
5 COTs
5 Answers
Human-like
Critic
Feedback
Efficiency Expert
Readability Expert
Simplicity Expert
Experts
Feedback
Refinement
3 times
All
Answers
Evaluate Top-3
Answers
Ensemble
Final
Answer
Structured Feedback and Ensemble Agent
The Best Discovered Agent on ARC
(b)
Figure 3 | The results of Meta Agent Search on the ARC challenge. (a) Meta Agent Search progressively discovers high-performance agents based on an ever-growing archive of previous discoveries.
We report the median accuracy and the 95% bootstrap confidence interval on a held-out test set by
evaluating agents five times. (b) The visualization of the best agent discovered by Meta Agent Search
on the ARC challenge. Detailed implementation of this agent is available in Appendix C.
4.1. Case Study: ARC Challenge
We first demonstrate how Meta Agent Search discovers novel agentic systems and outperforms existing
state-of-the-art hand-designed agents in the Abstraction and Reasoning Corpus (ARC) challenge (Chollet, 2019). This challenge aims to evaluate the general intelligence of AI systems through their ability
to efficiently acquire new skills. Questions in ARC include (1) showing multiple examples of visual
input-output grid patterns, (2) the AI system learning the transformation rule of grid patterns from
examples, and (3) predicting the output grid pattern given a test input grid pattern. Since each
question in ARC has a unique transformation rule, it requires the AI system to learn efficiently with
6
Automated Design of Agentic Systems
few-shot examples, leveraging capabilities in number counting, geometry, and topology.
Setup. Following common practice (Greenblatt, 2024), we require the agent to write code for the
transformation rule instead of answering directly. We provide tool functions in the framework that
evaluate the generated transformation code. Given the significant challenge that ARC poses to current
AI systems, we sample our data from questions with grid dimensions ‚â§ 5 √ó 5 in the ‚ÄúPublic Training
Set (Easy)‚Äù. We sample a validation set and a test set with 20 and 60 questions, respectively, for
searching and testing. We calculate the validation and test accuracy of an agent by assessing it over
the validation and test sets five times to reduce the variance from the stochastic sampling of FMs. We
evaluate all discovered agents on the held-out test set and report the test accuracy in Figure 3. Meta
Agent Search runs for 25 iterations and the meta agent uses GPT-4 (OpenAI, 2024), while discovered
agents and baselines are evaluated using GPT-3.5 (OpenAI, 2022) to reduce compute cost. More
algorithmic details and examples of ARC questions can be found in Appendix C.
Baselines. We compared against five state-of-the-art hand-designed agents: (1) Chain-of-Thought
(COT) (Wei et al., 2022), which instructs the agent to output the reasoning before answering to
improve complex problem-solving through intermediate steps; (2) Self-Consistency with Chain-ofThought (COT-SC) (Wang et al., 2023b), which ensembles multiple parallel answers from COT to
produce a more accurate answer; (3) Self-Refine (Madaan et al., 2024; Shinn et al., 2023), which
allows iterative self-reflection to correct mistakes made in previous attempts; (4) LLM-Debate (Du
et al., 2023), which enables different LLMs to debate with each other, leveraging diverse perspectives
to find better answers; (5) Quality-Diversity, a simplified version of Intelligent Go-Explore (Lu et al.,
2024c), which produces and ensembles diverse answers to better explore potential solutions. We also
use all baselines as initial seeds in the archive for Meta Agent Search. More details about baselines
can be found in Appendix E.
Results and Analysis. As shown in Figure 3a, Meta Agent Search effectively and progressively
discovers agents that perform better than state-of-the-art hand-designed baselines. Important breakthroughs are highlighted in the text boxes. As is critical in prior works on open-endedness and AI-GAs
(Faldor et al., 2024; Lehman & Stanley, 2011; Wang et al., 2019, 2020; Zhang et al., 2024a), Meta
Agent Search innovates based on a growing archive of previous stepping stones. For example, an
important design pattern emerged in iteration 3 where it uses multiple COTs to generate possible
answers, refines them, and finally ensembles the best answers. This became a crucial stepping
stone that subsequent designs tended to utilize. Additionally, the best-discovered agent is shown
in Figure 3b, where a complex feedback mechanism is adopted to refine answers more effectively.
Careful observation of the search progress reveals that this sophisticated feedback mechanism did
not appear suddenly. Instead, the ideas of incorporating diverse feedback, evaluating for various
specific traits (via experts) such as efficiency and simplicity, and simulating human-like feedback
emerged in iterations 5, 11, and 12, respectively. The final mechanism is an innovation based on
these three stepping stones. This illustrates that even though these stepping stones did not achieve
high performance immediately upon emergence, later discoveries benefited from these innovations
by combining different stepping stones, resembling crossover in evolution via LLMs (Meyerson et al.,
2023). Overall, the results showcase the potential of ADAS and the effectiveness of Meta Agent Search
to progressively discover agents that outperform state-of-the-art hand-designed baselines and invent
novel design patterns through the innovation and combination of various stepping stones.
4.2. Reasoning and Problem-Solving Domains
Setup. Next, we investigate the potential of our algorithm to improve the capabilities of agents across
math, reading, and reasoning domains. We test Meta Agent Search on four popular benchmarks: (1)
DROP (Dua et al., 2019) for evaluating Reading Comprehension; (2) MGSM (Shi et al., 2023) for
7
Automated Design of Agentic Systems
Agent Name F1 Score Accuracy (%)
Reading Comprehension Math Multi-task Science
State-of-the-art Hand-designed Agents
Chain-of-Thought (Wei et al., 2022) 64.2 ¬± 0.9 28.0 ¬± 3.1 65.4 ¬± 3.3 29.2 ¬± 3.1
COT-SC (Wang et al., 2023b) 64.4 ¬± 0.8 28.2 ¬± 3.1 65.9 ¬± 3.2 30.5 ¬± 3.2
Self-Refine (Madaan et al., 2024) 59.2 ¬± 0.9 27.5 ¬± 3.1 63.5 ¬± 3.4 31.6 ¬± 3.2
LLM Debate (Du et al., 2023) 60.6 ¬± 0.9 39.0 ¬± 3.4 65.6 ¬± 3.3 31.4 ¬± 3.2
Step-back Abstraction (Zheng et al., 2023) 60.4 ¬± 1.0 31.1 ¬± 3.2 65.1 ¬± 3.3 26.9 ¬± 3.0
Quality-Diversity (Lu et al., 2024c) 61.8 ¬± 0.9 23.8 ¬± 3.0 65.1 ¬± 3.3 30.2 ¬± 3.1
Role Assignment (Xu et al., 2023) 65.8 ¬± 0.9 30.1 ¬± 3.2 64.5 ¬± 3.3 31.1 ¬± 3.1
Automated Design of Agentic Systems on Different Domains
Best Agents from Meta Agent Search 79.4 ¬± 0.8 53.4 ¬± 3.5 69.6 ¬± 3.2 34.6 ¬± 3.2
Table 1 | Performance comparison between Meta Agent Search and state-of-the-art handdesigned agents across multiple domains. Meta Agent Search discovers superior agents compared
to the baselines in every domain. We report the test accuracy and the 95% bootstrap confidence
interval on held-out test sets. The search is conducted independently for each domain.
evaluating Math capability under a multi-lingual setting; (3) MMLU (Hendrycks et al., 2021) for
evaluating Multi-task Problem Solving; and (4) GPQA (Rein et al., 2023) for evaluating the capability
of solving hard (graduate-level) questions in Science. The search is conducted independently within
each domain. Meta Agent Search runs for 30 iterations. The meta agent uses GPT-4 (OpenAI, 2024),
while the discovered agents and baselines are evaluated using GPT-3.5 (OpenAI, 2022). More details
about datasets and experiment settings can be found in Appendix D.
Baselines. We adopt all baselines introduced in Section 4.1. Additionally, since the above domains
require strong reasoning skills, we include two additional baselines that specifically focus on enhancing
the reasoning capabilities of agents for a more thorough comparison: (1) Step-back Abstraction (Zheng
et al., 2023), which instructs agents to first consider the principles involved in solving the task for
better reasoning; (2) Role Assignment, which assigns different roles to FMs similar to Xu et al. (2023)
to obtain better answers. More details about the baselines can be found in Appendix E.
Results and Analysis. The results across multiple domains demonstrate that Meta Agent Search
can discover agents that outperform state-of-the-art hand-designed agents (Table 1). We want to
highlight the substantial gap between the learned agents and hand-designed agents in the Reading
Comprehension and Math domains, with improvements in F1 scores by 13.6/100 and accuracy rates
by 14.4%, respectively. While Meta Agent Search also outperforms baselines in the Multi-task and
Science domains, the gap is smaller. We hypothesize that for challenging questions in the Science
and Multi-task domains, the knowledge in FMs is not sufficient to solve the questions, limiting the
improvement through optimizing agentic systems, which is a problem that will diminish as FMs
improve. In contrast, in the Reading Comprehension and Math domains, FMs possess adequate
knowledge to solve the questions, and errors could mainly be hallucinations or calculation mistakes,
which can be mitigated through well-designed agentic systems, like the ones discovered by Meta
Agent Search. Overall, the results across various domains showcase the effectiveness of Meta Agent
Search in searching for agents tailored to specific domains. This could be increasingly useful for
saving human efforts and developing better task-specific agents as we continue to create agents for a
diverse set of applications (Wang et al., 2024).
8
Automated Design of Agentic Systems
4.3. Generalization and transferability
Agent Name Accuracy on ARC (%)
GPT-3.5 Claude-Haiku GPT-4 Claude-Sonnet
Manually Designed Agents
Chain-of-Thought (Wei et al., 2022) 6.0 ¬± 2.7 4.3 ¬± 2.2 17.7 ¬± 4.4 25.3 ¬± 5.0
COT-SC (Wang et al., 2023b) 8.0 ¬± 3.2 5.3 ¬± 2.5 19.7 ¬± 4.5 26.3 ¬± 4.9
LLM Debate (Du et al., 2023) 4.0 ¬± 2.2 1.7 ¬± 1.5 19.0 ¬± 4.5 24.7 ¬± 4.8
Self-Refine (Madaan et al., 2024) 6.7 ¬± 2.7 6.3 ¬± 2.8 23.0 ¬± 5.2 39.3 ¬± 5.5
Quality-Diversity (Lu et al., 2024c) 7.0 ¬± 2.9 3.3 ¬± 2.2 23.0 ¬± 4.7 31.7 ¬± 5.3
Top Agents Searched with GPT-3.5 Transferred to Other FMs
Structured Feedback and Ensemble Agent 13.7 ¬± 3.9 5.0 ¬± 2.5 30.0 ¬± 5.2 38.7 ¬± 5.5
Hierarchical Committee Reinforcement Agent 13.3 ¬± 3.8 8.3 ¬± 3.2 32.3 ¬± 8.9 39.7 ¬± 5.5
Dynamic Memory and Refinement Agent‚Ä† 12.7 ¬± 3.9 9.7 ¬± 3.3 37.0 ¬± 5.3 48.3 ¬± 5.7
Table 2 | Performance on ARC when transferring top agents from GPT-3.5 to other FMs. Agents
discovered by Meta Agent Search consistently outperform the baselines across different models. We
report the test accuracy and the 95% bootstrap confidence interval. The names of top agents are
generated by Meta Agent Search. ‚Ä†We manually changed this name because the original generated
name was confusing.
In the previous sections, we illustrated that Meta Agent Search can find effective agents for
individual tasks. In this section, we further demonstrate the transferability and generalizability of the
discovered agents. To show that the invented building blocks and design patterns are generalizable,
we conduct experiments on the transferability of the discovered agents.
Transferability Across Foundation Models. We first transfer discovered agents from GPT-3.5 (OpenAI, 2022) to other FMs on ARC to test whether agents found when performing Meta Agent Search
with one FM generalize to others. We test the top 3 agents with the best test accuracy evaluated with
GPT-3.5 on ARC and then transfer them to three popular models: Claude-Haiku (Anthropic, 2024a),
GPT-4 (OpenAI, 2024), and Claude-Sonnet (Anthropic, 2024b). We adopt the same baselines as
those used in ARC (Section 4.1) and MGSM (Section 4.2). As shown in Table 2, we observe that the
searched agents consistently outperform the hand-designed agents with a substantial gap. Notably,
we found that Claude-Sonnet, the most powerful model from Anthropic, performs the best among all
tested models, enabling our best agent to achieve nearly 50% accuracy on ARC.
Transferability Across Domains. Next, we transfer the discovered agent from the MGSM (Math)
domain to other math domains to test whether the invented agents can generalize across different
domains. Similarly, we test the top 3 agents from MGSM and transfer them to (1) four popular math
domains: GSM8K (Cobbe et al., 2021), GSM-Hard (Gao et al., 2023), SVAMP (Patel et al., 2021),
and ASDiv (Miao et al., 2020) and (2) three domains beyond math adopted in Section 4.2. As shown
in Table 3, we observe a similar superiority in the performance of Meta Agent Search compared to
baselines. Notably, our agents improve accuracy by 25.9% and 13.2% on GSM8K (Cobbe et al., 2021)
and GSM-Hard (Gao et al., 2023), respectively, compared to the baselines. More surprisingly, we
observe that agents discovered in the math domain can be transferred to non-math domains (Table 4).
While the performance of agents originally searched in the math domain does not fully match that of
agents specifically designed for the target domains, they still outperform (in Reading Comprehension
and Multi-task) or match (in Science) the state-of-the-art hand-designed agent baselines. These
results illustrate that Meta Agent Search can discover generalizable design patterns and agentic
systems.
9
Automated Design of Agentic Systems
Agent Name Accuracy (%)
MGSM GSM8K GSM-Hard SVAMP ASDiv
Manually Designed Agents
Chain-of-Thought (Wei et al., 2022) 28.0 ¬± 3.1 34.9 ¬± 3.2 15.0 ¬± 2.5 77.8 ¬± 2.8 88.9 ¬± 2.2
COT-SC (Wang et al., 2023b) 28.2 ¬± 3.1 37.8 ¬± 3.4 15.5 ¬± 2.5 78.2 ¬± 2.8 89.0 ¬± 2.1
Self-Refine (Madaan et al., 2024) 27.5 ¬± 3.1 38.9 ¬± 3.4 15.1 ¬± 2.4 78.5 ¬± 2.8 89.2 ¬± 2.2
LLM Debate (Du et al., 2023) 39.0 ¬± 3.4 43.6 ¬± 3.4 17.4 ¬± 2.6 76.0 ¬± 3.0 88.9 ¬± 2.2
Step-back Abstraction (Zheng et al., 2023) 31.1 ¬± 3.2 31.5 ¬± 3.3 12.2 ¬± 2.3 76.1 ¬± 3.0 87.8 ¬± 2.3
Quality-Diversity (Lu et al., 2024c) 23.8 ¬± 3.0 28.0 ¬± 3.1 14.1 ¬± 2.4 69.8 ¬± 3.2 80.1 ¬± 2.8
Role Assignment (Xu et al., 2023) 30.1 ¬± 3.2 37.0 ¬± 3.4 18.0 ¬± 2.7 73.0 ¬± 3.0 83.1 ¬± 2.6
Top Agents Searched on MGSM (Math) Transferred to Other Math Domains
Dynamic Role-Playing Architecture 53.4 ¬± 3.5 69.5 ¬± 3.2 31.2 ¬± 3.2 81.5 ¬± 2.6 91.8 ¬± 1.8
Structured Multimodal Feedback Loop 50.2 ¬± 3.5 64.5 ¬± 3.4 30.1 ¬± 3.2 82.6 ¬± 2.6 89.9 ¬± 2.1
Interactive Multimodal Feedback Loop 47.4 ¬± 3.5 64.9 ¬± 3.3 27.6 ¬± 3.2 80.6 ¬± 2.8 89.8 ¬± 2.1
Table 3 | Performance on different math domains when transferring top agents from MGSM to
other math domains. Agents discovered by Meta Agent Search consistently outperform the baselines
across different math domains. We report the test accuracy and the 95% bootstrap confidence interval.
The names of top agents are generated by Meta Agent Search.
5. Related Work
Agentic Systems. Researchers develop various building blocks and design patterns for different
applications. Important building blocks for agentic systems includes: prompting techniques (Chen
et al., 2023a; Schulhoff et al., 2024), chain-of-thought-based planning and reasoning methods (Hu
& Clune, 2024; Wei et al., 2022; Yao et al., 2023), reflection (Madaan et al., 2024; Shinn et al.,
2023), developing new skills for embodied agents in code (Vemprala et al., 2023; Wang et al., 2023a),
external memory and RAG (Lewis et al., 2020; Zhang et al., 2024c), tool use (Nakano et al., 2021;
Qu et al., 2024; Schick et al., 2023), assigning FM modules in the agentic system with different
roles and enabling them to collaborate (Hong et al., 2023; Qian et al., 2023, 2024; Wu et al., 2023;
Xu et al., 2023), and enabling the agent to instruct itself for the next action (Richards, 2023), etc.
While the community has invested substantial effort in developing all the above important techniques,
this is only a partial list of the discovered building blocks, and many more remain to be uncovered.
Therefore, in this paper, we propose a new research area, ADAS, which aims to invent novel building
blocks and design powerful agentic systems in an automated manner.
AI-Generating Algorithms and AutoML. Following the lessons learned from the history of machine
learning, research in AI-Generating Algorithms (AI-GAs) (Clune, 2019) and AutoML (Hutter et al.,
2019) continually strives to learn more components in AI systems to replace handcrafted ones. There
are mainly three pillars in this field: (1) meta-learning architectures, (2) meta-learning the learning
algorithms, and (3) generating effective learning environments and training data (Clune, 2019). For
example, Neural Architecture Search (Elsken et al., 2019; Hu et al., 2021; Lu et al., 2019) aims to
automate the design of neural network architectures like convolution, which falls under the first pillar.
The second pillar includes works like MAML (Finn et al., 2017) and Meta-RL (Duan et al., 2017;
Norman & Clune, 2023; Wang et al., 2016; Zintgraf et al., 2021a,b), which allow ‚Äúlearning to learn‚Äù
for better sample efficiency, generalizability, and continuous learning of multiple tasks. Additionally,
works like POET (Dharna et al., 2020; Wang et al., 2019, 2020) and OMNI-EPIC (Faldor et al., 2024)
under the third pillar aim to generate learning environments in an open-ended manner. We believe
10
Automated Design of Agentic Systems
Agent Name Accuracy (%) F1 Score Accuracy (%)
Math Reading Comprehension Multi-task Science
Manually Designed Agents
Chain-of-Thought (Wei et al., 2022) 28.0 ¬± 3.1 64.2 ¬± 0.9 65.4 ¬± 3.3 29.2 ¬± 3.1
COT-SC (Wang et al., 2023b) 28.2 ¬± 3.1 64.4 ¬± 0.8 65.9 ¬± 3.2 30.5 ¬± 3.2
Self-Refine (Madaan et al., 2024) 27.5 ¬± 3.1 59.2 ¬± 0.9 63.5 ¬± 3.4 31.6 ¬± 3.2
LLM Debate (Du et al., 2023) 39.0 ¬± 3.4 60.6 ¬± 0.9 65.6 ¬± 3.3 31.4 ¬± 3.2
Step-back Abstraction (Zheng et al., 2023) 31.1 ¬± 3.2 60.4 ¬± 1.0 65.1 ¬± 3.3 26.9 ¬± 3.0
Quality-Diversity (Lu et al., 2024c) 23.8 ¬± 3.0 61.8 ¬± 0.9 65.1 ¬± 3.1 30.2 ¬± 3.1
Role Assignment (Xu et al., 2023) 30.1 ¬± 3.2 65.8 ¬± 0.9 64.5 ¬± 3.3 31.1 ¬± 3.1
Top Agents Searched on Math (MGSM) Transferred beyond Math Domains
Dynamic Role-Playing Architecture 53.4 ¬± 3.5 70.4 ¬± 0.9 62.4 ¬± 3.4 28.6 ¬± 3.1
Structured Multimodal Feedback Loop 50.2 ¬± 3.5 70.4 ¬± 0.9 67.0 ¬± 3.2 28.7 ¬± 3.1
Interactive Multimodal Feedback Loop 47.4 ¬± 3.5 71.9 ¬± 0.8 64.8 ¬± 3.3 29.9 ¬± 3.2
Table 4 | Performance across multiple domains when transferring top agents from the Math
(MGSM) domain to non-math domains. Agents discovered by Meta Agent Search in the math
domain can outperform or match the performance of baselines after being transferred to domains
beyond math. We report the test accuracy and the 95% bootstrap confidence interval.
that the proposed Automated Design of Agentic Systems belongs to both the first and second pillars:
Pillar one because ADAS meta-learns the architecture of agentic systems, but also Pillar two because
agents are proficient in in-context learning, thus ADAS can also be considered as learning to learn, as
demonstrated in the ARC challenge (Section 4.1).
Additionally, recent AI-GA and AutoML works have incorporated Foundation Models (FMs) to
write code. For example, in FunSearch (Romera-Paredes et al., 2024) and EoH (Liu et al., 2024),
FMs write code to discover better optimization algorithms. In DiscoPOP (Lu et al., 2024a), FMs
program the loss function for preference learning in FM alignment training (Rafailov et al., 2024).
Additionally, Eureka (Ma et al., 2023) and language-to-reward (Yu et al., 2023) enable FMs to write
reward functions for reinforcement learning in robotics. Finally, OMNI-EPIC (Faldor et al., 2024)
enables FMs to create robotics learning environments by programming in code. Here, we adopt a
similar idea that enables FMs to program new agents in code.
Existing Attempts to ADAS. There are two categories of works that can be considered attempts at
ADAS in the literature: those that learn better prompts only, and those that learn more components
in agents than just prompts. Most works fall into the first category: learning prompts only. Works like
OPRO (Yang et al., 2024), PromptBreeder (Fernando et al., 2024), and Self-Discover (Zhou et al.,
2024a) adopt FMs to automate prompt engineering for agents, primarily focusing on the phrasing of
instructions in the prompt to enhance the reasoning capability of agents. Thus, the learned prompts
are domain-specific and difficult to generalize. Beyond instructions, works like EvoAgent (Yuan
et al., 2024) and AgentVerse (Chen et al., 2023b) optimize role definition in the prompt, as assigning
personas or roles to agents has been shown to be beneficial (Xu et al., 2023). Although tuning prompts
effectively improves performance, other important components in agentic systems remain fixed and
hand-designed, vastly limiting the space of agents that can be discovered.
There are far fewer attempts in the second category, which involves learning more components
than just prompts in agentic systems. Most represent agents as networks or graphs in the search
space. In these formulations, the FM with a certain prompt is considered a transformation function
for text on nodes, and the information flow of the text is considered as edges. DyLAN (Liu et al.,
11
Automated Design of Agentic Systems
2023) starts with a fully connected feed-forward network and uses FMs to score the response quality
of nodes in each layer to prune the connections. DSPy (Khattab et al., 2024) first generates a set
of possible nodes and then optimizes across the Cartesian product of these nodes while optimizing
the few-shot examples for nodes. GPT-Swarm (Zhuge et al., 2024) represents an agentic system in
a graph with a predefined set of nodes and uses a Reinforcement Learning algorithm to optimize
the possible connections between nodes while optimizing the prompt for each node in a separate
stage. Although these works allow the learning of control flow (optimizing edges in networks or
graphs), many other components, such as whether and which tools to learn or even how many nodes
to have, are still not learned, greatly limiting the space of agents that can be discovered. Besides
learning prompts and control flow, AgentOptimizer (Zhang et al., 2024b) learns the tools used in
agents, and Agent Symbolic Learning (Zhou et al., 2024b) learns prompts, tools, and control flow
together. While Agent Symbolic Learning shares similar motivations to learn more components in
agents, it manually designs the search space for each component separately, which may make it a
harder search space for search algorithms. In addition, it mainly improves agents based on an existing
complex agent, without showing the emergence of new design patterns or building blocks. In contrast,
our work represents all possible components in code, allowing the search to be easier by leveraging
human efforts in the existing codebase of agents and FMs‚Äô expertise in coding. We also demonstrate
how novel and diverse building blocks and design patterns emerge from a set of basic agent designs,
illustrating the potential creativity that can emerge from ADAS.
6. Discussion and Conclusion
Safety Considerations. We strongly advise researchers to be aware of the safety concerns
when executing untrusted model-generated code in Meta Agent Search and other research
involving code generation. While it is highly unlikely that model-generated code will perform overtly
malicious actions in our current settings and with the Foundation Models (FMs) we use, such code may
still act destructively due to limitations in model capability or alignment (Chen et al., 2021; Rokon
et al., 2020). Ideally, sandbox environments can be used to safely run untrusted model-generated
code (Chen et al., 2021; Yee et al., 2010).
More broadly, research on more powerful AI systems raises the question of whether we should
be conducting research to advance AI capabilities at all. That topic clearly includes the proposed
Automated Design of Agentic Systems (ADAS) as a new area in AI-GA research, which could potentially
contribute to an even faster way to create Artificial General Intelligence (AGI) than the current manual
approach (Clune, 2019). The question of whether and why we should pursue AGI and AI-GA has
been discussed in many papers (Bengio et al., 2024; Bostrom, 2002; Clune, 2019; Ecoffet et al., 2020;
Yudkowsky et al., 2008), and is beyond the scope of this paper. Specifically as regards ADAS, we
believe it is net beneficial to publish this work. First, this work demonstrates that with the available
API access to powerful FMs, it is easy to program powerful ADAS algorithms, and do so without any
expensive hardware like GPUs. We feel it is beneficial to let the community know such algorithms are
powerful and easy to create, so they can be informed and account for them. Moreover, by sharing this
information, we hope to motivate follow-up work into safe-ADAS, such as algorithms that conduct
ADAS safely during both search itself (e.g. not risking running any harmful code) and that refuse
to create dishonest, unhelpful, and/or harmful agents. Such an open-source research approach to
create safe-ADAS could be a better way to create safer AI systems (Caldwell, 2011; Meta, 2024). One
direction we find particularly promising is to simply ask the Meta Agent Search algorithm to be safe
during training and only create helpful, harmless, honest agents, potentially incorporating ideas such
as Constitutional AI (Bai et al., 2022).
12
Automated Design of Agentic Systems
Future Work. Our work also opens up many future research directions. For example:
‚Ä¢ Higher-order ADAS. Since the meta agent used in ADAS to program new agents in code is also
an agent, ADAS can become self-referential where the meta agent can be improved through ADAS
as well. It would be an exciting direction to have a higher order of meta-learning to allow the
learning of the meta agent and even the meta-meta agent, etc. (Lu et al., 2023)
‚Ä¢ Seeding ADAS with more existing building blocks. Although we can theoretically allow any
components in agentic systems to be programmed from scratch in the code space, it is not efficient
in practice. Therefore, it would be interesting to explore ADAS by standing on the shoulders of
existing human efforts, such as search engine tools, RAG (Lewis et al., 2020), or functions from
existing agent frameworks like LangChain (LangChainAI, 2022). Additionally, it is interesting
to support multi-modal capabilities (e.g. vision) in FMs or allow different FMs to be available in
agentic systems. This will enable the meta agent to choose from different FMs flexibly according to
the difficulty of the instruction and whether data privacy is a priority.
‚Ä¢ Multi-objective ADAS. We only consider one objective (i.e., performance) to optimize in this
paper, but in practice, multiple objectives are often considered, such as cost, latency, and robustness
of agentic systems (Hu et al., 2021; Huang et al., 2023). Thus, integrating multi-objective search
algorithms (Deb et al., 2002) in ADAS could be promising.
‚Ä¢ Novelty search algorithms. In Meta Agent Search, the design of the search algorithm is relatively simple, focusing solely on exploring interesting new designs. A more careful design of
the search algorithm can be a promising future direction. For example, one could incorporate
more sophisticated ideas from Quality-Diversity (Cully & Demiris, 2017; Mouret & Clune, 2015),
AI-generating (Clune, 2019), and Open-ended Algorithms (Faldor et al., 2024; Stanley & Lehman,
2015; Stanley et al., 2019; Zhang et al., 2024a). One could also include more classic approaches
to balance exploration and exploitation (Liu et al., 2024; Sutton & Barto, 2018).
‚Ä¢ More intelligent evaluation functions. In this work, we simply evaluate discovered agents on the
evaluation set and use the numerical performance results. However, this approach is both expensive
and misses a lot of information. A promising future direction is to enable the meta agent to analyze
detailed running logs during the evaluation, which contain rich information on the failure and
success modes for better debugging and improving agentic systems (Zhou et al., 2024b). Also,
many tasks involve subjective answer evaluations (Chiang et al., 2024; Lu et al., 2024b) that do
not have ground-truth answers. It is also important to design novel evaluation functions in ADAS
to address these tasks. Finally, in this work, we targeted only one domain during the search. It
would be interesting to explore whether ADAS algorithms can design even better generalist agents
when specifically searching for agents capable of performing well across multiple domains.
‚Ä¢ More complex domains. Additionally, we only evaluate Meta Agent Search on single-step QA
tasks in this paper. It would be interesting to extend the method to more complex domians, such
as real-world applications involving multi-step interaction with complex environments.
‚Ä¢ Understanding the emergence of complexity from human organizations. Beyond potentially
saving researchers‚Äô efforts and improving upon the manual design of agentic systems, the research
in ADAS is also scientifically intriguing as it sheds light on the origins of complexity emerging from
human organization and society. The agentic system is a machine learning system that operates
primarily over natural language‚Äîa representation that is interpretable to humans and used by
humans in constructing our organization and society. Thus, there is a close connection between
agentic systems and human organizations, as shown in works incorporating the organizational
structure for human companies in agents (Hong et al., 2023) or simulating a human town with
agents (Park et al., 2023). Therefore, the study in ADAS may enable us to observe how to create
a simple set of conditions and have an algorithm to bootstrap itself from simplicity to produce
complexity in a system akin to human society.
13
Automated Design of Agentic Systems
‚Ä¢ Towards a Better Understanding of FMs. Works from Neural Architecture Search (Huang et al.,
2023) show that by observing the emerged architecture, we could gain more insights into Neural
Networks. In this paper, we also gained insights about FMs from the results. For example, the
best agent with GPT-3.5 involves a complex feedback mechanism, but when we transfer to other
advanced models, the agent with a simpler feedback mechanism but more refinement becomes a
better agent (Section 4.3). This shows that GPT-3.5 may have a worse capability in evaluating and
refining the answers, so it needs a complex feedback mechanism for better refinement, while other
advanced models benefit more from a simpler feedback mechanism.
Conclusion. In this paper, we propose a new research problem, Automated Design of Agentic Systems
(ADAS), which aims to automatically invent novel building blocks and design powerful agentic systems.
We demonstrated that a promising approach to ADAS is to define agents in code, allowing new agents
to be automatically discovered by a ‚Äúmeta‚Äù agent programming them in code. Following this idea,
we propose Meta Agent Search, where the meta agent iteratively builds on previous discoveries
to program interesting new agents. The experiments show that Meta Agent Search consistently
outperforms state-of-the-art hand-designed agents across an extensive number of domains, and the
discovered agents transfer well across models and domains. Overall, our work illustrates the potential
of an exciting new research direction toward full automation in developing powerful agentic systems
from the bottom up.
Acknowledgments
This work was supported by the Vector Institute, the Canada CIFAR AI Chairs program, grants from
Schmidt Futures and Open Philanthropy, an NSERC Discovery Grant, and a generous donation from
Rafael Cosman. We thank Jenny Zhang, Rach Pradhan, Ruiyu Gou, Nicholas Ioannidis, and Eunjeong
Hwang for insightful discussions and feedback.
14
Automated Design of Agentic Systems
References
Anthropic. Introducing the next generation of claude. https://www.anthropic.com/news/
claude-3-family, March 2024a. Blog post.
Anthropic. Introducing claude 3.5 sonnet. https://www.anthropic.com/news/
claude-3-5-sonnet, June 2024b. Blog post.
Yuntao Bai, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson Kernion, Andy Jones, Anna
Chen, Anna Goldie, Azalia Mirhoseini, Cameron McKinnon, et al. Constitutional ai: Harmlessness
from ai feedback. arXiv preprint arXiv:2212.08073, 2022.
Yoshua Bengio, Geoffrey Hinton, Andrew Yao, Dawn Song, Pieter Abbeel, Trevor Darrell, Yuval Noah
Harari, Ya-Qin Zhang, Lan Xue, Shai Shalev-Shwartz, et al. Managing extreme ai risks amid rapid
progress. Science, 384(6698):842‚Äì845, 2024.
N Bostrom. Existential Risks: analyzing human extinction scenarios and related hazards. Journal of
Evolution and Technology, 9, 2002.
Robert S Boyer and J Strother Moore. A mechanical proof of the Turing completeness of pure LISP.
Citeseer, 1983.
Tracey Caldwell. Ethical hackers: putting on the white hat. Network Security, 2011(7):10‚Äì13, 2011.
Harrison Chase. What is an agent? https://blog.langchain.dev/what-is-an-agent/, June
2024. Blog post.
Banghao Chen, Zhaofeng Zhang, Nicolas Langren√©, and Shengxin Zhu. Unleashing the potential of prompt engineering in large language models: a comprehensive review. arXiv preprint
arXiv:2310.14735, 2023a.
Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde De Oliveira Pinto, Jared
Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. Evaluating large
language models trained on code. arXiv preprint arXiv:2107.03374, 2021.
Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chi-Min Chan, Heyang Yu, Yaxi Lu,
Yi-Hsin Hung, Chen Qian, et al. Agentverse: Facilitating multi-agent collaboration and exploring
emergent behaviors. In The Twelfth International Conference on Learning Representations, 2023b.
Wei-Lin Chiang, Lianmin Zheng, Ying Sheng, Anastasios Nikolas Angelopoulos, Tianle Li, Dacheng Li,
Hao Zhang, Banghua Zhu, Michael Jordan, Joseph E. Gonzalez, and Ion Stoica. Chatbot arena: An
open platform for evaluating llms by human preference, 2024.
Fran√ßois Chollet. On the measure of intelligence. arXiv preprint arXiv:1911.01547, 2019.
Jeff Clune. Ai-gas: Ai-generating algorithms, an alternate paradigm for producing general artificial
intelligence. arXiv preprint arXiv:1905.10985, 2019.
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias
Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. Training verifiers to solve math word
problems. arXiv preprint arXiv:2110.14168, 2021.
Antoine Cully and Yiannis Demiris. Quality and diversity optimization: A unifying modular framework.
IEEE Transactions on Evolutionary Computation, 22(2):245‚Äì259, 2017.
15
Automated Design of Agentic Systems
N. Dalal and B. Triggs. Histograms of oriented gradients for human detection. In 2005 IEEE Computer
Society Conference on Computer Vision and Pattern Recognition (CVPR‚Äô05), volume 1, pp. 886‚Äì893
vol. 1, 2005. doi: 10.1109/CVPR.2005.177.
Kalyanmoy Deb, Amrit Pratap, Sameer Agarwal, and TAMT Meyarivan. A fast and elitist multiobjective
genetic algorithm: Nsga-ii. IEEE transactions on evolutionary computation, 6(2):182‚Äì197, 2002.
Aaron Dharna, Julian Togelius, and Lisa B Soros. Co-generation of game levels and game-playing
agents. In Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment, volume 16, pp. 203‚Äì209, 2020.
Yilun Du, Shuang Li, Antonio Torralba, Joshua B Tenenbaum, and Igor Mordatch. Improving factuality
and reasoning in language models through multiagent debate. arXiv preprint arXiv:2305.14325,
2023.
Dheeru Dua, Yizhong Wang, Pradeep Dasigi, Gabriel Stanovsky, Sameer Singh, and Matt Gardner.
DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs. In Jill
Burstein, Christy Doran, and Thamar Solorio (eds.), Proceedings of the 2019 Conference of the North
American Chapter of the Association for Computational Linguistics: Human Language Technologies,
Volume 1 (Long and Short Papers), pp. 2368‚Äì2378, Minneapolis, Minnesota, June 2019. Association
for Computational Linguistics. doi: 10.18653/v1/N19-1246.
Yan Duan, John Schulman, Xi Chen, Peter L. Bartlett, Ilya Sutskever, and Pieter Abbeel. RL^2: Fast
reinforcement learning via slow reinforcement learning. In International Conference on Learning
Representations, 2017.
Adrien Ecoffet, Jeff Clune, and Joel Lehman. Open questions in creating safe open-ended AI: Tensions
between control and creativity. In Conference on Artificial Life, pp. 27‚Äì35. MIT Press, 2020.
Thomas Elsken, Jan Hendrik Metzen, and Frank Hutter. Neural architecture search: A survey. Journal
of Machine Learning Research, 20(55):1‚Äì21, 2019.
Maxence Faldor, Jenny Zhang, Antoine Cully, and Jeff Clune. Omni-epic: Open-endedness via
models of human notions of interestingness with environments programmed in code. arXiv preprint
arXiv:2405.15568, 2024.
Chrisantha Fernando, Dylan Sunil Banarse, Henryk Michalewski, Simon Osindero, and Tim Rockt√§schel. Promptbreeder: Self-referential self-improvement via prompt evolution, 2024.
Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation of
deep networks. In International conference on machine learning, pp. 1126‚Äì1135. PMLR, 2017.
Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, and
Graham Neubig. Pal: Program-aided language models. In International Conference on Machine
Learning, pp. 10764‚Äì10799. PMLR, 2023.
Ryan Greenblatt. Getting 50% sota on arc-agi with gpt-4. https://redwoodresearch.substack.
com/p/getting-50-sota-on-arc-agi-with-gpt, July 2024. Technical Report.
Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob
Steinhardt. Measuring massive multitask language understanding. In International Conference on
Learning Representations, 2021.
16
Automated Design of Agentic Systems
Sirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng Cheng, Jinlin Wang, Ceyao Zhang, Zili Wang,
Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, et al. Metagpt: Meta programming for multi-agent
collaborative framework. arXiv preprint arXiv:2308.00352, 2023.
Shengran Hu and Jeff Clune. Thought Cloning: Learning to think while acting by imitating human
thinking. Advances in Neural Information Processing Systems, 36, 2024.
Shengran Hu, Ran Cheng, Cheng He, Zhichao Lu, Jing Wang, and Miao Zhang. Accelerating multiobjective neural architecture search by random-weight evaluation. Complex & Intelligent Systems,
pp. 1‚Äì10, 2021.
Shihua Huang, Zhichao Lu, Kalyanmoy Deb, and Vishnu Naresh Boddeti. Revisiting residual networks
for adversarial robustness. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
Recognition, pp. 8202‚Äì8211, 2023.
Frank Hutter, Lars Kotthoff, and Joaquin Vanschoren. Automated machine learning: methods, systems,
challenges. Springer Nature, 2019.
Omar Khattab, Arnav Singhvi, Paridhi Maheshwari, Zhiyuan Zhang, Keshav Santhanam, Saiful
Haq, Ashutosh Sharma, Thomas T Joshi, Hanna Moazam, Heather Miller, et al. Dspy: Compiling
declarative language model calls into state-of-the-art pipelines. In The Twelfth International
Conference on Learning Representations, 2024.
Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convolutional
neural networks. Advances in neural information processing systems, 25, 2012.
Abrahim Ladha. Lecture 11: Turing-completeness. https://faculty.cc.gatech.edu/~ladha/
S24/4510/L11.pdf, 2024. CS 4510 Automata and Complexity, February 21st, 2024, Scribed by
Rishabh Singhal.
LangChainAI. Langchain: Build context-aware reasoning applications. https://github.com/
langchain-ai/langchain, 2022.
Joel Lehman and Kenneth O Stanley. Abandoning objectives: Evolution through the search for novelty
alone. Evolutionary computation, 19(2):189‚Äì223, 2011.
Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal,
Heinrich K√ºttler, Mike Lewis, Wen-tau Yih, Tim Rockt√§schel, et al. Retrieval-augmented generation
for knowledge-intensive nlp tasks. Advances in Neural Information Processing Systems, 33:9459‚Äì9474,
2020.
Fei Liu, Tong Xialiang, Mingxuan Yuan, Xi Lin, Fu Luo, Zhenkun Wang, Zhichao Lu, and Qingfu
Zhang. Evolution of heuristics: Towards efficient automatic algorithm design using large language
model. In Forty-first International Conference on Machine Learning, 2024.
Zijun Liu, Yanzhe Zhang, Peng Li, Yang Liu, and Diyi Yang. Dynamic llm-agent network: An llm-agent
collaboration framework with agent team optimization. arXiv preprint arXiv:2310.02170, 2023.
Chris Lu, Sebastian Towers, and Jakob Foerster. Arbitrary order meta-learning with simple populationbased evolution. In ALIFE 2023: Ghost in the Machine: Proceedings of the 2023 Artificial Life
Conference. MIT Press, 2023.
Chris Lu, Samuel Holt, Claudio Fanconi, Alex J Chan, Jakob Foerster, Mihaela van der Schaar, and
Robert Tjarko Lange. Discovering preference optimization algorithms with and for large language
models. arXiv preprint arXiv:2406.08414, 2024a.
17
Automated Design of Agentic Systems
Chris Lu, Cong Lu, Robert Tjarko Lange, Jakob Foerster, Jeff Clune, and David Ha. The AI Scientist:
Towards fully automated open-ended scientific discovery. arXiv preprint arXiv:2408.06292, 2024b.
Cong Lu, Shengran Hu, and Jeff Clune. Intelligent go-explore: Standing on the shoulders of giant
foundation models. arXiv preprint arXiv:2405.15143, 2024c.
Zhichao Lu, Ian Whalen, Vishnu Boddeti, Yashesh Dhebar, Kalyanmoy Deb, Erik Goodman, and
Wolfgang Banzhaf. Nsga-net: neural architecture search using multi-objective genetic algorithm.
In Proceedings of the genetic and evolutionary computation conference, pp. 419‚Äì427, 2019.
Yecheng Jason Ma, William Liang, Guanzhi Wang, De-An Huang, Osbert Bastani, Dinesh Jayaraman,
Yuke Zhu, Linxi Fan, and Anima Anandkumar. Eureka: Human-level reward design via coding
large language models. In The Twelfth International Conference on Learning Representations, 2023.
Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri
Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, et al. Self-refine: Iterative refinement with
self-feedback. Advances in Neural Information Processing Systems, 36, 2024.
Meta. Open source ai is the path forward. https://about.fb.com/news/2024/07/
open-source-ai-is-the-path-forward/, July 2024. News article.
Elliot Meyerson, Mark J Nelson, Herbie Bradley, Adam Gaier, Arash Moradi, Amy K Hoover, and
Joel Lehman. Language model crossover: Variation through few-shot prompting. arXiv preprint
arXiv:2302.12170, 2023.
Shen-yun Miao, Chao-Chun Liang, and Keh-Yih Su. A diverse corpus for evaluating and developing
english math word problem solvers. In Proceedings of the 58th Annual Meeting of the Association for
Computational Linguistics, pp. 975‚Äì984, 2020.
Jean-Baptiste Mouret and Jeff Clune. Illuminating search spaces by mapping elites. arXiv preprint
arXiv:1504.04909, 2015.
Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher
Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, et al. Webgpt: Browser-assisted questionanswering with human feedback. arXiv preprint arXiv:2112.09332, 2021.
Andrew Ng. Issue 253. https://www.deeplearning.ai/the-batch/issue-253/, June 2024.
Newsletter issue.
Ben Norman and Jeff Clune. First-explore, then exploit: Meta-learning intelligent exploration. arXiv
preprint arXiv:2307.02276, 2023.
OpenAI. Introducing chatgpt. https://openai.com/index/chatgpt/, November 2022. Blog
post.
OpenAI. Simple evals, 2023. URL https://github.com/openai/simple-evals. Accessed:
2024-08-10.
OpenAI. Gpt-4 technical report, 2024.
Joon Sung Park, Joseph O‚ÄôBrien, Carrie Jun Cai, Meredith Ringel Morris, Percy Liang, and Michael S
Bernstein. Generative agents: Interactive simulacra of human behavior. In Proceedings of the 36th
annual acm symposium on user interface software and technology, pp. 1‚Äì22, 2023.
18
Automated Design of Agentic Systems
Arkil Patel, Satwik Bhattamishra, and Navin Goyal. Are NLP models really able to solve simple
math word problems? In Proceedings of the 2021 Conference of the North American Chapter of the
Association for Computational Linguistics: Human Language Technologies, pp. 2080‚Äì2094, Online,
June 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.naacl-main.168.
Chen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su, Juyuan Xu, Zhiyuan Liu, and Maosong
Sun. Communicative agents for software development. arXiv preprint arXiv:2307.07924, 2023.
Chen Qian, Zihao Xie, Yifei Wang, Wei Liu, Yufan Dang, Zhuoyun Du, Weize Chen, Cheng Yang,
Zhiyuan Liu, and Maosong Sun. Scaling large-language-model-based multi-agent collaboration.
arXiv preprint arXiv:2406.07155, 2024.
Changle Qu, Sunhao Dai, Xiaochi Wei, Hengyi Cai, Shuaiqiang Wang, Dawei Yin, Jun Xu, and Ji-Rong
Wen. Tool learning with large language models: A survey. arXiv preprint arXiv:2405.17935, 2024.
Rafael Rafailov, Archit Sharma, Eric Mitchell, Christopher D Manning, Stefano Ermon, and Chelsea
Finn. Direct preference optimization: Your language model is secretly a reward model. Advances in
Neural Information Processing Systems, 36, 2024.
David Rein, Betty Li Hou, Asa Cooper Stickland, Jackson Petty, Richard Yuanzhe Pang, Julien Dirani,
Julian Michael, and Samuel R. Bowman. Gpqa: A graduate-level google-proof q&a benchmark,
2023.
Toran Bruce Richards. Autogpt. https://github.com/Significant-Gravitas/AutoGPT,
2023. GitHub repository.
Tim Rockt√§schel. Artificial Intelligence: 10 Things You Should Know. Seven Dials, September 2024.
ISBN 978-1399626521.
Md Omar Faruk Rokon, Risul Islam, Ahmad Darki, Evangelos E Papalexakis, and Michalis Faloutsos.
{SourceFinder}: Finding malware {Source-Code} from publicly available repositories in {GitHub}.
In 23rd International Symposium on Research in Attacks, Intrusions and Defenses (RAID 2020), pp.
149‚Äì163, 2020.
Bernardino Romera-Paredes, Mohammadamin Barekatain, Alexander Novikov, Matej Balog, M Pawan
Kumar, Emilien Dupont, Francisco JR Ruiz, Jordan S Ellenberg, Pengming Wang, Omar Fawzi, et al.
Mathematical discoveries from program search with large language models. Nature, 625(7995):
468‚Äì475, 2024.
Timo Schick, Jane Dwivedi-Yu, Roberto Dessi, Roberta Raileanu, Maria Lomeli, Eric Hambro, Luke
Zettlemoyer, Nicola Cancedda, and Thomas Scialom. Toolformer: Language models can teach
themselves to use tools. In Thirty-seventh Conference on Neural Information Processing Systems,
2023. URL https://openreview.net/forum?id=Yacmpz84TH.
Sander Schulhoff, Michael Ilie, Nishant Balepur, Konstantine Kahadze, Amanda Liu, Chenglei Si,
Yinheng Li, Aayush Gupta, HyoJung Han, Sevien Schulhoff, et al. The prompt report: A systematic
survey of prompting techniques. arXiv preprint arXiv:2406.06608, 2024.
Xuan Shen, Yaohua Wang, Ming Lin, Yilun Huang, Hao Tang, Xiuyu Sun, and Yanzhi Wang. Deepmad:
Mathematical architecture design for deep convolutional neural network. In Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 6163‚Äì6173, 2023.
Freda Shi, Mirac Suzgun, Markus Freitag, Xuezhi Wang, Suraj Srivats, Soroush Vosoughi, Hyung Won
Chung, Yi Tay, Sebastian Ruder, Denny Zhou, Dipanjan Das, and Jason Wei. Language models
19
Automated Design of Agentic Systems
are multilingual chain-of-thought reasoners. In The Eleventh International Conference on Learning
Representations, 2023.
Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik Narasimhan, and Shunyu Yao. Reflexion:
Language agents with verbal reinforcement learning. Advances in Neural Information Processing
Systems, 36, 2023.
Kenneth O Stanley and Joel Lehman. Why greatness cannot be planned: The myth of the objective.
Springer, 2015.
Kenneth O Stanley, Jeff Clune, Joel Lehman, and Risto Miikkulainen. Designing neural networks
through neuroevolution. Nature Machine Intelligence, 1(1):24‚Äì35, 2019.
Richard S Sutton and Andrew G Barto. Reinforcement learning: An introduction. MIT press, 2018.
Sai Vemprala, Rogerio Bonatti, Arthur Bucker, and Ashish Kapoor. Chatgpt for robotics:
Design principles and model abilities. Technical Report MSR-TR-2023-8, Microsoft,
February 2023. URL https://www.microsoft.com/en-us/research/publication/
chatgpt-for-robotics-design-principles-and-model-abilities/.
Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, and
Anima Anandkumar. Voyager: An open-ended embodied agent with large language models. arXiv
preprint arXiv: Arxiv-2305.16291, 2023a.
Jane X Wang, Zeb Kurth-Nelson, Dhruva Tirumala, Hubert Soyer, Joel Z Leibo, Remi Munos, Charles
Blundell, Dharshan Kumaran, and Matt Botvinick. Learning to reinforcement learn. arXiv preprint
arXiv:1611.05763, 2016.
Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai
Tang, Xu Chen, Yankai Lin, et al. A survey on large language model based autonomous agents.
Frontiers of Computer Science, 18(6):186345, 2024.
Rui Wang, Joel Lehman, Jeff Clune, and Kenneth O. Stanley. Poet: open-ended coevolution of
environments and their optimized solutions. In Proceedings of the Genetic and Evolutionary Computation Conference, GECCO ‚Äô19, pp. 142‚Äì151, New York, NY, USA, 2019. Association for Computing
Machinery. ISBN 9781450361118. doi: 10.1145/3321707.3321799.
Rui Wang, Joel Lehman, Aditya Rawal, Jiale Zhi, Yulun Li, Jeffrey Clune, and Kenneth Stanley.
Enhanced poet: Open-ended reinforcement learning through unbounded invention of learning
challenges and their solutions. In International conference on machine learning, pp. 9940‚Äì9951.
PMLR, 2020.
Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V Le, Ed H. Chi, Sharan Narang, Aakanksha
Chowdhery, and Denny Zhou. Self-consistency improves chain of thought reasoning in language
models. In The Eleventh International Conference on Learning Representations, 2023b.
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou,
et al. Chain-of-thought prompting elicits reasoning in large language models. Advances in neural
information processing systems, 35:24824‚Äì24837, 2022.
Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang Zhu, Beibin Li, Li Jiang,
Xiaoyun Zhang, and Chi Wang. Autogen: Enabling next-gen llm applications via multi-agent
conversation framework. arXiv preprint arXiv:2308.08155, 2023.
20
Automated Design of Agentic Systems
Benfeng Xu, An Yang, Junyang Lin, Quan Wang, Chang Zhou, Yongdong Zhang, and Zhendong Mao.
Expertprompting: Instructing large language models to be distinguished experts. arXiv preprint
arXiv:2305.14688, 2023.
Chengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu, Quoc V Le, Denny Zhou, and Xinyun Chen.
Large language models as optimizers. In The Twelfth International Conference on Learning Representations, 2024. URL https://openreview.net/forum?id=Bb4VGOWELI.
Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik R Narasimhan, and Yuan
Cao. React: Synergizing reasoning and acting in language models. In The Eleventh International
Conference on Learning Representations, 2023. URL https://openreview.net/forum?id=WE_
vluYUL-X.
Bennet Yee, David Sehr, Gregory Dardyk, J Bradley Chen, Robert Muth, Tavis Ormandy, Shiki Okasaka,
Neha Narula, and Nicholas Fullagar. Native client: A sandbox for portable, untrusted x86 native
code. Communications of the ACM, 53(1):91‚Äì99, 2010.
Wenhao Yu, Nimrod Gileadi, Chuyuan Fu, Sean Kirmani, Kuang-Huei Lee, Montserrat Gonzalez
Arenas, Hao-Tien Lewis Chiang, Tom Erez, Leonard Hasenclever, Jan Humplik, et al. Language to
rewards for robotic skill synthesis. In Conference on Robot Learning, pp. 374‚Äì404. PMLR, 2023.
Siyu Yuan, Kaitao Song, Jiangjie Chen, Xu Tan, Dongsheng Li, and Deqing Yang. Evoagent: Towards
automatic multi-agent generation via evolutionary algorithms. arXiv preprint arXiv:2406.14228,
2024.
Eliezer Yudkowsky et al. Artificial Intelligence as a positive and negative factor in global risk. Global
catastrophic risks, 1(303):184, 2008.
Matei Zaharia, Omar Khattab, Lingjiao Chen, Jared Quincy Davis, Heather Miller, Chris Potts,
James Zou, Michael Carbin, Jonathan Frankle, Naveen Rao, and Ali Ghodsi. The shift
from models to compound ai systems. https://bair.berkeley.edu/blog/2024/02/18/
compound-ai-systems/, 2024.
Jenny Zhang, Joel Lehman, Kenneth Stanley, and Jeff Clune. OMNI: Open-endedness via models of human notions of interestingness. In The Twelfth International Conference on Learning Representations,
2024a. URL https://openreview.net/forum?id=AgM3MzT99c.
Shaokun Zhang, Jieyu Zhang, Jiale Liu, Linxin Song, Chi Wang, Ranjay Krishna, and Qingyun
Wu. Offline training of language model agents with functions as learnable weights. In Forty-first
International Conference on Machine Learning, 2024b.
Zeyu Zhang, Xiaohe Bo, Chen Ma, Rui Li, Xu Chen, Quanyu Dai, Jieming Zhu, Zhenhua Dong, and
Ji-Rong Wen. A survey on the memory mechanism of large language model based agents. arXiv
preprint arXiv:2404.13501, 2024c.
Huaixiu Steven Zheng, Swaroop Mishra, Xinyun Chen, Heng-Tze Cheng, Ed H Chi, Quoc V Le, and
Denny Zhou. Take a step back: Evoking reasoning via abstraction in large language models. arXiv
preprint arXiv:2310.06117, 2023.
Pei Zhou, Jay Pujara, Xiang Ren, Xinyun Chen, Heng-Tze Cheng, Quoc V Le, Ed H Chi, Denny Zhou,
Swaroop Mishra, and Huaixiu Steven Zheng. Self-discover: Large language models self-compose
reasoning structures. arXiv preprint arXiv:2402.03620, 2024a.
21
Automated Design of Agentic Systems
Wangchunshu Zhou, Yixin Ou, Shengwei Ding, Long Li, Jialong Wu, Tiannan Wang, Jiamin Chen,
Shuai Wang, Xiaohua Xu, Ningyu Zhang, et al. Symbolic learning enables self-evolving agents.
arXiv preprint arXiv:2406.18532, 2024b.
Mingchen Zhuge, Wenyi Wang, Louis Kirsch, Francesco Faccio, Dmitrii Khizbullin, and J√ºrgen
Schmidhuber. Gptswarm: Language agents as optimizable graphs. In Forty-first International
Conference on Machine Learning, 2024.
Luisa Zintgraf, Sebastian Schulze, Cong Lu, Leo Feng, Maximilian Igl, Kyriacos Shiarlis, Yarin Gal, Katja
Hofmann, and Shimon Whiteson. Varibad: Variational bayes-adaptive deep rl via meta-learning.
Journal of Machine Learning Research, 22(289):1‚Äì39, 2021a.
Luisa M Zintgraf, Leo Feng, Cong Lu, Maximilian Igl, Kristian Hartikainen, Katja Hofmann, and
Shimon Whiteson. Exploration in approximate hyper-state space for meta reinforcement learning.
In International Conference on Machine Learning, pp. 12991‚Äì13001. PMLR, 2021b.
22
Automated Design of Agentic Systems
Supplementary Material
Table of Contents
A Prompts 24
B Framework Code 26
C Experiment Details for ARC Challenge 30
D Experiment Details for Reasoning and Problem-Solving Domains 33
E Baselines 35
F Example Agents 36
G Cost of Experiments 39
23
Automated Design of Agentic Systems
A. Prompts
We use the following prompts for the meta agent in Meta Agent Search. Variables in the prompts
that vary depending on domains and iterations are highlighted. All detailed prompts are available at
https://github.com/ShengranHu/ADAS.
We use the following system prompt for every query in the meta agent.
System prompt for the meta agent.
You are a helpful assistant. Make sure to return in a WELL-FORMED JSON object.
We use the following prompt for the meta agent to design the new agent based on the archive of
previously discovered agents.
Main prompt for the meta agent.
You are an expert machine learning researcher testing various agentic systems. Your objective is to design
building blocks such as prompts and control flows within these systems to solve complex tasks. Your aim
is to design an optimal agent performing well on [Brief Description of the Domain].
[Framework Code]
[Output Instructions and Examples]
[Discovered Agent Archive] (initialized with baselines, updated at every iteration)
# Your task
You are deeply familiar with prompting techniques and the agent works from the literature. Your goal is
to maximize the specified performance metrics by proposing interestingly new agents.
Observe the discovered agents carefully and think about what insights, lessons, or stepping stones can be
learned from them.
Be creative when thinking about the next interesting agent to try. You are encouraged to draw inspiration
from related agent papers or academic papers from other research areas.
Use the knowledge from the archive and inspiration from academic literature to propose the next
interesting agentic system design.
THINK OUTSIDE THE BOX.
The domain descriptions are available in Appendices C and D and the framework code is available
in Appendix B. We use the following prompt to instruct and format the output of the meta agent.
Here, we collect and present some common mistakes that the meta agent may make in the prompt.
We found it effective in improving the quality of the generated code.
Output Instruction and Example.
# Output Instruction and Example:
The first key should be (‚Äúthought‚Äù), and it should capture your thought process for designing the
next function. In the ‚Äúthought‚Äù section, first reason about what the next interesting agent to try
should be, then describe your reasoning and the overall concept behind the agent design, and
finally detail the implementation steps. The second key (‚Äúname‚Äù) corresponds to the name of
your next agent architecture. Finally, the last key (‚Äúcode‚Äù) corresponds to the exact ‚Äúforward()‚Äù
function in Python code that you would like to try. You must write COMPLETE CODE in ‚Äúcode‚Äù:
Your code will be part of the entire project, so please implement complete, reliable, reusable code snippets.
24
Automated Design of Agentic Systems
Here is an example of the output format for the next agent:
{‚Äúthought‚Äù: ‚Äú**Insights:** Your insights on what should be the next interesting agent. **Overall Idea:**
your reasoning and the overall concept behind the agent design. **Implementation:** describe the
implementation step by step.‚Äù,
‚Äúname‚Äù: ‚ÄúName of your proposed agent‚Äù,
‚Äúcode‚Äù: ‚Äúdef forward(self, taskInfo): # Your code here‚Äù}
## WRONG Implementation examples:
[Examples of potential mistakes the meta agent may make in implementation]
After the first response from the meta agent, we perform two rounds of self-reflection to make the
generated agent novel and error-free (Madaan et al., 2024; Shinn et al., 2023).
Prompt for self-reflection round 1.
[Generated Agent from Previous Iteration]
Carefully review the proposed new architecture and reflect on the following points:
1. **Interestingness**: Assess whether your proposed architecture is interesting or innovative compared
to existing methods in the archive. If you determine that the proposed architecture is not interesting,
suggest a new architecture that addresses these shortcomings.
- Make sure to check the difference between the proposed architecture and previous attempts.
- Compare the proposal and the architectures in the archive CAREFULLY, including their actual differences
in the implementation.
- Decide whether the current architecture is innovative.
- USE CRITICAL THINKING!
2. **Implementation Mistakes**: Identify any mistakes you may have made in the implementation.
Review the code carefully, debug any issues you find, and provide a corrected version. REMEMBER
checking "## WRONG Implementation examples" in the prompt.
3. **Improvement**: Based on the proposed architecture, suggest improvements in the detailed
implementation that could increase its performance or effectiveness. In this step, focus on refining and
optimizing the existing implementation without altering the overall design framework, except if you
want to propose a different architecture if the current is not interesting.
- Observe carefully about whether the implementation is actually doing what it is supposed to do.
- Check if there is redundant code or unnecessary steps in the implementation. Replace them with
effective implementation.
- Try to avoid the implementation being too similar to the previous agent.
And then, you need to improve or revise the implementation, or implement the new proposed architecture
based on the reflection.
Your response should be organized as follows:
"reflection": Provide your thoughts on the interestingness of the architecture, identify any mistakes in the
implementation, and suggest improvements.
"thought": Revise your previous proposal or propose a new architecture if necessary, using the same
format as the example response.
"name": Provide a name for the revised or new architecture. (Don‚Äôt put words like "new" or "improved"
in the name.)
"code": Provide the corrected code or an improved implementation. Make sure you actually implement
your fix and improvement in this code.
25
Automated Design of Agentic Systems
Prompt for self-reflection round 2.
Using the tips in ‚Äú## WRONG Implementation examples‚Äù section, further revise the code.
Your response should be organized as follows:
Include your updated reflections in the ‚Äúreflection‚Äù. Repeat the previous ‚Äúthought‚Äù and ‚Äúname‚Äù. Update
the corrected version of the code in the ‚Äúcode‚Äù section.
When an error is encountered during the execution of the generated code, we conduct a reflection
and re-run the code. This process is repeated up to five times if errors persist. Here is the prompt we
use to self-reflect any runtime error:
Prompt for self-reflection when a runtime error occurs.
Error during evaluation:
[Runtime errors]
Carefully consider where you went wrong in your latest implementation. Using insights from previous
attempts, try to debug the current code to implement the same thought. Repeat your previous thought in
‚Äúthought‚Äù, and put your thinking for debugging in ‚Äúdebug_thought‚Äù.
B. Framework Code
In this paper, we provide the meta agent with a simple framework to implement basic functions,
such as querying Foundation Models (FMs) and formatting prompts. The framework consists of
fewer than 100 lines of code (excluding comments). In this framework, we encapsulate every
piece of information into a namedtuple Info object, making it easy to combine different types of
information (e.g., FM responses, results from tool function calls, task descriptions) and facilitate
communication between different modules. Additionally, in the FM module, we automatically construct
the prompt by concatenating all input Info objects into a structured format, with each Info titled by
its metadata (e.g., name, author). Throughout the appendix, we renamed some variables in the
code to match the terminologies used in the main text. The full framework code is available at
https://github.com/ShengranHu/ADAS.
Code 1 | The simple framework used in Meta-Agent Search.
1 # Named tuple for holding task information
2 Info = namedtuple (‚ÄôInfo ‚Äô, [‚Äôname ‚Äô, ‚Äôauthor ‚Äô, ‚Äôcontent ‚Äô, ‚Äô
iteration_idx ‚Äô])
3
4 # Format instructions for FM response
5 FORMAT_INST = lambda request_keys : f" Reply EXACTLY with the
following JSON format .\n{str( request_keys )}\ nDO NOT MISS ANY
FIELDS AND MAKE SURE THE JSON FORMAT IS CORRECT !\n"
6
7 # Description of the role of the FM Module
8 ROLE_DESC = lambda role : f"You are a { role }."
9
10 @backoff . on_exception ( backoff . expo , openai . RateLimitError )
11 def get_json_response_from_gpt ( msg , model , system_message ,
temperature ) :
12 \"""
13 Function to get JSON response from GPT model .
14
15 Args :
16 - msg (str ): The user message .
26
Automated Design of Agentic Systems
17 - model (str ): The model to use .
18 - system_message (str ): The system message .
19 - temperature ( float ): Sampling temperature .
20
21 Returns :
22 - dict : The JSON response .
23 \"""
24 ...
25 return json_dict
26
27 class FM_Module :
28 \"""
29 Base class for an FM module .
30
31 Attributes :
32 - output_fields ( list ): Fields expected in the output .
33 - name (str ): Name of the FM module .
34 - role (str ): Role description for the FM module .
35 - model (str ): Model to be used .
36 - temperature ( float ): Sampling temperature .
37 - id (str ): Unique identifier for the FM module instance .
38 \"""
39
40 def __init__ ( self , output_fields : list , name : str , role =‚Äôhelpful
assistant ‚Äô, model =‚Äôgpt -3.5 - turbo -0125 ‚Äô, temperature =0.5) ->
None :
41 ...
42
43 def generate_prompt ( self , input_infos , instruction ) -> str:
44 \"""
45 Generates a prompt for the FM.
46
47 Args :
48 - input_infos ( list ): List of input information .
49 - instruction (str ): Instruction for the task .
50
51 Returns :
52 - tuple : System prompt and user prompt .
53
54 An example of generated prompt :
55 ""
56 You are a helpful assistant .
57
58 # Output Format :
59 Reply EXACTLY with the following JSON format .
60 ...
61
62 # Your Task :
63 You will given some number of paired example inputs and
outputs . The outputs ...
64
65 ### thinking #1 by Chain -of - Thought hkFo ( yourself ):
66 ...
67
68 # Instruction :
69 Please think step by step and then solve the task by writing
27
Automated Design of Agentic Systems
the code .
70 ""
71 \"""
72 ...
73 return system_prompt , prompt
74
75 def query ( self , input_infos : list , instruction , iteration_idx
= -1) -> list [ Info ]:
76 \"""
77 Queries the FM with provided input information and
instruction .
78
79 Args :
80 - input_infos ( list ): List of input information .
81 - instruction (str ): Instruction for the task .
82 - iteration_idx (int ): Iteration index for the task .
83
84 Returns :
85 - output_infos ( list [ Info ]): Output information .
86 \"""
87 ...
88 return output_infos
89
90 def __repr__ ( self ) :
91 return f"{ self . agent_name } { self .id}"
92
93 def __call__ ( self , input_infos : list , instruction , iteration_idx
= -1) :
94 return self . query ( input_infos , instruction , iteration_idx =
iteration_idx )
95
96 class AgentSystem :
97 def forward ( self , taskInfo ) -> Union [ Info , str ]:
98 \"""
99 Placeholder method for processing task information .
100
101 Args :
102 - taskInfo ( Info ): Task information .
103
104 Returns :
105 - Answer ( Union [Info , str ]): Your FINAL Answer . Return
either a namedtuple Info or a string for the answer .
106 \"""
107 pass
With the provided framework, an agent can be easily defined with a ‚Äúforward‚Äù function. Here we
show an example of implementing self-reflection using the framework.
Code 2 | Self-Reflection implementation example
1 def forward ( self , taskInfo ) :
2 # Instruction for initial reasoning
3 cot_initial_instruction = " Please think step by step and then
solve the task ."
4
5 # Instruction for reflecting on previous attempts and feedback
28
Automated Design of Agentic Systems
to improve
6 cot_reflect_instruction = " Given previous attempts and feedback ,
carefully consider where you could go wrong in your latest
attempt . Using insights from previous attempts , try to solve
the task better ."
7 cot_module = FM_Module ([ ‚Äôthinking ‚Äô, ‚Äôanswer ‚Äô] , ‚ÄôChain -of - Thought
‚Äô)
8
9 # Instruction for providing feedback and correcting the answer
10 critic_instruction = " Please review the answer above and
criticize on where might be wrong . If you are absolutely sure
it is correct , output ‚ÄôTrue ‚Äô in ‚Äôcorrect ‚Äô."
11 critic_module = FM_Module ([ ‚Äôfeedback ‚Äô, ‚Äôcorrect ‚Äô] , ‚ÄôCritic ‚Äô)
12
13 N_max = 5 # Maximum number of attempts
14
15 # Initial attempt
16 cot_inputs = [ taskInfo ]
17 thinking , answer = cot_module ( cot_inputs ,
cot_initial_instruction , 0)
18
19 for i in range ( N_max ) :
20 # Get feedback and correct status from the critic
21 feedback , correct = critic_module ([ taskInfo , thinking ,
answer ] , critic_instruction , i )
22 if correct . content == ‚ÄôTrue ‚Äô:
23 break
24
25 # Add feedback to the inputs for the next iteration
26 cot_inputs . extend ([ thinking , answer , feedback ])
27
28 # Reflect on previous attemps and refine the answer
29 thinking , answer = cot_module ( cot_inputs ,
cot_reflect_instruction , i + 1)
30 return answer
29
Automated Design of Agentic Systems
Example Input-output grid #1
Example Input-output grid #2
Test grid
Answer
Figure 4 | An example task from the ARC challenge (Chollet, 2019). Given the input-output grid
examples, the AI system is asked to learn the transformation rules and then apply these learned rules
to the test grid to predict the final answer.
C. Experiment Details for ARC Challenge
An example task from the ARC challenge is shown in Figure 4. In the ARC challenge experiments
(Section 4.1), we represent the grids as strings of 2-D arrays, where each color is represented by an
integer. We instruct the meta agent to design agents that generate code as solutions rather than directly
outputting answers. Additionally, we provide two tool functions within the framework: (1) to test
whether the generated code can solve the example grids and (2) to obtain the task‚Äôs answer by applying
the generated code to the test grid. The accuracy rate is calculated by the Exact Match between the
reference solution and the predicted answer. The meta agent uses ‚Äúgpt-4o-2024-05-13‚Äù (OpenAI,
2024), while discovered agents and baselines are evaluated using ‚Äúgpt-3.5-turbo-0125‚Äù (OpenAI,
2022) to reduce compute cost.
The domain description of ARC for the meta agent is shown below:
Description of ARC for the meta agent.
Your aim is to find an optimal agent performing well on the ARC (Abstraction and Reasoning Corpus)
challenge.
In this challenge, each task consists of three demonstration examples, and one test example. Each
Example consists of an ‚Äúinput grid‚Äù and an ‚Äúoutput grid‚Äù. Test-takers need to use the transformation rule
learned from the examples to predict the output grid for the test example.
30
Automated Design of Agentic Systems
# An example task from ARC challenge:
## Task Overview:
You will be given some number of paired example inputs and outputs grids. The outputs were produced
by applying a transformation rule to the input grids. In addition to the paired example inputs and
outputs, there is also one test input without a known output.
The inputs and outputs are each ‚Äúgrids‚Äù. A grid is a rectangular matrix of integers between 0 and 9
(inclusive). Each number corresponds to a color. 0 is black.
Your task is to determine the transformation rule from examples and find out the answer, involving
determining the size of the output grid for the test and correctly filling each cell of the grid with the
appropriate color or number.
The transformation only needs to be unambiguous and applicable to the example inputs and the test
input. It doesn‚Äôt need to work for all possible inputs. Observe the examples carefully, imagine the grid
visually, and try to find the pattern.
## Examples:
### Example 0:
input = [[0,0,0,0,5,0,0,0,0], [0,0,0,0,5,0,0,0,0], [0,0,0,4,5,0,0,0,0], [0,0,0,4,5,4,4,0,0],
[0,0,3,3,5,0,0,0,0], [0,0,0,3,5,0,0,0,0], [0,0,0,3,5,3,3,3,0], [0,0,0,3,5,0,0,0,0], [0,0,0,0,5,0,0,0,0],
[0,0,0,0,5,0,0,0,0]]
output = [[0,0,0,0], [0,0,0,0], [0,0,0,4], [0,0,4,4], [0,0,3,3], [0,0,0,3], [0,3,3,3], [0,0,0,3], [0,0,0,0],
[0,0,0,0]]
### Example 1:
input = [[0,0,0,0,5,0,0,0,0], [0,0,0,2,5,0,0,0,0], [0,0,0,2,5,2,6,0,0], [0,0,0,2,5,0,0,0,0],
[0,0,0,2,5,2,2,2,0], [0,0,6,6,5,6,0,0,0], [0,0,0,2,5,0,0,0,0], [0,2,2,0,5,2,0,0,0], [0,0,0,2,5,0,0,0,0],
[0,0,0,0,5,0,0,0,0]]
output = [[0,0,0,0], [0,0,0,2], [0,0,6,2], [0,0,0,2], [0,2,2,2], [0,0,6,6], [0,0,0,2], [0,2,2,2], [0,0,0,2],
[0,0,0,0]]
### Example 2:
input = [[0,0,0,0,5,0,0,0,0], [0,0,0,0,5,7,0,0,0], [0,0,0,8,5,0,0,0,0], [0,0,0,8,5,0,0,0,0],
[0,7,8,8,5,0,0,0,0], [0,0,0,0,5,8,8,0,0], [0,0,0,8,5,0,0,0,0], [0,0,0,8,5,0,0,0,0], [0,0,0,0,5,8,7,0,0],
[0,0,0,0,5,0,0,0,0]]
output= [[0,0,0,0], [0,0,0,7], [0,0,0,8], [0,0,0,8], [0,7,8,8], [0,0,8,8], [0,0,0,8], [0,0,0,8], [0,0,7,8],
[0,0,0,0]]
### Test Problem:
input = [[0,0,0,0,5,0,0,0,0], [0,0,0,1,5,0,0,0,0], [0,0,0,1,5,1,0,0,0], [0,1,1,1,5,1,1,1,6],
[0,0,0,6,5,6,6,0,0], [0,0,0,0,5,1,1,1,0], [0,0,0,1,5,0,0,0,0], [0,0,0,1,5,1,6,0,0], [0,0,0,0,5,6,0,0,0],
[0,0,0,0,5,0,0,0,0]]
Analyze the transformation rules based on the provided Examples and determine what the output should
be for the Test Problem.
Here we present the best agent on ARC discovered by Meta Agent Search. All agents from the
experiment can be found at https://github.com/ShengranHu/ADAS.
Code 3 | The best agent on ARC discovered by Meta Agent Search
1 # Structured Feedback and Ensemble Agent
2 def forward ( self , taskInfo ) :
3 # Step 1: Generate initial candidate solutions using multiple FM
Modules
31
Automated Design of Agentic Systems
4 initial_instruction = ‚ÄôPlease think step by step and then solve
the task by writing the code .‚Äô
5 num_candidates = 5 # Number of initial candidates
6 initial_module = [ FM_Module ([ ‚Äôthinking ‚Äô, ‚Äôcode ‚Äô] , ‚ÄôInitial
Solution ‚Äô, temperature =0.8) for _ in range ( num_candidates ) ]
7
8 initial_solutions = []
9 for i in range ( num_candidates ) :
10 thoughts = initial_module [ i ]([ taskInfo ] , initial_instruction
)
11 thinking , code = thoughts [0] , thoughts [1]
12 feedback , correct_examples , wrong_examples = self .
run_examples_and_get_feedback ( code )
13 if len ( correct_examples ) > 0: # Only consider solutions
that passed at least one example
14 initial_solutions . append ({ ‚Äôthinking ‚Äô: thinking , ‚Äôcode ‚Äô:
code , ‚Äôfeedback ‚Äô: feedback , ‚Äô correct_count ‚Äô: len (
correct_examples ) })
15
16 # Step 2: Simulate human - like feedback for each candidate
solution
17 human_like_feedback_module = FM_Module ([ ‚Äôthinking ‚Äô, ‚Äôfeedback ‚Äô] ,
‚ÄôHuman - like Feedback ‚Äô, temperature =0.5)
18 human_feedback_instruction = ‚ÄôPlease provide human - like feedback
for the code , focusing on common mistakes , heuristic
corrections , and best practices .‚Äô
19
20 for sol in initial_solutions :
21 thoughts = human_like_feedback_module ([ taskInfo , sol [‚Äô
thinking ‚Äô] , sol [‚Äôcode ‚Äô]] , human_feedback_instruction )
22 human_thinking , human_feedback = thoughts [0] , thoughts [1]
23 sol [‚Äô human_feedback ‚Äô] = human_feedback
24
25 # Step 3: Assign expert advisors to evaluate and provide
targeted feedback
26 expert_roles = [‚ÄôEfficiency Expert ‚Äô, ‚Äô Readability Expert ‚Äô, ‚Äô
Simplicity Expert ‚Äô]
27 expert_advisors = [ FM_Module ([ ‚Äôthinking ‚Äô, ‚Äôfeedback ‚Äô] , role ,
temperature =0.6) for role in expert_roles ]
28 expert_instruction = ‚ÄôPlease evaluate the given code and provide
targeted feedback for improvement .‚Äô
29
30 for sol in initial_solutions :
31 sol_feedback = {}
32 for advisor in expert_advisors :
33 thoughts = advisor ([ taskInfo , sol [‚Äôthinking ‚Äô] , sol [‚Äôcode
‚Äô]] , expert_instruction )
34 thinking , feedback = thoughts [0] , thoughts [1]
35 sol_feedback [ advisor . role ] = feedback
36 sol [‚Äô expert_feedback ‚Äô] = sol_feedback
37
38 # Step 4: Parse and structure the feedback to avoid redundancy
and refine the solutions iteratively
39 max_refinement_iterations = 3
40 refinement_module = FM_Module ([ ‚Äôthinking ‚Äô, ‚Äôcode ‚Äô] , ‚ÄôRefinement
Module ‚Äô, temperature =0.5)
32
Automated Design of Agentic Systems
41 refined_solutions = []
42
43 for sol in initial_solutions :
44 for i in range ( max_refinement_iterations ) :
45 combined_feedback = sol [‚Äôfeedback ‚Äô]. content + sol [‚Äô
human_feedback ‚Äô]. content + ‚Äô‚Äô. join ([ fb . content for fb
in sol [‚Äô expert_feedback ‚Äô]. values () ])
46 structured_feedback = ‚Äô ‚Äô. join (set( combined_feedback .
split () ) ) # Avoid redundancy
47 refinement_instruction = ‚ÄôUsing the structured feedback ,
refine the solution to improve its performance .‚Äô
48 thoughts = refinement_module ([ taskInfo , sol [‚Äôthinking ‚Äô] ,
sol [‚Äôcode ‚Äô] , Info (‚Äôfeedback ‚Äô, ‚ÄôStructured Feedback ‚Äô,
structured_feedback , i ) ] , refinement_instruction , i )
49 refinement_thinking , refined_code = thoughts [0] ,
thoughts [1]
50 feedback , correct_examples , wrong_examples = self .
run_examples_and_get_feedback ( refined_code )
51 if len ( correct_examples ) > 0:
52 sol . update ({ ‚Äôthinking ‚Äô: refinement_thinking , ‚Äôcode ‚Äô:
refined_code , ‚Äôfeedback ‚Äô: feedback , ‚Äô
correct_count ‚Äô: len( correct_examples ) })
53 refined_solutions . append ( sol )
54
55 # Step 5: Select the best - performing solutions and make a final
decision using an ensemble approach
56 sorted_solutions = sorted ( refined_solutions , key = lambda x : x [‚Äô
correct_count ‚Äô] , reverse = True )
57 top_solutions = sorted_solutions [:3] # Select the top 3
solutions
58
59 final_decision_instruction = ‚ÄôGiven all the above solutions ,
reason over them carefully and provide a final answer by
writing the code .‚Äô
60 final_decision_module = refinement_module ([ ‚Äôthinking ‚Äô, ‚Äôcode ‚Äô] ,
‚ÄôFinal Decision Module ‚Äô, temperature =0.1)
61 final_inputs = [ taskInfo ] + [ item for solution in top_solutions
for item in [ solution [‚Äôthinking ‚Äô] , solution [‚Äôcode ‚Äô] , solution
[‚Äôfeedback ‚Äô]]]
62 final_thoughts = final_decision_module ( final_inputs ,
final_decision_instruction )
63 final_thinking , final_code = final_thoughts [0] , final_thoughts
[1]
64 answer = self . get_test_output_from_code ( final_code )
65 return answer
D. Experiment Details for Reasoning and Problem-Solving Domains
To reduce costs during search and evaluation, we sample subsets of data from each domain. For GPQA
(Science), the validation set consists of 32 questions, while the remaining 166 questions form the
test set. For the other domains, the validation and test sets are sampled with 128 and 800 questions,
respectively. We evaluate agents five times for GPQA and once for the other domains to maintain a
consistent total number of evaluations. Each domain uses zero-shot style questions, except DROP
(Reading Comprehension), which uses one-shot style questions following the practice in (OpenAI,
33
Automated Design of Agentic Systems
2023). The meta agent uses ‚Äúgpt-4o-2024-05-13‚Äù (OpenAI, 2024), while discovered agents and
baselines are evaluated using ‚Äúgpt-3.5-turbo-0125‚Äù (OpenAI, 2022) to reduce compute cost.
We present the description of each domain we provide to the meta agent.
Description of DROP (Reading Comprehension).
Your aim is to find an optimal agent performing well on the Reading Comprehension Benchmark
Requiring Discrete Reasoning Over Paragraphs (DROP), which assesses the ability to perform discrete
reasoning and comprehend detailed information across multiple paragraphs.
## An example question from DROP:
You will be asked to read a passage and answer a question.
Passage:
Non-nationals make up more than half of the population of Bahrain, with immigrants making up
about 55% of the overall population. Of those, the vast majority come from South and Southeast Asia:
according to various media reports and government statistics dated between 2005-2009 roughly 290,000
Indians, 125,000 Bangladeshis, 45,000 Pakistanis, 45,000 Filipinos, and 8,000 Indonesians.
Question: What two nationalities had the same number of people living in Bahrain between
2005-2009?
Answer [Not Given]: Pakistanis and Filipinos
Description of GPQA (Science) for the meta agent.
Your aim is to find an optimal agent performing well on the GPQA (Graduate-Level Google-Proof Q&A
Benchmark). This benchmark consists of challenging multiple-choice questions across the domains of
biology, physics, and chemistry, designed by domain experts to ensure high quality and difficulty.
## An example question from GPQA:
Two quantum states with energies E1 and E2 have a lifetime of 10‚àí9 sec and 10‚àí8 sec, respectively. We
want to clearly distinguish these two energy levels. Which one of the following options could be their
energy difference so that they be clearly resolved?
Answer choices:
10‚àí9 eV
10‚àí8 eV
10‚àí7 eV
10‚àí6 eV
Correct answer [Not provided]:
10‚àí7 eV
Explanation [Not provided]:
According to the uncertainty principle, Delta E* Delta t=hbar/2. Delta t is the lifetime and Delta E is the
width of the energy level. With Delta t=10‚àí9 s==> Delta E1= 3.3 10‚àí7 ev. And Delta t=10‚àí11 s gives
Delta E2=3.310‚àí8 eV. Therefore, the energy difference between the two states must be significantly
greater than 10‚àí7 ev. So the answer is 10‚àí4 ev.
34
Automated Design of Agentic Systems
Description of MGSM (Math) for the meta agent.
Your aim is to find an optimal agent performing well on the Multilingual Grade School Math Benchmark
(MGSM) which evaluates mathematical problem-solving abilities across various languages to ensure
broad and effective multilingual performance.
## An example question from MGSM:
**Question**: „Åì„ÅÆÊï∞Â≠¶„ÅÆÂïèÈ°å„ÇíËß£„ÅÑ„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ
ËøëÊâÄ„Åß„ÅØ„ÄÅ„Éö„ÉÉ„Éà„ÅÆ„Ç¶„Çµ„ÇÆ„ÅÆÊï∞„Åå„Éö„ÉÉ„Éà„ÅÆÁä¨„Å®Áå´„ÇíÂêà„Çè„Åõ„ÅüÊï∞„Çà„Çä„ÇÇ12ÂåπÂ∞ë„Å™„ÅÑ„ÄÇÁä¨1Âåπ„ÅÇ„Åü„Çä2Âåπ
„ÅÆÁå´„Åå„Åä„Çä„ÄÅÁä¨„ÅÆÊï∞„ÅØ60Âåπ„Å†„Å®„Åô„Çã„Å®„ÄÅÂÖ®ÈÉ®„ÅßËøëÊâÄ„Å´„ÅØ‰ΩïÂåπ„ÅÆ„Éö„ÉÉ„Éà„Åå„ÅÑ„Åæ„Åô„ÅãÔºü
**Answer (Not Given)**: 348
Description of MMLU (Mult-task) for the meta agent.
Your aim is to find an optimal agent performing well on the MMLU (Massive Multitask Language
Understanding) benchmark, a challenging evaluation that assesses a model‚Äôs ability to answer questions
across a wide range of subjects and difficulty levels. It includes subjects from STEM, social sciences,
humanities, and more.
## An example question from MMLU:
Answer the following multiple-choice question.
The constellation ... is a bright W-shaped constellation in the northern sky.
(A) Centaurus
(B) Cygnus
(C) Cassiopeia
(D) Cepheus
E. Baselines
In this paper, we implement five state-of-the-art hand-designed agent baselines for experiments
on ARC (Section 4.1): (1) Chain-of-Thought (COT) (Wei et al., 2022), (2) Self-Consistency with
Chain-of-Thought (COT-SC)(Wang et al., 2023b), (3) Self-Refine (Madaan et al., 2024; Shinn et al.,
2023), (4) LLM-Debate (Du et al., 2023), and (5) Quality-Diversity, a simplified version of Intelligent
Go-Explore (Lu et al., 2024c).
In addition to these baselines, we implement two more for experiments on Reasoning and
Problem-Solving domains (Section 4.2): (6) Step-back Abstraction (Zheng et al., 2023) and (7)
Role Assignment (Xu et al., 2023). An example implementation of Self-Refine with our simple
framework is shown in Appendix B. Detailed implementations of all baselines can be found at
https://github.com/ShengranHu/ADAS.
In COT, we prompt the FM to think step by step before answering the question. In COT-SC, we
sample ùëÅ = 5 answers and then perform an ensemble using either majority voting or an FM query.
In Self-Refine, we allow up to five refinement iterations, with an early stop if the critic deems the
answer correct. In LLM-Debate, each debate module is assigned a unique role, such as Physics Expert
or Chemistry Expert, and the debate lasts for two rounds. In Quality-Diversity, we conduct three
35
Automated Design of Agentic Systems
iterations to collect diverse answers based on previously proposed ones. In Role Assignment, we use
an FM query to first choose a role from a predefined set, and then use another FM query to answer
the question by acting within the chosen role.
F. Example Agents
In this section, we present the detailed implementation of three example discovered agents by Meta
Agent Search shown in Figure 1. The ‚ÄúMulti-Step Peer Review Agent‚Äù and ‚ÄúDivide and Conquer Agent‚Äù
were discovered during the search in the Reading Comprehension domain (GPQA) (Rein et al., 2023),
while the ‚ÄúVerified Multimodal Agent‚Äù was discovered during the search in the Math domain (MGSM)
(Shi et al., 2023). All discovered agents can be found at https://github.com/ShengranHu/ADAS.
Code 4 | Example discovered agent: Multi-Step Peer Review Agent
1 def forward ( self , taskInfo ) :
2 initial_instruction = " Please think step by step and then solve
the task ."
3 critique_instruction = " Please review the answer above and
provide feedback on where it might be wrong . If you are
absolutely sure it is correct , output ‚ÄôTrue ‚Äô in ‚Äôcorrect ‚Äô."
4 refine_instruction = " Given previous attempts and feedback ,
carefully consider where you could go wrong in your latest
attempt . Using insights from previous attempts , try to solve
the task better ."
5 final_decision_instruction = " Given all the above thinking and
answers , reason over them carefully and provide a final
answer ."
6
7 FM_modules = [ FM_module ([ ‚Äôthinking ‚Äô, ‚Äôanswer ‚Äô] , ‚ÄôFM Module ‚Äô,
role = role ) for role in [‚ÄôPhysics Expert ‚Äô, ‚ÄôChemistry Expert ‚Äô,
‚ÄôBiology Expert ‚Äô, ‚ÄôScience Generalist ‚Äô]]
8 critic_modules = [ FM_module ([ ‚Äôfeedback ‚Äô, ‚Äôcorrect ‚Äô] , ‚ÄôCritic ‚Äô,
role = role ) for role in [‚ÄôPhysics Critic ‚Äô, ‚ÄôChemistry Critic ‚Äô,
‚ÄôBiology Critic ‚Äô, ‚ÄôGeneral Critic ‚Äô]]
9 final_decision_module = FM_module ([ ‚Äôthinking ‚Äô, ‚Äôanswer ‚Äô] , ‚ÄôFinal
Decision ‚Äô, temperature =0.1)
10
11 all_thinking = [[] for _ in range (len( FM_modules ) ) ]
12 all_answer = [[] for _ in range (len( FM_modules ) ) ]
13 all_feedback = [[] for _ in range (len( FM_modules ) ) ]
14
15 for i in range (len( FM_modules ) ) :
16 thinking , answer = FM_modules [ i ]([ taskInfo ] ,
initial_instruction )
17 all_thinking [ i ]. append ( thinking )
18 all_answer [ i ]. append ( answer )
19
20 for i in range (len( FM_modules ) ) :
21 for j in range (len( FM_modules ) ) :
22 if i != j :
23 feedback , correct = critic_modules [ j ]([ taskInfo ,
all_thinking [ i ][0] , all_answer [ i ][0]] ,
critique_instruction )
24 all_feedback [ i ]. append ( feedback )
25
36
Automated Design of Agentic Systems
26 for i in range (len( FM_modules ) ) :
27 refine_inputs = [ taskInfo , all_thinking [ i ][0] , all_answer [ i
][0]] + all_feedback [ i ]
28 thinking , answer = FM_modules [ i ]( refine_inputs ,
refine_instruction )
29 all_thinking [ i ]. append ( thinking )
30 all_answer [ i ]. append ( answer )
31
32 final_inputs = [ taskInfo ] + [ all_thinking [ i ][1] for i in range (
len( FM_modules ) ) ] + [ all_answer [ i ][1] for i in range (len(
FM_modules ) ) ]
33 thinking , answer = final_decision_module ( final_inputs ,
final_decision_instruction )
34
35 return answer
Code 5 | Example discovered agent: Divide and Conquer Agent
1 def forward ( self , taskInfo ) :
2 # Step 1: Decompose the problem into sub - problems
3 decomposition_instruction = " Please decompose the problem into
smaller , manageable sub - problems . List each sub - problem
clearly ."
4 decomposition_module = FM_Module ([ ‚Äôthinking ‚Äô, ‚Äô sub_problems ‚Äô] , ‚Äô
Decomposition Module ‚Äô)
5
6 # Step 2: Assign each sub - problem to a specialized expert
7 sub_problem_instruction = " Please think step by step and then
solve the sub - problem ."
8 specialized_experts = [ FM_Module ([ ‚Äôthinking ‚Äô, ‚Äô sub_solution ‚Äô] , ‚Äô
Specialized Expert ‚Äô, role = role ) for role in [‚ÄôPhysics Expert ‚Äô
, ‚ÄôChemistry Expert ‚Äô, ‚ÄôBiology Expert ‚Äô, ‚ÄôGeneral Expert ‚Äô]]
9
10 # Step 3: Integrate the sub - problem solutions into the final
answer
11 integration_instruction = " Given the solutions to the sub -
problems , integrate them to provide a final answer to the
original problem ."
12 integration_module = FM_Module ([ ‚Äôthinking ‚Äô, ‚Äôanswer ‚Äô] , ‚Äô
Integration Module ‚Äô, temperature =0.1)
13
14 # Decompose the problem
15 thinking , sub_problems = decomposition_module ([ taskInfo ] ,
decomposition_instruction )
16
17 # Ensure sub_problems is a string and split into individual sub -
problems
18 sub_problems_list = sub_problems . content . split (‚Äô\n‚Äô) if
isinstance ( sub_problems . content , str) else []
19
20 # Solve each sub - problem
21 sub_solutions = []
22 for i , sub_problem in enumerate ( sub_problems_list ) :
23 sub_problem_info = Info (‚Äô sub_problem ‚Äô, decomposition_module .
__repr__ () , sub_problem , i )
24 sub_thinking , sub_solution = specialized_experts [ i % len (
37
Automated Design of Agentic Systems
specialized_experts ) ]([ sub_problem_info ] ,
sub_problem_instruction )
25 sub_solutions . append ( sub_solution )
26
27 # Integrate the sub - problem solutions
28 integration_inputs = [ taskInfo ] + sub_solutions
29 thinking , answer = integration_module ( integration_inputs ,
integration_instruction )
30
31 return answer
Code 6 | Example discovered agent: Verified Multimodal Agent
1 def forward ( self , taskInfo ) :
2 # Instruction for generating visual representation of the
problem
3 visual_instruction = " Please create a visual representation (e.g
. , diagram , graph ) of the given problem ."
4
5 # Instruction for verifying the visual representation
6 verification_instruction = " Please verify the accuracy and
relevance of the visual representation . Provide feedback and
suggestions for improvement if necessary ."
7
8 # Instruction for solving the problem using the verified visual
aid
9 cot_instruction = " Using the provided visual representation ,
think step by step and solve the problem ."
10
11 # Instantiate the visual representation module , verification
module , and Chain -of - Thought module
12 visual_module = FM_Module ([ ‚Äôvisual ‚Äô] , ‚ÄôVisual Representation
Module ‚Äô)
13 verification_module = FM_Module ([ ‚Äôfeedback ‚Äô, ‚Äô verified_visual ‚Äô] ,
‚Äô Verification Module ‚Äô)
14 cot_module = FM_Module ([ ‚Äôthinking ‚Äô, ‚Äôanswer ‚Äô] , ‚ÄôChain -of - Thought
Module ‚Äô)
15
16 # Generate the visual representation of the problem
17 visual_output = visual_module ([ taskInfo ] , visual_instruction )
18 visual_representation = visual_output [0] # Using Info object
directly
19
20 # Verify the visual representation
21 feedback , verified_visual = verification_module ([ taskInfo ,
visual_representation ] , verification_instruction )
22
23 # Use the verified visual representation to solve the problem
24 thinking , answer = cot_module ([ taskInfo , verified_visual ] ,
cot_instruction )
25 return answer
38
Automated Design of Agentic Systems
G. Cost of Experiments
A single run of search and evaluation on ARC (Section 4.1) costs approximately $500 USD in OpenAI
API costs, while a run within the reasoning and problem-solving domains (Section 4.2) costs about
$300 USD.
The primary expense comes from querying the ‚Äúgpt-3.5-turbo-0125‚Äù model during the evaluation
of discovered agents. Notably, the latest GPT-4 model, ‚Äúgpt-4o-mini,‚Äù is less than one-third the price
of ‚Äúgpt-3.5-turbo-0125‚Äù and offers better performance, suggesting that we could achieve improved
results with Meta Agent Search at just one-third of the cost. Additionally, as discussed in Section 6, the
current naive evaluation function is both expensive and overlooks valuable information. We anticipate
that future work adopting more sophisticated evaluation functions could significantly reduce the cost
of ADAS algorithms.
39

---
./notebooks/assets/papers/paper3.txt
---
https://arxiv.org/pdf/2404.12272
Who Validates the Validators? Aligning LLM-Assisted Evaluation
of LLM Outputs with Human Preferences
Shreya Shankar
UC Berkeley
Berkeley, California, USA
shreyashankar@berkeley.edu
J.D. Zamfirescu-Pereira
UC Berkeley
Berkeley, California, USA
zamfi@berkeley.edu
Bj√∂rn Hartmann
UC Berkeley
Berkeley, California, USA
bjoern@eecs.berkeley.edu
Aditya G. Parameswaran
UC Berkeley
Berkeley, California, USA
adityagp@berkeley.edu
Ian Arawjo
Universit√© de Montr√©al
Montr√©al, Qu√©bec, Canada
ian.arawjo@umontreal.ca
ABSTRACT
Due to the cumbersome nature of human evaluation and limitations
of code-based evaluation, Large Language Models (LLMs) are increasingly being used to assist humans in evaluating LLM outputs.
Yet LLM-generated evaluators simply inherit all the problems of
the LLMs they evaluate, requiring further human validation. We
present a mixed-initiative approach to ‚Äúvalidate the validators‚Äù‚Äî
aligning LLM-generated evaluation functions (be it prompts or
code) with human requirements. Our interface, EvalGen, provides
automated assistance to users in generating evaluation criteria and
implementing assertions. While generating candidate implementations (Python functions, LLM grader prompts), EvalGen asks
humans to grade a subset of LLM outputs; this feedback is used to
select implementations that better align with user grades. A qualitative study finds overall support for EvalGen but underscores
the subjectivity and iterative process of alignment. In particular,
we identify a phenomenon we dub criteria drift: users need criteria
to grade outputs, but grading outputs helps users define criteria.
What is more, some criteria appears dependent on the specific LLM
outputs observed (rather than independent criteria that can be defined a priori), raising serious questions for approaches that assume
the independence of evaluation from observation of model outputs.
We present our interface and implementation details, a comparison
of our algorithm with a baseline approach, and implications for the
design of future LLM evaluation assistants.
CCS CONCEPTS
‚Ä¢ Human-centered computing ‚Üí Interactive systems and
tools; ‚Ä¢ Computing methodologies ‚Üí Natural language processing.
KEYWORDS
language models, auditing, evaluation, interfaces, prompt engineering, active learning
1 INTRODUCTION
Large Language Models (LLMs) make mistakes‚Äîthey hallucinate, ignore instructions, and generate outputs that require validation [25].
But validating the behavior of LLMs is challenging. In response,
researchers and industry developers have created tools for prompt
engineering and auditing that help people with testing outputs more
systematically [1, 16, 23, 24, 27, 36, 41, 52]. Such approaches require
metrics‚Äîa set of functions to automatically score LLM outputs,
each typically an assertion with true or false values. These metrics
increasingly include calls to ‚Äúevaluator‚Äù LLMs (e.g., [1, 27, 52, 58])
that act as ‚Äújudges,‚Äù grading outputs on qualities hard to articulate
in code; for instance, the ‚Äúconciseness‚Äù of an output.
The problem is that, just like the LLMs they evaluate, LLMs that
perform evaluations cannot be trusted. These ‚Äúgrader‚Äù prompts
suffer from the same problems as any other prompt‚Äîthey are unintuitively sensitive to seemingly minor changes in wording or
structure [43]. Yet many existing systems do not include support
for verifying the quality of LLM-generated evaluations, asking users
to simply trust these outputs. How can users reap the efficiency
benefits of LLM-assisted evaluation of LLM outputs, while minimizing or avoiding misalignment? How can we help users validate
the validators?
In this paper, we propose a mixed-initiative approach, EvalGen,
to address this automated-evaluation alignment problem in the context of prompt engineering. Our approach streamlines the selection
of metrics under practical constraints of user effort and latency.
Specifically, an LLM suggests criteria in natural language, based on
user context (e.g., the prompt under test), that the user can modify.
An LLM then generates a pool of candidate assertions for each
criterion‚Äîeither code or LLM grader prompts that output ‚Äútrue‚Äù or
‚Äúfalse.‚Äù While the user waits for the LLM to generate candidates, they
are asked to grade outputs with a simple ‚Äúgood‚Äù (thumbs-up) or
‚Äúbad‚Äù (thumbs-down) voting scheme. These grades then guide the
automatic selection of assertions that optimize for alignment with
user preferences (Section 4.2). After assertion selection, a final report card reveals the alignment between the chosen assertions and
the user‚Äôs grades. Our approach generalizes beyond the particulars
of our specific design, and could be extended to, for instance, update
metric implementations with feedback from human preferences, or
query the user for finer-grained individual grades.
EvalGen is embedded inside an existing open-source interface
for prompt engineering and auditing, ChainForge [1]. Our alignment algorithm adapts SPADE [45], a fully-automated algorithm
for generating Python assertions from the revision history of a
prompt. We performed an off-line verification of our human-guided
alignment algorithm with SPADE as a baseline [45], then ran a
qualitative user study with nine (9) industry practitioners that use
arXiv:2404.12272v1 [cs.HC] 18 Apr 2024
Shreya Shankar, J.D. Zamfirescu-Pereira, Bj√∂rn Hartmann, Aditya G. Parameswaran, and Ian Arawjo
LLMs in production contexts. Because our participants were industry practitioners and thus possibly dealing with NDA-protected
data, we offered a task adapted from a real LLM pipeline prompt.
Our study design did not impose restrictions on how participants
used EvalGen, and users could choose whether to ask the tool to
suggest criteria, enter criteria manually, or grade a few LLM outputs
first before proceeding onto the criteria specification screen.
Our findings find overall support for EvalGen, with one important caveat. We observed a ‚Äúcatch-22‚Äù situation: to grade outputs,
people need to externalize and define their evaluation criteria; however, the process of grading outputs helps them to define that very
criteria. We dub this phenomenon criteria drift, and it implies that
it is impossible to completely determine evaluation criteria prior to
human judging of LLM outputs. Even when participants graded
first, we observed that they still refined their criteria upon further
grading, even going back to change previous grades. Thus, our findings suggest that users need evaluation assistants to support rapid
iteration over criteria and implementations simultaneously. Since
criteria are dependent upon LLM outputs (and not independent from
them), this raises questions about how to contend with criteria drift
in the context of other ‚Äúdrifts‚Äù‚Äîe.g., model drift [4], prompt edits,
or upstream changes in a chain. Our findings also (i) underscore
the necessity of mixed-initiative approaches to the alignment of
LLM-assisted evaluations that also embrace messiness and iteration,
and (ii) raise broader questions about what ‚Äúalignment with user
preferences‚Äù means for evaluation assistants.
We first position our work (Section 2) and present EvalGen‚Äôs
design (Sec. 3) and implementation details (Sec. 4). We then present
two evaluations: an off-line evaluation of our approach (Sec. 5), and
a qualitative study with developers (Sec. 6 & 7). Finally, we suggest
implications for future work (Sec. 8).
2 MOTIVATION AND RELATED WORK
In response to the popularity of black-boxed LLMs like ChatGPT,
prompt engineering (PE) has emerged as a new practice and research area. Alongside PE is the auditing of model behavior in
practices such as ‚Äúred-teaming,‚Äù used to identify harmful outputs in
internal teams to tweak LLM behavior, usually prior to release [32,
p.17]. These tasks have spurred the advent of new tools for ‚ÄúLLM
operations‚Äù (hereafter called LLMOps) and new terminology such
as ‚Äúprompt template,‚Äù ‚Äúchain of thought‚Äù, ‚Äúchains,‚Äù etc.
Automating Evaluations of Prompts. When evaluating LLM
behavior, users typically send off hundreds or thousands of queries
to models. As users reach the limits of manual evaluation, users set
up automated evaluation pipelines (Figure 1a) in code or with other
LLMs (here we use the term LLM-based evaluators; other work uses
terms such as ‚ÄúLLM-as-a-judge‚Äù [58] or ‚Äúco-audit‚Äù [18]).1
Public PE
tools like promptfoo [52] and ChainForge [1] allow users to write
their own evaluation metrics to score LLM response quality, and
support both code-based and LLM-based evaluators. For instance,
in promptfoo users can write a rubric in a config file to specify how
an LLM should evaluate responses, and may use pre-created grader
prompt templates or customize them; an example is the assertion
1An analog of this problem exists in software engineering as well: developing a set of
assertions, often in the form of a set of unit tests or regression tests, that give developers
confidence that their code is correct and that code changes do not (re)introduce bugs.
‚ÄúThe response is not apologetic.‚Äù Prototypes such as EvalLM [27]
and PromptsRoyale [40] also support LLM evaluators, oftentimes
exclusively, to help users compare between two prompts. Of PE
tools, only EvalLM offers a way to help users calculate the alignment of LLM evaluators with their expectations, but this feature is
mentioned only in authors‚Äô Design section and is absent from their
user study.2 At best, users of PE tools inspect LLM-generated evaluator outputs manually to double-check; at worst, the tool hides
individual scores entirely. Regardless of aligning implementations
of metrics with user preferences, even identifying what metrics to
evaluate for custom tasks remains challenging for LLM practitioners, as evidenced by a recent study [37]. While many evaluation
tools require users to declare metrics they care about, some prior
work [45] and EvalGen employ LLMs to propose custom metrics
based on prompts in the user‚Äôs LLM pipelines.
Over-trust and Over-generalization of LLM Behavior. That
tools provide little assistance to validate evaluator quality is alarming, considering that other research shows people tend to over-rely
and over-trust AI systems [3, 28, 31, 50]. For instance, in one highprofile incident, researchers from MIT posted a pre-print on arXiv
claiming that GPT-4 could ace the MIT EECS exam. Within hours,
work by Chowdhuri et al. debunked the study [5], citing problems
arising from over-reliance on GPT-4 to grade itself. Other work
has found further reasons to be cautious: LLMs asked to choose
the best response from a set can be consistently biased by set ordering [30, 51]; and LLMs can be highly sensitive to seemingly
innocuous formatting changes [43].
A related problem to over-reliance is over-generalization. Zamfirescu et al. [57] found that users unfamiliar with PE tend to overgeneralize from single failures (causing them to throw out potentially good prompts), rather than having a holistic view of the
overall performance of a prompt or chain. This was despite the
fact that the interface had support for systematic testing. Similarly,
Arawjo et al. [1] found that even people familiar with LLMs (developers, academics in ML) struggled to scale up their evaluations,
appearing to over-generalize from a limited number of outputs
even after an automated evaluation pipeline was setup. The authors
identified three modes of PE on open-domain tasks, with the second, ‚Äúlimited evaluation,‚Äù‚Äô characterized as users ‚Äúprototyping an
evaluation‚Äù [1], and suggested that future work focus on supported
users in prototyping evaluation pipelines. Over-generalization is
common in traditional ML, too‚ÄîKocielnik et al. [29] found that AI
systems that showcase subsets of errors, like false positives or false
negatives, that have the same accuracy, can lead to vastly different
perceptions of accuracy.
Approaches to Aligning LLMs. The HCI community has extensively studied interactive machine learning (iML). In iML, users
iteratively develop models by selecting training examples, labeling
data, and evaluating model performance [10]. Interfaces that facilitate seamless transitions between these activities result in fewer
errors and outputs that better match users‚Äô expectations [38, 46].
Some iML interfaces even use ML to assist users, for example, in
scaling up labeling‚Äîreducing overall user effort required [8]. When
using iML concepts for developing LLM pipelines, we must acknowledge a key challenge with LLMs: they often work with little to no
2As of this writing, EvalLM is not publicly released.
Who Validates the Validators? Aligning LLM-Assisted Evaluation of LLM Outputs with Human Preferences
Inputs
Prompt
Under Test
LLM
Outputs Metrics
Evaluator LLM
Metric Prompt
Metric (Code)
‚Ä¶
Test Results
‚Ä¶
iterate
(a) Typical Evaluation Pipeline
Inputs
Prompt
Under Test
LLM
Outputs
Test Results
Candidate
Criteria
Candidate
Assertions
edit criteria
grade
LLM
outputs
Selected
Assertions
Alignment
Report Card
EvalGen
LLM
LLM
(b) The EvalGen Evaluation Pipeline
Figure 1: EvalGen‚Äôs approach to assisting users in aligning evaluations. Users iterate through the process of refining criteria
and grading. Note that LLM pipeline inputs and outputs are provided by our larger system, and outside the scope of this paper.
specific training data [37]. Users may simply prototype with inputs
they imagine the LLM would see, hoping the prompt generalizes.
In the ML and NLP communities, researchers have explored
many ways to align LLMs‚Äîand their evaluations‚Äîto specific user
tasks. Many approaches rely on custom model training or finetuning [6], but all strategies heavily rely on humans to identify
examples of desirable and undesirable outputs. For instance, Liu
et al. [34] demonstrated using annotated LLM outputs‚Äîjudged on
criteria like consistency and relevance‚Äîas ‚Äúfew-shot examples‚Äù for
calibrating LLM-based evaluators. Beyond classical summarization
and NLP tasks, in response to the ad-hoc tedium of PE [56], academics and developers are building automated prompt optimization
tools, maximizing some user-defined metric on a labeled set of examples. For instance, given some metrics and prompts, Khattab
et al. [26] automatically run variations of inserted few-shot examples and LLM-generated rephrasings to optimize the prompt. Other
work urges users to write assertions to guide outputs with a mix of
code and natural language suggestions [42, 48], but writing these
assertions is left up to developers, which is often time-consuming
and error-prone. A broader point is that research in LLMOps optimization tends to come from the domains of NLP and ML, where
authors generally validate tool performance against benchmark
datasets with pre-defined metrics, leaving open the question of
how well they perform in the wild on idiosyncratic user tasks (e.g.
EvoPrompt, PromptBreeder, AutoCalibrate [12, 20, 34]). It thus remains unclear how to support developers in their prototyping of
evaluations, with the problem becoming even more pressing as the
popularity of prompt optimization increases.
Overall, this work reveals that users need more support for (a)
prototyping evaluations and (b) validating evaluators of LLM outputs. It also reveals that auditing LLM outputs is far from easy, with
humans prone to the dual biases of over-generalization and overreliance. One recent LLM-assisted approach, SPADE [45], makes
headway on these issues, helping developers generate Python assertion functions for LLM outputs from prompt history. Here we
leverage a similar algorithmic approach to SPADE, but embed it
inside an LLM-assisted user interface for evaluator prototyping,
EvalGen, that also assists with criteria generation, measuring alignment with human preferences, and visualizing results.
3 EVALGEN DESIGN
In designing EvalGen, our goal was (1) to investigate how to assist
developers in creating evaluators to grade LLM outputs, and (2) to
help them ‚Äúvalidate the validators‚Äù through both automated assistance and transparency around how aligned each evaluator is with
their expectations. As we covered in Section 2, emerging practices
in prompt engineering, LLM auditing, and prompt optimization
involve the writing of evaluation functions (metrics) to automate
Shreya Shankar, J.D. Zamfirescu-Pereira, Bj√∂rn Hartmann, Aditya G. Parameswaran, and Ian Arawjo
Figure 2: The workflow of our EvalGen prototype, from (a) a Prompt Node attached to an empty Multi-Eval Node, showing a
Generate Criteria button; (b) the pop-up EvalGen Wizard with three options, Infer, Manual, and Grade First; (c) the Pick Criteria
screen, allowing users to describe criteria in natural language and toggle Code or LLM implementations; (d) the Grade screen,
with the LLM output (top), input variables (left), and prompt (right), Good and Bad grade buttons, and an ‚ÄúI‚Äôm Tired‚Äù button
(bottom-right) to finish; and finally (e) the Report Card screen, showing the alignment of each criteria and across criteria.
Hovering over the alignment shows a confusion matrix. Note that some descriptions and elements have been clipped for space.
grading. These functions may be code- or LLM-based. Based on this
context, we set out to design an LLM-powered evaluation assistant
that provided developers control over metric criteria, evaluator type
(code or LLM), and implementation (i.e., function) generation and
selection processes, without asking them to come up with criteria
or write code or grader prompts themselves.
3.1 EvalGen Workflow
We implemented EvalGen in an existing open-source system for
prompt engineering, ChainForge [1], which handles querying multiple LLMs with parametrized prompts, running code- and LLM-based
evaluators, plotting scores, chaining, etc. In ChainForge, users write
LLM pipelines by creating nodes of various types to represent their
dataflow, such as an ‚Äúinput‚Äù node feeding into a ‚Äúprompt‚Äù node.
We discuss here only our extension, chiefly a pop-up screen that
helps the user define, implement, and validate evaluation functions.
We also implemented a new node, Multi-Eval, that allows users to
include multiple evaluators in a single node and run all evaluators
on the outputs of the pipeline‚Äôs previous node. Finally, we made
improvements to plotting per-criteria scores in the Table View of
the LLM output inspector, which can be accessed via the Multi-Eval
node. Fig. 1b provides a high-level overview of the EvalGen architecture compared to the typical LLM output evaluation pipeline;
we discuss implementation details in Sec. 4.
Who Validates the Validators? Aligning LLM-Assisted Evaluation of LLM Outputs with Human Preferences
Figure 2 depicts the workflow of in the context of the EvalGen
interface, excluding returning to the main workflow with selected
implementations and using the Table View to inspect scores. EvalGen assists a developer in engineering an evaluation of LLM outputs
for a single prompt template. First, EvalGen is accessed as a button
on a ‚ÄúMulti-Eval‚Äù node we added to ChainForge, which is attached
to a Prompt Node (Fig. 2a). A Wizard opens, depicting three options
(Fig. 2b): Infer, Manual, and Grade First. A description of EvalGen
(not shown) appears above the options. Clicking Infer or Manual
leads to the Pick Criteria screen (Fig. 2c); clicking Grade First leads
to the Grading screen (Fig. 2d) and asks users to grade at least five
outputs, before continuing to the Pick Criteria screen.
The Pick Criteria interface is depicted in Fig. 2c. An LLM has
generated criteria suggestions in natural language (Sections 4.1
and 4.2), along with a toggle to prefer a Python code-based or
LLM-based evaluator. The user can edit all parts‚Äîincluding the
titles or descriptions and type of evaluator‚Äîor add new criteria
not suggested by the LLM. They can also delete criteria or deselect
criteria as needed. Pressing ‚ÄúImplement It‚Äù passes the criteria to a
second LLM that generates candidate implementations.
While implementations are generated and executed on LLM
outputs, users are asked to grade outputs. EvalGen uses these
grades to implementations with their preferences. Fig. 2d depicts
the Grading screen. A single LLM response is presented to the user,
centered in focus in the grader window. The context of the prompt
and any input variables (vars) is also present. The user grades
outputs with the Good and Bad buttons. Since it may be timeconsuming to ask the developer to grade on a per-criterion basis,
for the grader interface we decided on the simplicity of thumbsup/down scoring. Such scoring is a noisy yet informative signal of
quality‚Äîif a response is given a thumbs-up, it is assumed to pass all
criteria, and so if a candidate assertion fails on that response, the
candidate is down-ranked in the pool (details in Section 4.1). Users
may also click arrows to navigate through outputs (for instance, if
they are unsure about a grade, or want to revise a prior grade).3
Finally, after the user is done grading and all candidate implementations are generated, executed, and filtered for alignment with
grades, a Report Card screen appears with feedback on per-criteria
and aggregate measures of alignment with user grades (Fig. 2e).
Hovering over per-criteria metrics shows a confusion matrix of
how aligned that particular criterion is to the human grades, while
the aggregate metrics show the coverage and false failure rate (see
Section 5) of the selected subset of EvalGen-generated assertions.
The user then returns to the main ChainForge interface (not shown),
where the selected implementations are available in a ‚ÄúMulti-Eval‚Äù
node, titled by criteria. The user can edit or add more criteria, inspect and visualize evaluation results (Fig. 3), etc.; however, this is
outside the scope of our design discussion.
Our design reflects trade-offs between developer effort and robust human verification of LLM-generated metrics. The human
cannot completely validate an LLM-based evaluator: the point of
3
Initially, we had asked users to grade a preset number of outputs and a bar showed
their progress. However, calling LLMs and executing assertions are asynchronous
operations that take an indeterminate amount of time: suggesting an ‚Äúend point‚Äù to user
grading may lose valuable information when the user still has to wait for generations
to return. The user may also find grading enjoyable or important. For these reasons,
we did not seek to limit user grading. However, we kept this number-left progress bar
in the Grade First screen (accessed via Fig.2b).
LLM evaluators is to reduce the effort required by the developer,
who would otherwise have to grade outputs manually. The only
way to fully align an LLM evaluator would be to ask the user to
label all outputs; obviously, this defeats the purpose. Asking the
developer to grade some outputs, using some time they would have
spent waiting anyway, is the key idea behind our design.
4 IMPLEMENTATION
4.1 System Architecture
Like prior work on evaluator assistants [27, 45], our solution decomposes evaluations into criteria and assertions (boolean functions
that implement the criteria, evaluating outputs). We employ LLMs
in generating criteria, based on the prompt [45], and in generating
various candidate implementations of each criterion [27, 45]. As
users grade, we rank candidate assertions that implement each criteria based on their alignment with user grades (see Appendix A.3
for how we define alignment). At a high level, alignment is a combination of the assertion‚Äôs coverage, or ability to fail outputs that the
user thinks are bad, and the false failure rate, or ability to not fail
outputs that the user thinks are good. We give a formal definition
of assertion alignment in Appendix A.3.
EvalGen‚Äôs architecture differs from prior work in two main components: first, EvalGen solicits grades from the user on a sample
of LLM outputs‚Äîrequiring some policy to sample LLM outputs to
grade. Second, in contrast to SPADE [45], which operates offline and
solves an integer linear program to generate the optimal assertion
set, EvalGen employs an online (i.e., streaming) system architecture to progressively optimize for the most aligned assertion set.
When EvalGen generates a new candidate implementation, it immediately executes this implementation on the set of LLM outputs,
culling implementations that are obviously bad (e.g., Python functions with runtime errors). EvalGen maintains a dynamic estimate
of selectivity (i.e., pass rate) for each candidate assertion, which in
turn informs how grades are sampled in the interface. Our system,
as depicted in Figure 1b, is structured into three components:
Criteria Suggestion. We use an GPT-4 to propose various binary evaluation criteria in natural language, such as response length
or tone. Developers can select from these suggestions or add their
own criteria. For each criterion, developers can select whether it
should be evaluated with a purely code-based function or a function
that involves calls to another LLM.
Candidate Assertion Synthesis and Execution. Based on
the selected criteria, we use GPT-4 to asynchronously generate
one or more candidate assertions as code or a grader prompt to
be evaluated by an LLM. For each criterion, we issue one call to
GPT-4 to generate multiple candidate assertions within markers
in a streaming fashion. Every time we detect the end of marker in
any GPT-4 response, we parse the candidate assertion and submit it
to EvalGen‚Äôs executor, which will run it on LLM pipeline outputs.
Generating multiple candidate assertions improves the probability
that there is at least one implementation that aligns with developer
expectations. Moreover, for code-based assertions, LLMs occasionally synthesize erroneous functions (e.g., hallucinating a function
in a Python library), requiring several candidate assertions.
Grading Sampler. This component samples LLM pipeline outputs for the user to give binary feedback on (thumbs up/down).
Shreya Shankar, J.D. Zamfirescu-Pereira, Bj√∂rn Hartmann, Aditya G. Parameswaran, and Ian Arawjo
When the user grades an LLM output, we update internal estimates
of alignment for each candidate assertion, and we sample the next
output for the user to grade.
Once the user does not want to grade LLM outputs anymore,
or is finished grading all outputs, for each criterion, we select the
candidate assertion with the highest alignment with the user‚Äôs
grades. The user can provide a threshold for the false failure rate
(as defined in Section 5) such that EvalGen only selects assertions
that do not exceed this threshold.
4.2 Selecting Assertions & Eliciting Grades
Once the user selects criteria, EvalGen‚Äôs executor begins generating candidate assertions and executing them on all LLM outputs.
EvalGen maintains dynamic estimates for the following:
Selectivity of Candidate Assertions. The selectivity is the
probability that an assertion will classify an LLM output as passing. This probability is adjusted each time EvalGen processes the
outcome of executing a candidate assertion on an LLM output.
Confidence Scores for Potentially Poor Outputs. These
scores estimate the likelihood that an LLM output is of low quality,
without having been explicitly evaluated by the user. The scores
are dependent on assertion selectivity and are revised whenever
EvalGen evaluates a new assertion against an LLM output, or when
a user grades an LLM output directly.
Assertion Alignment. Alignment, or the harmonic mean of
coverage and false failure rate (Appendix A.3), is recalculated for
each assertion every time the user grades an LLM pipeline output.
See Appendix A for a complete description of assertion selectivity
and how it impacts confidence scores; how EvalGen uses these
confidence scores to sample grades from the user; formal definitions
of alignment; and how EvalGen determines the resulting assertion
set based on alignment with grades.
5 ALGORITHM EVALUATION
Here we present results on the effectiveness of EvalGen‚Äôs selection algorithm. Our experiment aimed to understand how soliciting
human input at the criteria suggestion stage impacts the size (number of assertions) and alignment of the resulting assertion set. We
compared to a baseline, SPADE [45], a fully automated system that
generates criteria and candidate assertions and chooses the minimal
assertion set that meet coverage and false failure rate constraints.
5.1 Evaluation Setup
We developed two LLM pipelines based on real-world datasets. The
medical pipeline operates on a dataset of 84 unstructured text transcripts from doctor-patient calls [54], aiming to extract specific
information (e.g., symptoms, medication) without revealing any
personally identifiable information (PII). This task requires assertions to ensure compliance with privacy laws. The product pipeline
involved crafting SEO-friendly descriptions for 100 Amazon products and their reviews [21]. We selected this task because it mirrors
actual LLM applications (there are a number of startups using AI
to write SEO-optimized product descriptions), and it benefits from
assertions: for example, even if there are negative reviews, the descriptions should not say negative things about the products, which
would adversely affect the products‚Äô sales potential. Our prompts
are presented in Appendix B. For both prompts, the placeholder
variables (i.e., transcript and document) represent the input context to inject at pipeline runtime. For each dataset, we executed
the corresponding pipeline once for each input using OpenAI‚Äôs
GPT-3.5-Turbo to generate outputs‚Äîresulting in 84 medical LLM
outputs and 100 product LLM outputs.
Two of the paper authors manually graded all LLM outputs to
establish ground-truth labels. Overall, 68% and 51% of the outputs
were good for the medical and product LLM pipelines, respectively.
Common issues included the presence of personal information in
the medical pipeline outputs and bad reviews or lengthy content in
the product pipeline outputs.
5.2 Impact of Human Input in the Criteria
Generation Step
Here, we report quantitative and qualitative differences in SPADE‚Äôs
and EvalGen‚Äôs assertion sets. There are two differences between
SPADE and EvalGen in how they generate assertion sets. The first
difference is that EvalGen asks the user to add, edit, or remove
criteria before generating different candidate assertions, whereas
SPADE does not solicit any input from the user about the criteria.
The second difference is in the selection of the assertions themselves:
given user-confirmed criteria and a sample of grades provided in
a UI, EvalGen picks the most aligned assertion per criterion that
meets some false failure rate threshold. Meanwhile, SPADE solves
an optimization problem to select a minimal assertion set that meet
a false failure rate threshold and cover all SPADE-generated criteria.
5.2.1 Evaluation Procedure. We first ran SPADE end-to-end for
both LLM pipelines, supplying all labeled LLM outputs to see
the resulting assertion sets. We initially set both false failure rate
thresholds to 10%. While SPADE met this threshold for the medical
pipeline, the product pipeline required adjusting the false failure
rate to 40% to find a viable assertion set. This illustrates the challenge of balancing coverage with false failures, underscoring the
need for evaluator systems to effectively navigate these trade-offs.
Subsequently, we ran EvalGen for both pipelines with the same
false failure rate thresholds. For the medical pipeline, we defined
three evaluation criteria: word count, presence of the six targeted
keys, and absence of PII, with the first two implemented via codebased assertions and the last via an LLM evaluator. The product
pipeline criteria included absence of negative reviews, absence of
links, adherence to markdown format, and word count limitation,
with only the first criterion requiring LLM implementation. To
create the aligned assertion sets, we provided EvalGen with 16
graded outputs per pipeline instead of all 80-100 graded outputs‚Äî
given the impracticality of expecting users to extensively grade in
a single session.
5.2.2 Results. Our results in Table 1 show that EvalGen, by incorporating human judgment during criteria selection, achieved equal
or better alignment than SPADE with fewer assertions for both
pipelines. Specifically, in the product pipeline, EvalGen produced
an assertion set less than half the size of SPADE‚Äôs and increased
coverage from 49% to 73%. This underscores the benefit of involving humans in selecting criteria, as a fully automated tool may
generate assertions for criteria that humans may not actually care
Who Validates the Validators? Aligning LLM-Assisted Evaluation of LLM Outputs with Human Preferences
about writing assertions for. In the medical pipeline, SPADE added
unnecessary assertions, such as one for a neutral tone, not chosen
for EvalGen, and split checks for specific keys into more criteria than needed. For the product pipeline, SPADE generated twice
the number of assertions compared to EvalGen, some of which
were unrealistic, like a Python function designed to flag specific
negative phrases such as ‚Äúnever order‚Äù and ‚Äúdisappointed‚Äù in the
output. In contrast, EvalGen returned a more pragmatic assertion
for this criterion‚Äîan LLM-based validator to ensure the product
descriptions remained entirely positive.
Medical Pipeline Product Pipeline
Metric EvalGen SPADE EvalGen SPADE
Dataset Size 84 84 100 100
# Bad Outputs 27 27 49 49
# Assertions 3 5 4 9
Coverage 0.33 0.33 0.73 0.49
FFR 0.10 0.10 0.39 0.39
Alignment (%) 48.29 48.29 66.46 54.35
Table 1: Comparison of EvalGen and SPADE Across
Pipelines. With user input at the criteria stage, EvalGen
achieves the same or greater alignment with fewer functions.
6 USER STUDY
To understand how developers might use EvalGen to build evaluators for LLM pipelines, we asked nine industry practitioners who
had prior experience with LLMs to use EvalGen and think aloud.
Recruitment and Participants. We recruited nine industry
practitioners via a Twitter post, calling for anyone interested in solving the problem of ‚Äúwho validates the validators.‚Äù We selected the
first nine who had experience coding and building LLM pipelines
for some company or product. Participants included software engineers, ML scientists, startup executives, and independent consultants. We focused on developers with experience with LLMs
because they can best intuit what features of an assertion assistant
they would find useful, compared to their existing workflows.
Procedure. All studies were conducted over Zoom. We first
spent 5 minutes establishing rapport and asking participants about
their backgrounds and experience. We then introduced the participants to our LLM pipeline in ChainForge, where the pipeline‚Äôs task
was to do named entity recognition (NER) on a dataset of tweets.
The LLM used in our pipeline was GPT-3.5-Turbo from OpenAI.
The prompt for our LLM pipeline was as follows: You will be doing
named entity recognition (NER). Extract up to 3 well-known entities
from the following tweet: {tweet_full_text} For each entity, write one
sentence describing the person or entity. All the entities you extract
should be found in a knowledge base like Wikipedia, so don‚Äôt make up
entities. Return your answer as a bulleted Markdown list, where each
bullet is formatted as ‚Äò- entity: description‚Äò. Do not extract hashtags as
entities. We chose this task and set of inputs for three reasons: first,
NER is a common, real-world task that language models excel at;
second, tweets are short and can be displayed in a UI without any
scrolling; third, ‚ÄúNER for tweets‚Äù is a problem that many people
have studied [15, 33, 49]. We allowed participants to change the
task or prompt if they wanted.
Next, we spent a few minutes describing EvalGen‚Äôs functionality.
We showed participants how to view LLM outputs, trigger EvalGen,
write an assertion from scratch and add it to their set, run the
assertion set on all the LLM outputs, and inspect the Table View
plotting results of each assertion on each LLM output. We then gave
the participant remote control access to our screen, instructing them
to come up with an assertion set for the pipeline. Participants were
allowed up to 40 minutes to explore the tool while thinking aloud.
We communicated that we were mainly interested in observing their
process of creating assertions, not interacting with other features of
ChainForge such as comparing different LLM APIs. If the participant
had any questions about the interface, we answered them.
After the participant had an assertion set they liked, or ran out
of time, we asked them open-ended questions. We first asked them
to comment on EvalGen‚Äôs approach to generating assertions, and
whether they felt that the assertions aligned with their grades.
We then asked follow-up questions to learn more about why they
felt a particular way or found some aspect of assertion alignment
challenging. We limited the post-interview to 10 minutes. At the end,
we asked participants to rate how they felt about the assertions‚Äô
alignment on a 7-point Likert scale (1 = strongly disagree, 7 =
strongly agree). Overall, the study ranged from 45min to 1h15min.
Our study was approved by our institutional review board (IRB),
and participants generously volunteered their time.
Analysis. We asked participants to think aloud while using
the tool, while we took notes on their thoughts and any visible
emotions (e.g., delight when EvalGen suggested a criterion they
struggled to externalize, or frustration when they could not find
a good assertion for a criterion). We also recorded the transcripts
for each video call. We employed open and axial coding [13] to
identify common themes across the transcripts and notes for each
participant. Initially, we coded individual sentences of interest for
each participant, then grouped these into broader themes on a perparticipant basis in a second pass of coding. Finally, we consolidated
these themes across all participants, reorganizing them as needed.
7 USER STUDY FINDINGS
Overall, we found that:
‚Ä¢ Participants felt that EvalGen was a great starting point
for assertions, and wanted to‚Äîand could‚Äîexercise control
over EvalGen‚Äôs assistance.
‚Ä¢ Participants struggled to align assertions with their preferences due to two main challenges in grading: (i) some
criteria are difficult for humans to grade (e.g., under a target word count), and (ii) as they grade more LLM outputs,
we observe a criteria drift phenomenon, in which criteria
change as participants grade more LLM outputs (both definitions of existing criteria, and changes to the overall set
of criteria).
‚Ä¢ Participants‚Äô perceptions of alignment and needs varied
based on the evaluator type (i.e., code-based vs. LLM-based).
We unpack these findings below. We first describe the typical
participant workflow and highlight where participants wanted to
exercise control in the process. Then, we discuss the challenges
participants faced in aligning assertions with their preferences.
Shreya Shankar, J.D. Zamfirescu-Pereira, Bj√∂rn Hartmann, Aditya G. Parameswaran, and Ian Arawjo
7.1 Typical Participant Workflow
All participants (ùëõ = 9) used the provided task (a prompt template
for NER of a dataset of 100 tweets, described in 6). Three (3) participants changed the prompt: of these three, one (1) person changed
the task from NER to sentiment analysis. After participants had
settled on their own prompt (or decided they wanted to use our
prompt), each engaged in roughly the following activities:
(1) Eyeballing LLM outputs: Participants viewed the table
of 100 LLM outputs, making sure the outputs seemed reasonable at a glance.
(2) Starting EvalGen: Participants clicked the button to start
EvalGen. This wizard presents three options (Fig. 2b): autogenerate criteria, write criteria, and grade outputs first (before generating criteria). 6 participants clicked the autogenerate button; 1 participant wrote a criterion themselves
and then clicked the auto-generate button. The remaining
2 participants wanted to grade first (P4, P9).
(3) Grading outputs: Participants who graded LLM outputs
first graded between 5 and 10 outputs, with 2 to 4 ‚Äúthumbsdown‚Äù grades. After grading, both participants clicked the
button to auto-generate criteria.
(4) Refining criteria:After receiving criteria suggestions from
EvalGen, participants removed some suggestions and added
1-2 criteria of their own. They usually left evaluation type
(code-based or LLM-based) unchanged from what EvalGen
suggested, even if EvalGen suggested a type that did not
make sense (e.g., checking word count with an LLM API
call, rather than code), which happened rarely.
(5) Grading more outputs: Participants graded outputs while
EvalGen generated and evaluated different candidate assertions. Some participants graded continuously for up to
10 minutes; others stopped after 10 grades.
(6) Understanding alignment on graded outputs: Participants viewed the ‚ÄúReport Card‚Äù screen, where they all spent
a few minutes inspecting the resulting assertion set. Only
one participant did not understand what the overall set‚Äôs
coverage and false failure rate meant (P9), but did once
the researcher explained it. Participants chose to view the
different assertion implementations EvalGen evaluated,
including the ones that did not align with their grades.
(7) Eyeballing alignment on ungraded outputs: Returning
to the main screen, participants clicked the Run button of
the Multi-Eval node to run all assertions on all 100 LLM
outputs and inspected the table of results (Fig. 3).
(8) Iterating on criteria: 3 out of 9 participants again opened
the EvalGen wizard to iterate on their criteria and assertions (back to step 2), or stopped because they were satisfied
or tired. More than half of the participants expressed interest in iterating on their assertions if they had more time.
7.2 EvalGen as a Starting Point
We found that participants liked EvalGen as a starting point to generating assertions. They felt that exerting control was necessary‚Äî
since EvalGen sometimes made mistakes‚Äîand they did not mind
doing so. P8 said:
This is how I would want a workflow to assist me in
evals‚Äîbasically I want the AI to do 80% of it, and
there can be escape hatches if the AI fails.
Here, we discuss what participants liked and disliked in different
components of EvalGen‚Äôs UI.
7.2.1 LLM-generated criteria alleviates writer‚Äôs block. Eight (out
of 9) participants were pleasantly surprised that suggested criteria
reflected the criteria they wanted (all except P3). P4 said, ‚ÄúI get
writer‚Äôs block when thinking about what assertions to write, so
this is great.‚Äù P6 said, ‚ÄúI feel that if I gave my prompt [for my
own pipeline], this would create really good criteria automatically.‚Äù
Some participants had negative initial reactions: for example, P7
initially expressed dissatisfaction that 7 criteria were generated,
as they had expected less. But after deleting some criteria, they
realized that the suggestions covered all the criteria they wanted
(i.e., they did not have to add criteria themselves), and stated, ‚Äúthis
auto-generation is sweet‚Äù. P3 found that some EvalGen-suggested
criteria did not make sense given that assertions only operate on
LLM pipeline input-output pairs, like response latency and response
stability over time. P3 did not feel that this was a failure of EvalGen,
but rather expressed that LLMs are not perfect and stressed the
importance of having control over selected criteria.
7.2.2 Grading outputs first helps refine initial criteria. Participants
who graded before selecting criteria (P4 and P9) expressed that
they found the grading process very useful. Both participants were
happy that EvalGen prompted them to give feedback on why an
LLM output was bad. While P9 selected the grading option initially
because it seemed like the ‚Äúoption that required the least thinking,‚Äù
they later realized that it was the correct thing to do:
Of the 3 options, [selecting criteria] probably wasn‚Äôt
the best to start with because I couldn‚Äôt have extracted
[all the] rules directly from the prompt. [While grading, I found] some rules that aren‚Äôt included in the
prompt.
Other participants who did not grade before selecting criteria
regretted this decision: for example, P2 said, ‚Äúyou should enforce
that we all look at at least 20 examples first.‚Äù We discuss criteria
refinement more in 7.3.1.
7.2.3 Users were happy to grade while waiting. Overall, all participants but one (P7) found grading while waiting for EvalGen to
finish generating and executing candidate assertions to be a good
use of their time. The participant who did not agree said that they
would find it useful if, on the grading screen, EvalGen showed
what it was doing with the grades. However, three participants
found it difficult to enumerate all criteria in their head and grade
against all criteria, wanting EvalGen to prompt them to grade per
each criteria (P6, P7, P8). Several participants realized they needed
to go back and change their grades in EvalGen and were happy
they could do this.
7.2.4 Users need more control when reviewing alignment on graded
results. In the Report Card screen, participants liked that EvalGen
generated multiple assertion implementations for each criterion
and picked the most aligned one (i.e., highest coverage within a false
failure rate threshold of 20%). However, for some criteria, EvalGen
Who Validates the Validators? Aligning LLM-Assisted Evaluation of LLM Outputs with Human Preferences
Figure 3: The Table View, showing inputs, LLM outputs, and
evaluation results per criteria for the NER task (Sec. 6).
generated no good assertions, and participants deleted the criteria
without complaints. P8 said, ‚ÄúI like that it tries, because maybe there
will be a good implementation!‚Äù This suggests that, compared to
an opaque approaches we discussed in Related Work, seeing alignment scores helped participants cull assertions that were unaligned
rather than blindly trusting them. For criteria where EvalGen did
not find any good assertion implementations, participants also expressed interest in writing assertions. Some participants said that
they had not graded enough responses to get their ideal alignment
numbers, so they wanted to go back and grade more (P1, P7). Participants also liked seeing the coverage and false failure rate of the
set, and how each assertion contributed to these overall statistics.
However, in this screen, some participants expressed interest in
seeing per-criterion alignment and asked to provide grades for each
criterion (P5, P6, P7, P8). Another place where participants wanted
to exercise control but were limited by EvalGen‚Äôs interface was
in the selected assertions: P2 and P5 wanted to change a selected
assertion to another candidate assertion. Both P2 and P5 wanted to
change code-based assertions: for example, P5 said, ‚Äúthis is a weird
implementation of entity count‚Äù and preferred another assertion
with a small modification.4
7.2.5 Users differ in how they assess alignment for ungraded results.
Participants really liked viewing the table of assertion results on
all LLM outputs, with all participants expressing interest upon first
viewing it (Figure 3)‚Äîbut they verified the results differently. In this
table, rows represent LLM outputs, and columns represent assertions. P2 said that this table ‚Äúearns trust‚Äù; P5 said that it was ‚Äúcool
to see all the results on examples [they] didn‚Äôt grade.‚Äù P5 initially
did not like using a GUI to come up with assertions, and then said
that they ‚Äúprefer looking at this table to [their] current workflow
in Jupyter notebooks.‚Äù Interestingly, only one participant assessed
alignment in this table via coverage‚Äîby inspecting each row in
4Note that assertions can be edited in the MultiEval node after returning to the main
window, but not in EvalGen‚Äôs report card screen.
P1 P2 P3 P4 P5 P6 P7 P8 P9
6 5 3 4 5 3 1 2 5
Table 2: Ratings (1-7, 7 best) for the statement, ‚ÄúI felt like the
assertions aligned with my grades.‚Äù Responses were mixed.
the table, one at a time‚Äîand everyone else assessed alignment via
false failure rate: for each column (assertion), they typically looked
for rows (LLM outputs) that the assertion returned False. Some
participants wanted this table to automatically recompute, with an
accompanying visualization, whenever there were changes to the
LLM pipeline; for example, P6 said:
One thing I would find cool is if there is a way to
easily see how changes to my prompt impact the
overall [coverage and false failure rate] scores. Just
very quickly being able to visualize how [my prompt
edit] changes the classifications on a bunch of [LLM
outputs.]
This suggests users want data visualization plots between the
original prompt and its revision, akin to LLM Comparator and
EvalLM [24, 27]. Note that ChainForge [1] also has visualization
plots, but we did not introduce participants to this feature.
7.3 Alignment is Iterative, Criteria- and
Implementation-specific
Perceptions of the tools‚Äô support of alignment were polarized across
participants, as shown in Table 2. The main reason why people
had low confidence in the assertion report card‚Äôs alignment with
their grades was because they were still uncertain of their own
criteria while grading. Participants would say utterances with a
questioning tone, like ‚ÄúI guess‚Äù and ‚Äúsure,‚Äù when grading, indicating their uncertainty (P2, P5, P7, P8, P9). Looking more closely at
their interactions, we observed a catch-22 situation: participants
needed to externalize criteria in order to grade outputs, but they
also needed to grade outputs‚Äîproviding feedback on why bad outputs were bad‚Äîin order to externalize criteria. Here, we explore
their challenges.
7.3.1 Criteria drift. Grading outputs spurred changes or refinements in participants‚Äô criteria, which we refer to as criteria drift.
We observed two types of drift.
First, participants wanted to add new criteria when they observed
new ‚Äútypes‚Äù of bad LLM outputs (P2, P5, P6, P8, P9). In the EvalGen
interface, they could not go back and add new criteria; they had to
wait for all candidate assertions to finish executing, move past the
report card screen, and start a new EvalGen process.
Second, as participants graded more outputs, we found that they
reinterpret existing criteria to better fit the LLM‚Äôs behavior (P2, P5,
P6, P8, P9). For example, P2 and P8 had a ‚Äúproper noun‚Äù criterion,
which was supposed to assess that ‚Äúthe entities extracted were
proper nouns.‚Äù At first, they rated as bad any LLM outputs that contained any entity that was not a proper noun. But, after observing
that responses had varying numbers of proper nouns, both wanted
to change their criteria such that most of the entities were proper
nouns, rather than all. P9 appreciated the ability to provide feedback on unsatisfactory outputs before finalizing the initial criteria
set, as this process helped them articulate their criteria. Twice, P8
Shreya Shankar, J.D. Zamfirescu-Pereira, Bj√∂rn Hartmann, Aditya G. Parameswaran, and Ian Arawjo
mentioned that they gave a bad grade not because they believed
the output was bad, but because they wanted to be consistent with
previous grades‚Äîgood labeling practice, perhaps, but not good for
alignment. P7 noticed that in some outputs included hashtags from
the original tweet inputs (e.g., #justdoit), while in other cases, the
outputs did not use the hashtag symbol but still mentioned the entities referred to by the hashtags (e.g., ‚ÄúNike‚Äù instead of #Nike). This
inconsistency led P7 to rethink the criteria definition for including
hashtags; specifically, whether it was acceptable for the LLM to
replicate entities from hashtags, provided the hashtag was removed.
P5 expressed the same uncertainty. ‚ÄúI think it‚Äôs hard to know until
you see it,‚Äù P7 said.
7.3.2 Users prefer to adjust their grading approach based on the
difficulty of evaluating a criterion. Overall, participants generally
liked the process of grading LLM responses and feeling like the
grades were useful, but they wanted to prioritize grading criteria
they felt needed their alignment‚Äîespecially for LLM-based assertions (P3, P5, P7, P8). For example, P3 expressed that they would
trust the assertions more if the EvalGen process allowed them to
set different false failure rates per criteria (since LLMs might be
bad at evaluating some criteria), instead of one global false failure
rate constraint for the entire assertion set:
There are criteria where you can be okay with failing,
and then there are other criteria where you are like,
‚Äòthis must absolutely pass‚Äô... [T]here‚Äôs a [spectrum] of
failure as opposed to: it just passes or fails.
Relatedly, some participants expressed that they didn‚Äôt trust their
grades because they themselves couldn‚Äôt evaluate some criteria as
well as an automated solution (P2, P5, P6, P7, P8; we discuss further
in Section 7.4). A criterion like word count is hard for humans to
assess but easy for a good Python function to evaluate. P8 desired
to grade for only one criteria, reasoning that it might improve
efficiency (‚ÄúI generally want to be in the loop for these tests...but I
want to put myself in the loop in a way that is efficient.‚Äù).
7.3.3 What constitutes ‚Äúalignment‚Äù is subjective, especially when
converting natural language criteria to code-based assertions. For
code-based assertions, EvalGen‚Äôs interpretation of the criterion
(i.e., GPT-4‚Äôs interpretation) did not match what the participants
expected. As such, no matter how many grades the participant gave,
all candidate assertions were similarly misaligned. Participants
who observed this were confused why their grades seemingly had
little impact on some of the chosen assertions (P3, P5, P7, P9). For
example, while all participants had a criterion to enforce that there
were no entities with hashtags in the output, some participants
interpreted this as any hashtags representing entities should not be
extracted as entities: e.g., if the output included the hashtag #Nike,
P5 did not want Nike to be extracted at all. On the other hand, P9
wanted Nike to be extracted as an entity, but they did not want the
LLM output to include the hashtag. Both P5 and P9 got the same
code-based assertion for the criterion, which simply checked for
the presence of the hashtag character in the output‚Äîthis assertion
did not align with P5‚Äôs grades, but did with P9‚Äôs. This particular
misalignment can also be viewed as an instance of criteria drift,
as described in Section 7.3.1, since P5 was only able to refine the
criterion after grading several LLM outputs. For another criterion,
P5 felt that EvalGen could not find a good assertion that aligned
with their grades, but also said that they were ‚Äúlost at what would
be a good implementation.‚Äù
Overall, alignment is not merely a matter of performance (i.e.,
the idea that ‚Äúa better LLM would do better‚Äù): we observed that misalignment sometimes occurred due to tacit criteria that participants
held which was not explicitly explained in natural language. Like
prior work has found for cross-LLM comparison [1], this tacit understanding of criteria could be highly subjective and contradictory
across participants.
7.4 Alignment Needs and Preferences Differ for
Code vs. LLM Evaluators
All participants liked EvalGen‚Äôs ability to assist in generating
both code-based and LLM-based assertions, expressing the need for
both types of assertions. Both P4 and P6 mentioned that they liked
the ability to correct EvalGen‚Äôs suggested type. Yet participants
reasoned about code-based assertions and LLM-based assertions
differently: while they liked having assertions of both types, they
wanted to construct and iterate on them differently in order to feel
like the resulting set of assertions aligned with their preferences.
7.4.1 Users like having control over the evaluation type and thought
each evaluation type had a different affordance. Participants seemed
to have a clear idea of when a criterion should be evaluated by code,
and when it should be evaluated by an LLM. Generally, for formatting checks (e.g., asserting that an output is in Markdown), countbased checks, and checks to include or exclude specific phrases,
participants preferred code-based assertions. P6 and P8 expressed
that they wanted to use LLM-based assertions for their own LLM
pipelines because ‚Äúmost of their criteria was fuzzy.‚Äù P2 selected criteria to be evaluated via LLM whenever they could not immediately
think of a Python function that could implement that criteria. We
also observed a participant (P8) preferring LLM-based to code-based
assertions: LLMs are relatively forgiving when encountering outputs with an unexpected quality or format, whereas code assertions
check exact constraints.
7.4.2 Users can‚Äîand want to‚Äîdirectly verify code-based implementations. Regardless of the type of assertion (code or LLM), EvalGen
follows the same process of exploring multiple candidate assertions
per criterion and, for each criterion, selecting the assertion that
aligns most with the user‚Äôs grades. While participants generally
liked this approach for LLM-based assertions, they did not like this
for code-based assertions. This observation may be specific to users
who are experts in coding (as all of our participants are). Some
participants wanted to see the code for each candidate assertion
and select the best Python function for each criterion themselves
(P2, P5, P7). P5 said:
When something can be solved using Python code,
I do have an envisioned [implementation] in mind
that I can easily verify. Just showing [me] the [code]
will be quicker.
P7 wanted to iterate on code-based assertions simply by providing feedback to make the assertion more or less ‚Äúfancy‚Äù‚Äîfor
example, in checking for a pattern in the LLM output, they might
Who Validates the Validators? Aligning LLM-Assisted Evaluation of LLM Outputs with Human Preferences
want the regex to be more or less complicated depending on the sample of LLM outputs they‚Äôve seen. However, P7 then acknowledged
that their ability to edit depends on code length and complexity:
For something that‚Äôs like 10 lines of code or less, I‚Äôll
look at [the code]. But for [longer functions,] I probably want to eyeball [the function results]. This is
where it gets a bit unclear.
While participants had lots of ideas for improvement, participants overall felt that EvalGen provided a good start to code-based
assertions, and it was easy for them to edit the code if they wanted:
two participants even asked for the ability to export code-based
assertions as unit tests or in a Python file (P4, P6).
7.4.3 Users want their grades to aid automated criteria generation.
While participants liked that EvalGen tried multiple candidate assertions for each criterion, they wanted EvalGen to use their grades,
as well as natural language feedback on thumbs-down grades, in
prompting LLMs for candidate assertions (P3, P4, P5, P7). For example, any time a user gives a grade, EvalGen could query an LLM for
a new candidate assertion, including the new grade in the prompt
so that the candidate assertion may be more aligned with the user‚Äôs
grades. This strategy can, of course, be used to generate new codebased assertions too. Not only did participants want grades to be
included in the process of generating new candidate assertions,
but some wanted their labeled LLM outputs to be included in the
LLM-based assertions‚Äô prompts themselves (P3, P5). P3 excitedly
realized this when looking at the table of results (‚ÄúI can take these
good and bad examples and use them as few-shot exemplars in the
prompt for the LLM evaluators...‚Äù). This suggests an optimization
loop akin to ConstitutionMaker and DSPy [26, 39], but for assertion
generation and validation, rather than prompt optimization.
7.4.4 LLM-based assertions are harder to trust. While participants
found EvalGen‚Äôs suggested code-based assertions to be more obviously misaligned than the LLM-based assertions (Section 7.3.3),
they also acknowledged that LLM-based assertions are harder for
them to trust‚Äîsince they can edit the code-based assertions more
easily than the LLM-based assertions (P2, P5, P6, P8, P9). Some
participants were skeptical of how LLM-based assertions might
transfer to monitoring LLM outputs in a production pipeline (P3,
P6, P8). P8 said, ‚ÄúI cannot begin to think about how LLMs as validators [in production] can work, I‚Äôm very skeptical.‚Äù P9 asked, ‚ÄúHow
do I maintain my evals over time; do I have to rerun this entire
process?‚Äù One suggestion is an interface that solicits grades from
other people‚Äîpossibly the end-users of the user‚Äôs LLM pipeline‚Äîto
continually realign LLM-based assertions.
8 DISCUSSION
Here, we unpack criteria drift and how it affects alignment, discuss
the implications of our findings for future LLMOps evaluation
assistants, and outline some open questions.
8.1 Implications of Criteria Drift for LLM
Evaluation Assistants
The practice of benchmarks in ML and NLP presume a world of
well-defined criteria (and well-labeled data) on which to judge
LLM outputs. For instance, AutoCalibrate is a method to calibrate LLM evaluators with human preferences that requires large
expert-labelled datasets with settled (i.e., established upfront) criteria [34]. However, in practice, we found that developers rapidly
iterate over criteria, and furthermore that cognitively engaging
with LLM outputs helps them to refine their criteria. This suggests
criteria refinement and grading should happen in tandem in interactive settings, and poses challenges to alignment methods that
presume settled, expert labels. In particular, the dependence of criteria on a specific prompt and LLM‚Äôs outputs means that any change
to the LLM pipeline can cause criteria drift: for example, LLM APIs
can be replaced with new models, resulting in prompt drift [4].
Future system designs should support these requirements. For
instance, an evaluator assistant might adjust criteria dynamically
as the user grades and gives feedback. We might also consider percriteria grading (while keeping the simplicity of thumbs up/down
voting). Eliciting grades at the criteria level might allow evaluation
assistants to more precisely adjust both the criteria for evaluation,
as well as the way these criteria are implemented. Finally, including
examples of both good and bad LLM outputs within the LLM-based
evaluator prompts could also be beneficial (a method akin to recent
work [26, 35]). However, whenever outputs change, we may need
to ask users to re-grade or re-think their criteria.
Our criteria drift finding echoes prior work in educational settings, where instructors often update their grading rubrics to reflect
common errors as they grade more assignments [47]. Similar to
how teachers adjust rubrics and regrade as they see more student
submissions, making users reassess LLM outputs after updating criteria could enhance the accuracy and consistency of grades. Given
the observed inconsistency in participants‚Äô grading, evaluation assistants might also pursue crowdsourcing methods like majority
voting and self or external assessments to determine accurate grades
for LLM outputs [7, 9]. Another challenge for evaluation assistants
is extending adapted criteria to grade both ungraded and future
unseen LLM outputs. How do evaluation assistants consistently
sample grades for outputs that reflect the overall distribution of
LLM pipeline successes and failures?
The reader might wonder when criteria ‚Äúsettle.‚Äù Perhaps there
was simply not enough time in our study, and had participants
graded for an hour or two, they might have solidified their criteria,
and criteria drift goes away. There is reason to believe that this
situation does not change with more time‚Äîas we saw, the criteria
participants refined changed to adapt to the behavior of the LLM
outputs being evaluated‚Äîa dependent, rather than independent assessment of quality. In the real world, similar situations exist where
criteria are never ‚Äúfully settled‚Äù as more inputs come in‚Äîconsider
the court of law. One of our participants remarked that people
‚Äúknow a bad output when they see it.‚Äù Their adage reflects a U.S.
Supreme Court Justice‚Äôs famous opinion in a 1964 court case about
obscene content [17]. As in that remark, the decisions of human
validators seem at first glance ‚Äúto be based on a non-rational, intuitive gut reaction, instead of reasoned analysis; it seems to be
utterly subjective and personal‚Äù [17, p.1025]. However, perhaps, as
the law scholar Gewirtz argues, subjectivity is not necessarily a
sign of irrationality (contrasting with some imagined future AI that
is entirely objective and rational, entirely ‚Äúaligned‚Äù or ‚Äúbetter‚Äù than
humans). On the contrary: ‚ÄúThere are good reasons to accept the
Shreya Shankar, J.D. Zamfirescu-Pereira, Bj√∂rn Hartmann, Aditya G. Parameswaran, and Ian Arawjo
imperfect in a judge. We should encourage judges to believe and
say: This is the best I can do now; it doesn‚Äôt solve all the problems,
but it‚Äôs a start, and I‚Äôll keep thinking‚Äù [17, p.1027]. This raises a
deeper epistemic question for evaluation assistants‚Äîis ‚Äúalignment‚Äù
an actualizable goal? To what extent does our common terminology
and assumptions‚Äîe.g., that there is a ‚Äúground truth‚Äù set of labels
we merely need to elicit‚Äîfail us? Is validating the validators only
ever a work-in-progress?
8.2 Operationalizing Assertions
Participants expressed the desire to deploy their assertions in production. Some wanted to deploy assertions in the critical path of
the LLM pipeline, to catch bad outputs before they are shown to
end-users. Others wanted a more passive deployment‚Äîone participant requested for some form of report sent to their email inbox
daily, containing results of the assertion set executed on a sample
of LLM outputs from that day. In practice, assertions have different
operational requirements. For example, if an assertion runs in the
critical path, it should not result in many false failures, otherwise
the LLM may get unnecessarily reprompted (i.e., rerun) and the
overall latency might increase for our LLM pipeline. Moreover, as
criteria changes over time, evaluation assistants should ask users to
grade new LLM outputs observed in production and automatically
adapt assertion sets.
Our study confirmed the dual necessity for both code-based
and LLM-based assertions among participants, but further showed
that participants felt each type required distinct treatment, both
in implementation selection and in how they perceive alignment.
Often useful for sanity checks like output structure, code-based
assertions can be used in the critical path of the LLM pipeline.
In fact, a number of LLMOps tools exist for users to implement
such code-based guardrails [19, 22, 42]. However, our participants
highlighted the challenge of finding the right implementation for
a given assertion‚Äîa decision that can depend intricately on the
characteristics of LLM outputs. For example, determining the acceptable length of a response might vary significantly based on
the observed output distribution. In fact, specifically for an output
length criterion, P3 mentioned that they would look at a histogram
of word lengths for a batch of outputs and see if there were some
buckets of anomalous word lengths that exhibited other failure
modes (e.g., a ‚Äúrambling‚Äù response from the LLM).
Some participants mentioned that they wanted their collaborators, such as product managers, to grade outputs in EvalGen.
Importantly, when allowing multiple users to collaborate on grading, evaluation assistants have to consider inter-rater reliability and
handle disagreements, if any. Again, we can draw inspiration from
techniques from the crowdsourcing literature: for example, evaluation assistants could model each individual grader‚Äôs accuracy and
apply corrections if necessary [59]. Moreover, collaborators may
have different experience levels with coding: those with less experience may choose LLM-based assertions for criteria that might be
better evaluated with code. While EvalGen provides initial suggestions for whether criteria should be evaluated with code or another
LLM, evaluation assistants may want to make sure that all users
from the same team ‚Äúagree‚Äù on the right implementations. One
could imagine interfaces similar to creating a ‚Äúpull request‚Äù for a
new assertion and soliciting review from a team member, and a
workflow similar to continuous integration/continuous deployment
(CI/CD) that seamlessly pushes new assertions to production.
8.3 Future Work and Limitations
Assertions serve as a straightforward mechanism for evaluating
LLM outputs, yet the potential of evaluation assistants extends
beyond EvalGen‚Äôs supported binary judgments. Consider the example of word count: rather than setting rigid thresholds, one might
find it more useful to monitor variations in word count across different LLM outputs. Like in traditional ML monitoring [44], there
is, of course, still imprecision in what word count counts as ‚Äúbad,‚Äù
given its distribution. Does the AI assistant‚Äôs definition of bad align
with the user‚Äôs? Tracking finer-grained information in evaluations,
beyond simple true/false conditions, can aid in debugging issues
within LLM pipelines, once a user knows the output is bad. Second, many users write their LLM pipelines as chains of multiple
LLM calls [1, 11, 14, 53]. Evaluation assistants can facilitate end-toend alignment, which can be complicated not only with chains of
LLM calls, but also in compound AI systems that leverage other
components like retrieval-augmented generation [55].
Increasingly, user want their prompts to automatically improve
based on assertion results. For instance, if an assertion fails for a
group of LLM outputs, one might want to add an instruction to the
prompt to solve this failure mode. Some frameworks already experiment with using feedback from assertions or user grades to refine
prompts [35, 39, 48]. However, incorporating this into an evaluation
assistant is not as straightforward: there may be a cyclical process
where evaluation assistants not only help in adjusting assertions
based on prompt performance but also use these insights to suggest
further prompt modifications. This iterative cycle of evaluation
and adjustment could foster a co-evolutionary environment where
prompts, assertions, and even evaluative mechanisms themselves
are continuously refined in a unified interface.
Finally, there are two limitations of our study that are worth
pointing out. First, our off-line evaluation only focused on two
pipelines. Different applications may warrant different methods of
sampling grades and aligning assertions. Second, our qualitative
study focused on a small sample of developers, all of whom have
significant experience deploying LLMs. Moreover, participants did
not have enough time to iterate many times in EvalGen, and our
setup did not cover the deployment phase of LLM workflows. Future
work might explore best practices and pitfalls of evaluations in the
broader LLMOps lifecycle.
9 CONCLUSION
This work presented EvalGen, a mixed-initative approach to aligning LLM-generated evaluation functions with human preferences.
EvalGen assists users in developing both criteria acceptable LLM
outputs and developing functions to check these standards, ensuring evaluations reflect the users‚Äô own grading standards. In a
qualitative study with 9 expert users, we observed a pattern we call
criteria drift, where users refine their evaluation standards as they
grade more LLM outputs. Recognizing the dependency of criteria
on LLM outputs highlights new directions for designing future
evaluation assistants.
Who Validates the Validators? Aligning LLM-Assisted Evaluation of LLM Outputs with Human Preferences
REFERENCES
[1] Ian Arawjo, Chelse Swoopes, Priyan Vaithilingam, Martin Wattenberg, and Elena
Glassman. 2023. ChainForge: A Visual Toolkit for Prompt Engineering and LLM
Hypothesis Testing. arXiv preprint arXiv:2309.09128 (2023).
[2] Pierre Boyeau, Anastasios N Angelopoulos, Nir Yosef, Jitendra Malik, and
Michael I Jordan. 2024. AutoEval Done Right: Using Synthetic Data for Model
Evaluation. arXiv preprint arXiv:2403.07008 (2024).
[3] Zana Bu√ßinca, Maja Barbara Malaya, and Krzysztof Z Gajos. 2021. To trust or to
think: cognitive forcing functions can reduce overreliance on AI in AI-assisted
decision-making. Proceedings of the ACM on Human-Computer Interaction 5,
CSCW1 (2021), 1‚Äì21.
[4] Lingjiao Chen, Matei Zaharia, and James Zou. 2023. How is ChatGPT‚Äôs behavior
changing over time? arXiv preprint arXiv:2307.09009 (2023).
[5] Raunak Chowdhuri, Neil Deshmukh, and David Koplow. 2023. No, GPT4
can‚Äôt ace MIT. https://flower-nutria-41d.notion.site/No-GPT4-can-t-ace-MITb27e6796ab5a48368127a98216c76864
[6] Paul F Christiano, Jan Leike, Tom Brown, Miljan Martic, Shane Legg, and Dario
Amodei. 2017. Deep reinforcement learning from human preferences. Advances
in neural information processing systems 30 (2017).
[7] Aida Mostafazadeh Davani, Mark D√≠az, and Vinodkumar Prabhakaran. 2022.
Dealing with disagreements: Looking beyond the majority vote in subjective
annotations. Transactions of the Association for Computational Linguistics 10
(2022), 92‚Äì110.
[8] Michael Desmond, Michelle Brachman, Evelyn Duesterwald, Casey Dugan,
Narendra Nath Joshi, Qian Pan, and Carolina Spina. 2022. AI Assisted Data
Labeling with Interactive Auto Label. In Proceedings of the AAAI Conference on
Artificial Intelligence, Vol. 36. 13161‚Äì13163.
[9] Steven Dow, Anand Kulkarni, Scott Klemmer, and Bj√∂rn Hartmann. 2012. Shepherding the crowd yields better work. In Proceedings of the ACM 2012 conference
on computer supported cooperative work. 1013‚Äì1022.
[10] John J Dudley and Per Ola Kristensson. 2018. A review of user interface design
for interactive machine learning. ACM Transactions on Interactive Intelligent
Systems (TiiS) 8, 2 (2018), 1‚Äì37.
[11] Harrison Chase et al. 2023. LangChain. https://pypi.org/project/langchain/.
[12] Chrisantha Fernando, Dylan Banarse, Henryk Michalewski, Simon Osindero,
and Tim Rockt√§schel. 2023. Promptbreeder: Self-referential self-improvement
via prompt evolution. arXiv preprint arXiv:2309.16797 (2023).
[13] Uwe Flick. 2013. The SAGE handbook of qualitative data analysis. Sage.
[14] FlowiseAI, Inc. 2023. FlowiseAI Build LLMs Apps Easily. flowiseai.com.
[15] Michel Naim Gerguis, Cherif Salama, and M Watheq El-Kharashi. 2016. ASU:
An Experimental Study on Applying Deep Learning in Twitter Named Entity
Recognition.. In Proceedings of the 2nd Workshop on Noisy User-generated Text
(WNUT). 188‚Äì196.
[16] Katy Ilonka Gero, Chelse Swoopes, Ziwei Gu, Jonathan K Kummerfeld, and
Elena L Glassman. 2024. Supporting Sensemaking of Large Language Model
Outputs at Scale. arXiv preprint arXiv:2401.13726 (2024).
[17] Paul Gewirtz. 1996. On "I know it when I see it". The Yale Law Journal 105, 4
(1996), 1023.
[18] Andrew D. Gordon, Carina Negreanu, Jos√© Cambronero, Rasika Chakravarthy,
Ian Drosos, Hao Fang, Bhaskar Mitra, Hannah Richardson, Advait Sarkar,
Stephanie Simmons, Jack Williams, and Ben Zorn. 2023. Co-audit: tools to
help humans double-check AI-generated content. arXiv:2310.01297 [cs.HC]
[19] Guardrails 2023. Guardrails AI. https://github.com/guardrails-ai/guardrails.
[20] Qingyan Guo, Rui Wang, Junliang Guo, Bei Li, Kaitao Song, Xu Tan, Guoqing
Liu, Jiang Bian, and Yujiu Yang. 2023. Connecting large language models with
evolutionary algorithms yields powerful prompt optimizers. arXiv preprint
arXiv:2309.08532 (2023).
[21] Yupeng Hou, Jiacheng Li, Zhankui He, An Yan, Xiusi Chen, and Julian McAuley.
2024. Bridging Language and Items for Retrieval and Recommendation. arXiv
preprint arXiv:2403.03952 (2024).
[22] Instructor 2023. Instructor, Generating Structure from LLMs.
https://jxnl.github.io/instructor/.
[23] Ellen Jiang, Kristen Olson, Edwin Toh, Alejandra Molina, Aaron Donsbach,
Michael Terry, and Carrie J Cai. 2022. PromptMaker: Prompt-based Prototyping
with Large Language Models. In Extended Abstracts of the 2022 CHI Conference
on Human Factors in Computing Systems (New Orleans, LA, USA) (CHI EA ‚Äô22).
Association for Computing Machinery, New York, NY, USA, Article 35, 8 pages.
https://doi.org/10.1145/3491101.3503564
[24] Minsuk Kahng, Ian Tenney, Mahima Pushkarna, Michael Xieyang Liu, James
Wexler, Emily Reif, Krystal Kallarackal, Minsuk Chang, Michael Terry, and Lucas
Dixon. 2024. LLM Comparator: Visual Analytics for Side-by-Side Evaluation of
Large Language Models. arXiv:2402.10524 [cs.HC]
[25] Adam Tauman Kalai and Santosh S Vempala. 2023. Calibrated language models
must hallucinate. arXiv preprint arXiv:2311.14648 (2023).
[26] Omar Khattab, Arnav Singhvi, Paridhi Maheshwari, Zhiyuan Zhang, Keshav
Santhanam, Sri Vardhamanan, Saiful Haq, Ashutosh Sharma, Thomas T Joshi,
Hanna Moazam, et al. 2023. Dspy: Compiling declarative language model calls
into self-improving pipelines. arXiv preprint arXiv:2310.03714 (2023).
[27] Tae Soo Kim, Yoonjoo Lee, Jamin Shin, Young-Ho Kim, and Juho Kim. 2023.
Evallm: Interactive evaluation of large language model prompts on user-defined
criteria. arXiv preprint arXiv:2309.13633 (2023).
[28] Agnes M Kloft, Robin Welsch, Thomas Kosch, and Steeven Villa. 2023. " AI enhances our performance, I have no doubt this one will do the same": The Placebo
effect is robust to negative descriptions of AI. arXiv preprint arXiv:2309.16606
(2023).
[29] Rafal Kocielnik, Saleema Amershi, and Paul N. Bennett. 2019. Will You Accept
an Imperfect AI? Exploring Designs for Adjusting End-user Expectations of
AI Systems. In Proceedings of the 2019 CHI Conference on Human Factors in
Computing Systems (Glasgow, Scotland Uk) (CHI ‚Äô19). Association for Computing
Machinery, New York, NY, USA, 1‚Äì14. https://doi.org/10.1145/3290605.3300641
[30] Zongjie Li, Chaozheng Wang, Pingchuan Ma, Daoyuan Wu, Shuai Wang, Cuiyun
Gao, and Yang Liu. 2023. Split and merge: Aligning position biases in large
language model based evaluators. arXiv preprint arXiv:2310.01432 (2023).
[31] Q. Vera Liao and S. Shyam Sundar. 2022. Designing for Responsible Trust in
AI Systems: A Communication Perspective. In Proceedings of the 2022 ACM
Conference on Fairness, Accountability, and Transparency (Seoul, Republic of
Korea) (FAccT ‚Äô22). Association for Computing Machinery, New York, NY, USA,
1257‚Äì1268. https://doi.org/10.1145/3531146.3533182
[32] Q Vera Liao and Jennifer Wortman Vaughan. 2023. AI transparency in the age
of LLMs: A human-centered research roadmap. arXiv preprint arXiv:2306.01941
(2023).
[33] Xiaohua Liu, Furu Wei, Shaodian Zhang, and Ming Zhou. 2013. Named entity
recognition for tweets. ACM Transactions on Intelligent Systems and Technology
(TIST) 4, 1 (2013), 1‚Äì15.
[34] Yuxuan Liu, Tianchi Yang, Shaohan Huang, Zihan Zhang, Haizhen Huang, Furu
Wei, Weiwei Deng, Feng Sun, and Qi Zhang. 2023. Calibrating LLM-based
evaluator. arXiv preprint arXiv:2309.13308 (2023).
[35] Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah
Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, et al.
2024. Self-refine: Iterative refinement with self-feedback. Advances in Neural
Information Processing Systems 36 (2024).
[36] Aditi Mishra, Utkarsh Soni, Anjana Arunkumar, Jinbin Huang, Bum Chul Kwon,
and Chris Bryan. 2023. PromptAid: Prompt Exploration, Perturbation, Testing
and Iteration using Visual Analytics for Large Language Models. arXiv preprint
arXiv:2304.01964 (2023).
[37] Chris Parnin, Gustavo Soares, Rahul Pandita, Sumit Gulwani, Jessica Rich, and
Austin Z Henley. 2023. Building Your Own Product Copilot: Challenges, Opportunities, and Needs. arXiv preprint arXiv:2312.14231 (2023).
[38] Kayur Patel, Naomi Bancroft, Steven M. Drucker, James Fogarty, Amy J. Ko,
and James Landay. 2010. Gestalt: integrated support for implementation and
analysis in machine learning. In Proceedings of the 23nd Annual ACM Symposium
on User Interface Software and Technology (New York, New York, USA) (UIST
‚Äô10). Association for Computing Machinery, New York, NY, USA, 37‚Äì46. https:
//doi.org/10.1145/1866029.1866038
[39] Savvas Petridis, Ben Wedin, James Wexler, Aaron Donsbach, Mahima Pushkarna,
Nitesh Goyal, Carrie J. Cai, and Michael Terry. 2023. ConstitutionMaker: Interactively Critiquing Large Language Models by Converting Feedback into Principles.
arXiv:2310.15428 [cs.HC]
[40] PromptsRoyale. 2023. PromptsRoyale. https://www.promptsroyale.com.
[41] Charvi Rastogi, Marco Tulio Ribeiro, Nicholas King, and Saleema Amershi. 2023.
Supporting Human-AI Collaboration in Auditing LLMs with LLMs. arXiv preprint
arXiv:2304.09991 (2023).
[42] Traian Rebedea, Razvan Dinu, Makesh Sreedhar, Christopher Parisien, and
Jonathan Cohen. 2023. Nemo guardrails: A toolkit for controllable and safe llm
applications with programmable rails. arXiv preprint arXiv:2310.10501 (2023).
[43] Melanie Sclar, Yejin Choi, Yulia Tsvetkov, and Alane Suhr. 2023. Quantifying Language Models‚Äô Sensitivity to Spurious Features in Prompt Design or:
How I learned to start worrying about prompt formatting. arXiv preprint
arXiv:2310.11324 (2023).
[44] Shreya Shankar, Labib Fawaz, Karl Gyllstrom, and Aditya Parameswaran. 2023.
Automatic and Precise Data Validation for Machine Learning. In Proceedings of the
32nd ACM International Conference on Information and Knowledge Management.
2198‚Äì2207.
[45] Shreya Shankar, Haotian Li, Parth Asawa, Madelon Hulsebos, Yiming Lin, JD
Zamfirescu-Pereira, Harrison Chase, Will Fu-Hinthorn, Aditya G Parameswaran,
and Eugene Wu. 2024. SPADE: Synthesizing Assertions for Large Language
Model Pipelines. arXiv preprint arXiv:2401.03038 (2024).
[46] Patrice Simard, David Chickering, Aparna Lakshmiratan, Denis Charles, L√©on
Bottou, Carlos Garcia Jurado Suarez, David Grangier, Saleema Amershi, Johan
Verwey, and Jina Suh. 2014. Ice: enabling non-experts to build models interactively for large-scale lopsided problems. arXiv preprint arXiv:1409.4814 (2014).
[47] Arjun Singh, Sergey Karayev, Kevin Gutowski, and Pieter Abbeel. 2017. Gradescope: a fast, flexible, and fair system for scalable assessment of handwritten
work. In Proceedings of the fourth (2017) acm conference on learning@ scale. 81‚Äì88.
Shreya Shankar, J.D. Zamfirescu-Pereira, Bj√∂rn Hartmann, Aditya G. Parameswaran, and Ian Arawjo
[48] Arnav Singhvi, Manish Shetty, Shangyin Tan, Christopher Potts, Koushik
Sen, Matei Zaharia, and Omar Khattab. 2023. DSPy Assertions: Computational Constraints for Self-Refining Language Model Pipelines. arXiv preprint
arXiv:2312.13382 (2023).
[49] Chanchal Suman, Saichethan Miriyala Reddy, Sriparna Saha, and Pushpak Bhattacharyya. 2021. Why pay more? A simple and efficient named entity recognition
system for tweets. Expert Systems with Applications 167 (2021), 114101.
[50] Helena Vasconcelos, Matthew J√∂rke, Madeleine Grunde-McLaughlin, Tobias
Gerstenberg, Michael S Bernstein, and Ranjay Krishna. 2023. Explanations can
reduce overreliance on ai systems during decision-making. Proceedings of the
ACM on Human-Computer Interaction 7, CSCW1 (2023), 1‚Äì38.
[51] Peiyi Wang, Lei Li, Liang Chen, Zefan Cai, Dawei Zhu, Binghuai Lin, Yunbo Cao,
Qi Liu, Tianyu Liu, and Zhifang Sui. 2023. Large Language Models are not Fair
Evaluators. arXiv:2305.17926 [cs.CL]
[52] Ian Webster. 2023. promptfoo: Test your prompts. https://www.promptfoo.dev/.
[53] Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina,
Michael Terry, and Carrie J Cai. 2022. PromptChainer: Chaining Large Language
Model Prompts through Visual Programming. In Extended Abstracts of the 2022
CHI Conference on Human Factors in Computing Systems (New Orleans, LA, USA)
(CHI EA ‚Äô22). Association for Computing Machinery, New York, NY, USA, Article
359, 10 pages. https://doi.org/10.1145/3491101.3519729
[54] Wen-wai Yim, Yujuan Fu, Asma Ben Abacha, Neal Snider, Thomas Lin, and
Meliha Yetisgen. 2023. Aci-bench: a novel ambient clinical intelligence dataset
for benchmarking automatic visit note generation. Scientific Data 10, 1 (2023),
586.
[55] Matei Zaharia, Omar Khattab, Lingjiao Chen, Jared Quincy Davis, Heather Miller,
Chris Potts, James Zou, Michael Carbin, Jonathan Frankle, Naveen Rao, and
Ali Ghodsi. 2024. The Shift from Models to Compound AI Systems. https:
//bair.berkeley.edu/blog/2024/02/18/compound-ai-systems/.
[56] JD Zamfirescu-Pereira, Heather Wei, Amy Xiao, Kitty Gu, Grace Jung, Matthew G
Lee, Bjoern Hartmann, and Qian Yang. 2023. Herding AI cats: Lessons from designing a chatbot by prompting GPT-3. In Proceedings of the 2023 ACM Designing
Interactive Systems Conference. 2206‚Äì2220.
[57] J.D. Zamfirescu-Pereira, Richmond Y. Wong, Bjoern Hartmann, and Qian Yang.
2023. Why Johnny Can‚Äôt Prompt: How Non-AI Experts Try (and Fail) to Design
LLM Prompts. In Proceedings of the 2023 CHI Conference on Human Factors in
Computing Systems (Hamburg, Germany) (CHI ‚Äô23). Association for Computing
Machinery, New York, NY, USA, Article 437, 21 pages. https://doi.org/10.1145/
3544548.3581388
[58] Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu,
Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al. 2024. Judging
llm-as-a-judge with mt-bench and chatbot arena. Advances in Neural Information
Processing Systems 36 (2024).
[59] Honglei Zhuang, Aditya Parameswaran, Dan Roth, and Jiawei Han. 2015. Debiasing crowdsourced batches. In Proceedings of the 21th ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining. 1593‚Äì1602.
Who Validates the Validators? Aligning LLM-Assisted Evaluation of LLM Outputs with Human Preferences
A ALGORITHMS FOR SELECTING
ASSERTIONS & ELICITING GRADES
A.1 Assertion Selectivity and Impact on LLM
Output Quality Confidence
One way to establish confidence in whether an LLM output is
problematic is to assess the selectivity, or pass rate, of assertions
that fail it. Intuitively, assertions that frequently fail outputs (low
selectivity) provide limited insight into output quality. For example,
an assertion that trivially fails every output offers no discernment
and has a selectivity of 0.
EvalGen leverages selectivity estimates of assertions to assign
a confidence score to each LLM output, indicating the likelihood
it is of poor quality. The rationale is straightforward: an output is
more likely to be problematic if failed by assertions known for their
high selectivity. Concretely, for a set of assertions ùêπ where each
assertion ùëì ‚àà ùêπ returns 1 for a pass and 0 for a fail, we calculate the
confidence score for an LLM output ùëí as follows:
ùúé (ùëí) =
‚àëÔ∏Å
ùëì ‚ààùêπ
selectivity (ùëì ) √ó ùëì (ùëí)
The score ùúé is always non-negative. A score of 0 means no
assertions have failed the output, indicating a higher likelihood of
quality, while lower scores, resulting from failures by non-selective
assertions, point to uncertainty or potential issues with the output.
A.2 Sampling Grades
Given that users may not want to grade so many outputs in the
EvalGen interface, choosing which outputs for users to grade is
crucial for aligning the system‚Äôs evaluations with user expectations.
Randomly selecting outputs without considering their predicted
quality can lead to misalignment, especially if the selected samples
aren‚Äôt representative of the entire dataset. Prior work also underscores the importance of soliciting a representative graded sample
of LLM outputs [2, 45].
Given ùúé scores as previously defined, we consider a number of
strategies to sample outputs for grading:
‚Ä¢ Random: Sample outputs at random (uniformly)
‚Ä¢ Highest: Sample the outputs with the highest ùúé. This approach focuses on potentially problematic content.
‚Ä¢ Lowest: Sample the outputs with the lowest ùúé, prioritizing
outputs that don‚Äôt fail any assertions or fail low-selectivity
assertions.
‚Ä¢ Alternating: Alternate between high and low ùúé, aiming
for a diverse sample with both bad and good outputs.
In Section 5, we test these strategies against a random baseline
on two different LLM pipelines. We employ an alternating sampling
policy for the EvalGen user studies. We do not claim to have the
best sampling policy; we chose an alternating policy with the hope
that it would solicit a balanced sample of good and bad grades.
One may wonder why we do not list a policy that ranks the
outputs by score and samples the middle for grading. While this
might seem akin to seeking out uncertain cases‚Äîas is common
in active learning‚Äîour scores represent the likelihood of outputs
being poor. They do not differentiate between good and bad per se.
Therefore, outputs with low scores may still vary widely in quality,
reflecting our system‚Äôs uncertainty.
A.3 Choosing Aligned Assertions
Once the user stops grading and wants to see the alignment Report
Card, as depicted in Figure 2e, for each criterion, we select the
candidate assertion with the highest alignment score. We adopt
notation from Shankar et al. [45] in defining alignment. Formally,
let ùê∏ be a set of LLM pipeline input-output pairs and ùëì : ùê∏ ‚Üí {0, 1}
represent an assertion. Let ùë¶ be a binary vector, where ùë¶ùëñ ‚àà {0, 1}
represents whether the user thinks an LLM output ùëíùëñ
is bad. Suppose
ùêπ = {ùëì1, ùëì2, . . . , ùëìùëó } is a set of ùëó assertions. Concretely, the coverage
and false failure rate (FFR) of ùêπ is represented by the following
equations:
Coverage (ùêπ ) =
√ç
ùëñ
I [ùë¶ùëñ = 0 ‚àß (‚àÉùëì ‚àà ùêπ, ùëì (ùëíùëñ) = 0)]
√ç
ùëñ
I [ùë¶ùëñ = 0]
FFR (ùêπ ) =
√ç
ùëñ
I [ùë¶ùëñ = 1 ‚àß (‚àÉùëì ‚àà ùêπ, ùëì (ùëíùëñ) = 0)]
√ç
ùëñ
I [ùë¶ùëñ = 1]
In both definitions, I is the indicator function. Intuitively, coverage represents the set‚Äôs true negative rate, while false failure rate
represents the set‚Äôs false negative rate. An aligned set of assertions
would have a high coverage and low false failure rate. We define the
alignment of ùêπ as the harmonic mean of coverage and the inverse
of FFR:
Alignment (ùêπ ) = 2 √ó
Coverage (ùêπ ) √ó (1 ‚àí FFR (ùêπ ))
Coverage (ùêπ ) + (1 ‚àí FFR (ùêπ ))
Note that alignment is very similar to F1 score; however, we are
concerned with the precision and recall of failures (i.e., when ùëì = 0,
not when ùëì = 1), and we are concerned with a set (i.e., when any
assertion returns 0).
A.4 Evaluation of Sampling Policy
We described in Appendix A.2 four options we considered to sample
LLM outputs: random, highest, lowest, and alternating. Here, we
compare EvalGen‚Äôs sampling policy, alternating, to these other
three baselines. For this experiment, we sampled 16 outputs to
grade, but in practice the user can grade more or fewer. Using the
same LLM pipelines as described in Section 5.1, to assess sampling
variance, we conducted 10 trials for each of the four sampling
policies‚Äîwhere, for each trial, we kept the same set of candidate
assertion functions.
The findings, shown in Figure 4, reveal that the random sampling
policy exhibits a large variance in alignment. This inconsistency
could lead to user frustration, particularly if the effort spent in
grading outputs results in assertion sets with unpredictable relevance to their specified criteria. The alternative sampling strategies,
which weight the probability for an LLM output to be graded by
the selectivity (i.e., pass rate) of assertions that fail it, consistently
yielded higher alignment scores across the entire datasets than the
random policy. Notably, while the alternating policy didn‚Äôt consistently outperform, our results suggest that any non-random policy
implemented in EvalGen may achieve satisfactory outcomes.
Shreya Shankar, J.D. Zamfirescu-Pereira, Bj√∂rn Hartmann, Aditya G. Parameswaran, and Ian Arawjo
random highest lowest alternating
Sampling Policy
0.0
0.1
0.2
0.3
0.4
0.5
0.6
Alignment
Dataset
product medical
Figure 4: Alignments for assertion sets that result from different policies to sample grades from the user. Each policy
was tested across 10 trials, with each involving a sample of 16
LLM outputs. Randomly sampling LLM outputs for grading
introduces significant variance in alignment across the entire
dataset.
In this offline study, as shown in Figure 4, there‚Äôs no variation in
the outcomes of the non-random policies because they are deterministic. However, in real-world use, EvalGen updates its predictions
as it receives new information, so there could be some differences
in results over time. Initially, when users start grading outputs in
EvalGen, they might effectively be grading random outputs for
the first one or two outputs, as the ùúé scores update and stabilize.
B TASK PROMPTS
We prepared two prompts and corresponding datasets for tasks to
present users (5.1). Both pipelines were adapted from prior work [21,
54] and correspond to medical record processing and a product
description writing, respectively. The medical pipeline prompt is
as follows:
You are extracting insights from some medical records .
The records contain a medical note and a
dialogue between a doctor and a patient . You need
to extract values for the following : Chief
complaint , History of present illness , Physical
examination , Symptoms experienced by the patient ,
New medications prescribed or changed , including
dosages ( N / A if not provided ) , and Follow - up
instructions ( N / A if not provided ) . Your answer
should not include any personal identifiable
information ( PII ) such as name , age , gender , or
ID . Use " the patient " instead of their name , for
example . Return your answer as a bullet list ,
where each bullet is formatted like `chief
complaint : xx .` If there is no value for the key ,
the value should be `N /A`. Keep your response
around 150 words ( you may have to summarize some
extracted values to stay within the word limit ) .
{ transcript }
And the product pipeline prompt is as follows:
You are an expert copywriter . You need to write an e -
commerce product description based on the product
details and customer reviews . Your description
should be SEO - optimized . It should use an active
voice and include the product 's features ,
benefits , unique selling points without
overpromising , and a call to action for the buyer
. Benefits describe how product features will
work for the buyer , addressing exactly how the
product will improve their lives . Clearly
distinguish between features ( e . g . , lightweight ,
USB - chargeable ) and benefits ( e . g . , convenience ,
nutritious drinks on - the - go ) . Don 't mention
weaknesses of the product or use generic or
repetitive language . Don 't make up review text or
quotes . Don 't include any links . Don 't cite the
reviews too heavily . Divide your description into
readable chunks divided by relevant subheadings .
Keep your description around 200 words , no more
than 300 , in Markdown format .
{ document }
Received 03 April 2024

---
./notebooks/assets/fake-invoices/invoice1.txt
---
OTOVO, UNIPESSOAL, LDA. RUA VISCONDE DE SEABRA, 3 - 1o DTO 516920219 1700-421 LISBOA
OTOVO, UNIPESSOAL, LDA.
RUA VISCONDE DE SEABRA, 3 - 1o DTO 1700-421 LISBOA
LISBOA
LUCAS BARBOSA NICOLOSI SOARES 0022
AI SOFTWARE ENGINEER 12074046801
292804768
AGEAS 0010.10.315407
516920219 Original DOurpiglicnadlo
LISBOA
Recibo de Vencimentos
Recibo de Vencimentos Per√≠odo Dezembro
Data Fecho 31/12/2023 Vencimento 3.339,29
Per√≠odo Data Fecho Vencimento Venc. / Hora N. Dias M√™s:
Faltas Alim.
C√≥d.
R01 R06 R13 D01 D02 D05
Dezembro 31/12/2023
3.339,29 19,27 18.00
Nome
N.o Mecan. Categoria
N.o Benef.
N.o Contrib. Departamento Seguro
LUCAS BARBOSA NICOLOSI SOARES 0022
AI SOFTWARE ENGINEER 12074046801
292804768
AGEAS 0010.10.315407
Reten√ß√£o IRS
SDD IRS Retido Total Remun.
Venc. / Hora N. Dias M√™s:
19,27 18.00
Nome
N.o Mecan. Categoria
N.o Benef.
N.o Contrib. Departamento Seguro
Turno Data
12-2023 12-2023 12-2023 12-2023 12-2023 12-2023
CDD
SDH
Faltas
Alim. Turno CDH
Reten√ß√£o IRS
IRS Retido
CDH
Descri√ß√£o Remunera√ß√µes Descontos
SDH
SDD
Total Remun.
18.059,57
Descontos
432,14 1.146,00 144,00
CDD
Descri√ß√£o Remunera√ß√µes
Vencimento 3.339,29 IHT 589,29
4.825,00 18.059,57
4.825,00
Vencimento 3.339,29 IHT 589,29
C√≥d. Data
R01 12-2023 R06 12-2023 R13 12-2023 D01 12-2023 D02 12-2023 D05 12-2023
Subs√≠dio Alimenta√ß√£o Cart√£o Seguran√ßa Social
IRS (Venc. 29,18%) (29,18%) Desconto Subsidio Alim. Cart√£o
144,00
Subs√≠dio Alimenta√ß√£o Cart√£o Seguran√ßa Social
IRS (Venc. 29,18%) (29,18%) Desconto Subsidio Alim. Cart√£o
144,00
432,14 1.146,00 144,00
Formas de Pagamento: % Remunera√ß√£o
100,00
Forma de Pagamento Moeda
Formas de Pagamento: % Remunera√ß√£o
100,00
Forma de Pagamento
Transfer√™ncia
Moeda
Total
4.072,58 1.722,14 Total Pago ( EUR ) 2.350,44
Total
4.072,58 Total Pago ( EUR )
1.722,14 2.350,44
Declaro que recebi a quantia constante neste recibo,
Obs.
Declaro que recebi a quantia constante neste recibo,
Transfer√™ncia EUR
EUR

---
./notebooks/assets/fake-invoices/invoice2.txt
---

ACME CORPORATION
123 Business Street
San Francisco, CA 94105
Tax ID: 12-3456789

INVOICE

Bill To:                                    Invoice No: INV-2024-0042
John Smith                                  Date: April 15, 2024
456 Client Avenue                          Due Date: May 15, 2024
New York, NY 10001

Description                     Quantity    Rate        Amount
-----------------------------------------------------------------
Software Development Services      80       $150.00    $12,000.00
Cloud Infrastructure Setup         1      $2,500.00    $2,500.00
Technical Documentation           40        $75.00     $3,000.00
                                                    ------------
                                           Subtotal:  $17,500.00
                                           Tax (8%):   $1,400.00
                                           Total:     $18,900.00

Payment Terms: Net 30
Please make checks payable to: ACME Corporation
Wire Transfer Details:
Bank: First National Bank
Account: 987654321
Routing: 021000021

Thank you for your business!


---
./notebooks/assets/fake-invoices/invoice3.txt
---
TECH SOLUTIONS INC.
789 Innovation Drive
Seattle, WA 98101
Tax ID: 98-7654321

INVOICE

Bill To:                                    Invoice No: INV-2024-0103 
Sarah Johnson                               Date: April 18, 2024
789 Enterprise Road                         Due Date: May 18, 2024
Chicago, IL 60601

Description                     Quantity    Rate        Amount
-----------------------------------------------------------------
AI Model Development              120      $200.00    $24,000.00
Data Processing Services           80      $125.00    $10,000.00
System Integration                 40      $175.00     $7,000.00
Hardware Configuration             1     $3,500.00     $3,500.00
                                                    ------------
                                           Subtotal:  $44,500.00
                                           Tax (9.5%): $4,227.50
                                           Total:     $48,727.50

Payment Terms: Net 30
Please make checks payable to: Tech Solutions Inc.
Wire Transfer Details:
Bank: Pacific Northwest Bank
Account: 123456789
Routing: 325081403

Notes:
- All prices in USD
- Late payments subject to 1.5% monthly interest
- Please include invoice number in payment reference

Thank you for your business!


---
./notebooks/02-ai-apis/01-ai-apis-overview.ipynb
---
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acda0389",
   "metadata": {},
   "source": [
    "# Using AI APIs: A Comprehensive Guide\n",
    "\n",
    "In this lesson, we'll explore how to interact with various AI models using their respective APIs. We'll cover text generation, image creation, and audio transcription across different providers.\n",
    "\n",
    "## Setting Up Libraries\n",
    "\n",
    "First, let's install all required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1457bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries (uncomment to run)\n",
    "# %pip install openai anthropic ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d65e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"var: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "_set_env(\"ANTHROPIC_API_KEY\")\n",
    "_set_env(\"OLLAMA_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46ad4fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, Image, Audio\n",
    "import os\n",
    "import openai\n",
    "import anthropic\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad18e9a8",
   "metadata": {},
   "source": [
    "## Helper Functions for Display\n",
    "\n",
    "Let's create some helper functions to make our outputs look nice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb6113db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from demo_utils import display_chat_message, display_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f331bbf",
   "metadata": {},
   "source": [
    "## Text Generation with Different Providers\n",
    "\n",
    "Let's compare how different AI providers handle the same prompt: \"Explain quantum computing in simple terms.\"\n",
    "\n",
    "### OpenAI (GPT-4o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e0b8699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Quantum computing is a type of computing that uses the principles of quantum mechanics, the science that explains how the smallest particles in the universe behave. Here's a simple breakdown:\\n\\n1. **Bits vs. Qubits**: Traditional computers use bits, which are like tiny switches that can be turned on (1) or off (0). Quantum computers use qubits, which can be both 0 and 1 at the same time, thanks to a property called superposition.\\n\\n2. **Superposition**: Imagine spinning coins that are both heads and tails until you look at them. In a similar way, qubits can hold multiple possibilities at once, allowing quantum computers to process a vast amount of data simultaneously.\\n\\n3. **Entanglement**: This is another quantum principle where qubits become linked, such that the state of one qubit can depend on the state of another, no matter the distance between them. This allows complex problem-solving capabilities and faster information exchange.\\n\\n4. **Interference**: Quantum computers use interference to amplify correct answers and cancel out wrong ones, similar to how noise-canceling headphones reduce unwanted sounds.\\n\\nTogether, these quantum properties make quantum computers incredibly powerful for certain tasks, like factoring large numbers, simulating molecules for drug development, or optimizing incredibly complex systems. However, they are still in development and not expected to replace traditional computers for everyday tasks yet.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ask_openai(prompt):\n",
    "    client = openai.OpenAI()\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Example usage\n",
    "openai_response = ask_openai(\"Explain quantum computing in simple terms\")\n",
    "openai_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ce0a4a",
   "metadata": {},
   "source": [
    "### Anthropic (Claude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc0c730d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Quantum computing can be explained through a few key concepts:\\n\\n1. Regular computers vs. Quantum computers:\\n- Regular computers use bits (0s and 1s)\\n- Quantum computers use quantum bits (qubits) that can be both 0 and 1 at the same time\\n\\n2. Think of it like this:\\n- Classical bit: A coin lying flat, either heads (0) or tails (1)\\n- Qubit: A spinning coin that's both heads and tails until it stops spinning\\n\\n3. Main advantages:\\n- Can process huge amounts of data simultaneously\\n- Can solve certain complex problems much faster than regular computers\\n- Perfect for tasks like encryption, drug discovery, and complex simulations\\n\\n4. Real-world example:\\nIf you needed to find a specific person in a phone book:\\n- Regular computer: Checks each name one by one\\n- Quantum computer: Can check many names simultaneously\\n\\nThe catch is that quantum computers are still experimental, very expensive, and challenging to build and maintain because qubits are extremely sensitive to their environment.\\n\\nThink of it as a super-powerful calculator that can process many possibilities at once, instead of one at a time like regular computers.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ask_claude(prompt):\n",
    "    client = anthropic.Anthropic()\n",
    "    message = client.messages.create(\n",
    "        model=\"claude-3-5-sonnet-20241022\",\n",
    "        max_tokens=1024,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return message.content[0].text\n",
    "\n",
    "# Example usage\n",
    "claude_response = ask_claude(\"Explain quantum computing in simple terms\")\n",
    "claude_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c1bc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _set_env(\"GOOGLE_API_KEY\")\n",
    "# Google (Gemini)\n",
    "# pip install google-generativeai \n",
    "# import google.generativeai as genai\n",
    "# def ask_gemini(prompt):\n",
    "#     genai.configure(api_key=\"YOUR_API_KEY\")\n",
    "#     model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "#     response = model.generate_content(prompt)\n",
    "#     return response.text\n",
    "\n",
    "# # Example usage\n",
    "# gemini_response = ask_gemini(\"Explain quantum computing in simple terms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31167c54",
   "metadata": {},
   "source": [
    "### Ollama (Local Models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d678cdfe",
   "metadata": {},
   "source": [
    "1. To use local models we'll need to download ollama from https://ollama.com/\n",
    "2. Then we'll need to open up a terminal (or powershell for Windows users) and type in: `ollama run llama3.2`\n",
    "3. Now, we can run the code below without any hassle!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a9e7fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Quantum computing is a new way of processing information that\\'s different from classical computers. Here\\'s a simplified explanation:\\n\\n**Classical Computers**\\n\\nImagine you have a filing cabinet with labeled folders, each containing a piece of information (like a number or a word). When you want to process this information, you take the folder, look inside, and do something with what you found.\\n\\nIn classical computing, these \"folders\" are called bits. A bit is either 0 (empty) or 1 (filled). The computer checks the bit one by one, performs calculations, and then moves on to the next piece of information.\\n\\n**Quantum Computers**\\n\\nNow imagine a giant filing cabinet with many, many folders that can be in multiple states at once: both 0 AND 1 simultaneously! This is similar to what happens in quantum computing.\\n\\nIn a quantum computer, these \"folders\" are called qubits (quantum bits). Qubits exist in a state of superposition, meaning they can be multiple values all at once. When a qubit is measured, it \"collapses\" into one value or another.\\n\\n**How Quantum Computing Works**\\n\\nHere\\'s where things get really interesting:\\n\\n1. **Quantum gates**: These are special operations that manipulate the qubits to perform calculations.\\n2. **Superposition**: Qubits exist in multiple states at once, allowing them to process multiple possibilities simultaneously.\\n3. **Entanglement**: Qubits can become connected (entangled) with each other, enabling quantum computers to solve problems that would be impossible for classical computers.\\n\\n**Advantages of Quantum Computing**\\n\\n1. **Faster processing times**: Quantum computers can solve certain problems much faster than classical computers.\\n2. **Simulation capabilities**: Quantum computers can simulate complex systems, like molecules or materials, more accurately than classical computers.\\n3. **Cryptography and security**: Quantum computers can potentially break some encryption methods used today, but they can also create new, unbreakable codes.\\n\\n**Current State of Quantum Computing**\\n\\nQuantum computing is still a developing field, with many challenges to overcome before it becomes widely available. Companies like Google, IBM, and Microsoft are actively working on building more powerful quantum computers, and researchers are making progress in understanding the fundamental principles of quantum computing.\\n\\nIn summary, quantum computing uses qubits that can exist in multiple states simultaneously, allowing for faster processing times and new simulation capabilities. While there\\'s still much to be discovered, quantum computing has the potential to revolutionize many fields!'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ask_ollama(prompt):\n",
    "    response = ollama.chat(\n",
    "        model='llama3.2',\n",
    "        messages=[{'role': 'user', 'content': prompt}]\n",
    "    )\n",
    "    return response['message']['content']\n",
    "\n",
    "# Example usage\n",
    "ollama_response = ask_ollama(\"Explain quantum computing in simple terms\")\n",
    "ollama_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f56d6d",
   "metadata": {},
   "source": [
    "### Comparing Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f3e338c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='display: flex; flex-wrap: wrap; gap: 10px;'>\n",
       "        <div style='flex: 1; min-width: 300px; background-color: #f8f9fa; padding: 15px; border-radius: 8px;'>\n",
       "            <h3 style='color: #2c3e50;'>OpenAI GPT-4o</h3>\n",
       "            <p style='color: #34495e;'>Quantum computing is a type of computing that uses the principles of quantum mechanics, the science that explains how the smallest particles in the universe behave. Here's a simple breakdown:\n",
       "\n",
       "1. **Bits vs. Qubits**: Traditional computers use bits, which are like tiny switches that can be turned on (1) or off (0). Quantum computers use qubits, which can be both 0 and 1 at the same time, thanks to a property called superposition.\n",
       "\n",
       "2. **Superposition**: Imagine spinning coins that are both heads and tails until you look at them. In a similar way, qubits can hold multiple possibilities at once, allowing quantum computers to process a vast amount of data simultaneously.\n",
       "\n",
       "3. **Entanglement**: This is another quantum principle where qubits become linked, such that the state of one qubit can depend on the state of another, no matter the distance between them. This allows complex problem-solving capabilities and faster information exchange.\n",
       "\n",
       "4. **Interference**: Quantum computers use interference to amplify correct answers and cancel out wrong ones, similar to how noise-canceling headphones reduce unwanted sounds.\n",
       "\n",
       "Together, these quantum properties make quantum computers incredibly powerful for certain tasks, like factoring large numbers, simulating molecules for drug development, or optimizing incredibly complex systems. However, they are still in development and not expected to replace traditional computers for everyday tasks yet.</p>\n",
       "        </div>\n",
       "        \n",
       "        <div style='flex: 1; min-width: 300px; background-color: #f8f9fa; padding: 15px; border-radius: 8px;'>\n",
       "            <h3 style='color: #2c3e50;'>Anthropic Claude</h3>\n",
       "            <p style='color: #34495e;'>Quantum computing can be explained through a few key concepts:\n",
       "\n",
       "1. Regular computers vs. Quantum computers:\n",
       "- Regular computers use bits (0s and 1s)\n",
       "- Quantum computers use quantum bits (qubits) that can be both 0 and 1 at the same time\n",
       "\n",
       "2. Think of it like this:\n",
       "- Classical bit: A coin lying flat, either heads (0) or tails (1)\n",
       "- Qubit: A spinning coin that's both heads and tails until it stops spinning\n",
       "\n",
       "3. Main advantages:\n",
       "- Can process huge amounts of data simultaneously\n",
       "- Can solve certain complex problems much faster than regular computers\n",
       "- Perfect for tasks like encryption, drug discovery, and complex simulations\n",
       "\n",
       "4. Real-world example:\n",
       "If you needed to find a specific person in a phone book:\n",
       "- Regular computer: Checks each name one by one\n",
       "- Quantum computer: Can check many names simultaneously\n",
       "\n",
       "The catch is that quantum computers are still experimental, very expensive, and challenging to build and maintain because qubits are extremely sensitive to their environment.\n",
       "\n",
       "Think of it as a super-powerful calculator that can process many possibilities at once, instead of one at a time like regular computers.</p>\n",
       "        </div>\n",
       "        \n",
       "        <div style='flex: 1; min-width: 300px; background-color: #f8f9fa; padding: 15px; border-radius: 8px;'>\n",
       "            <h3 style='color: #2c3e50;'>Ollama (Local)</h3>\n",
       "            <p style='color: #34495e;'>Quantum computing is a new way of processing information that's different from classical computers. Here's a simplified explanation:\n",
       "\n",
       "**Classical Computers**\n",
       "\n",
       "Imagine you have a filing cabinet with labeled folders, each containing a piece of information (like a number or a word). When you want to process this information, you take the folder, look inside, and do something with what you found.\n",
       "\n",
       "In classical computing, these \"folders\" are called bits. A bit is either 0 (empty) or 1 (filled). The computer checks the bit one by one, performs calculations, and then moves on to the next piece of information.\n",
       "\n",
       "**Quantum Computers**\n",
       "\n",
       "Now imagine a giant filing cabinet with many, many folders that can be in multiple states at once: both 0 AND 1 simultaneously! This is similar to what happens in quantum computing.\n",
       "\n",
       "In a quantum computer, these \"folders\" are called qubits (quantum bits). Qubits exist in a state of superposition, meaning they can be multiple values all at once. When a qubit is measured, it \"collapses\" into one value or another.\n",
       "\n",
       "**How Quantum Computing Works**\n",
       "\n",
       "Here's where things get really interesting:\n",
       "\n",
       "1. **Quantum gates**: These are special operations that manipulate the qubits to perform calculations.\n",
       "2. **Superposition**: Qubits exist in multiple states at once, allowing them to process multiple possibilities simultaneously.\n",
       "3. **Entanglement**: Qubits can become connected (entangled) with each other, enabling quantum computers to solve problems that would be impossible for classical computers.\n",
       "\n",
       "**Advantages of Quantum Computing**\n",
       "\n",
       "1. **Faster processing times**: Quantum computers can solve certain problems much faster than classical computers.\n",
       "2. **Simulation capabilities**: Quantum computers can simulate complex systems, like molecules or materials, more accurately than classical computers.\n",
       "3. **Cryptography and security**: Quantum computers can potentially break some encryption methods used today, but they can also create new, unbreakable codes.\n",
       "\n",
       "**Current State of Quantum Computing**\n",
       "\n",
       "Quantum computing is still a developing field, with many challenges to overcome before it becomes widely available. Companies like Google, IBM, and Microsoft are actively working on building more powerful quantum computers, and researchers are making progress in understanding the fundamental principles of quantum computing.\n",
       "\n",
       "In summary, quantum computing uses qubits that can exist in multiple states simultaneously, allowing for faster processing times and new simulation capabilities. While there's still much to be discovered, quantum computing has the potential to revolutionize many fields!</p>\n",
       "        </div>\n",
       "        </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses = [\n",
    "    (\"OpenAI GPT-4o\", openai_response),\n",
    "    (\"Anthropic Claude\", claude_response),\n",
    "    (\"Ollama (Local)\", ollama_response)\n",
    "]\n",
    "\n",
    "display_comparison(*responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1db0192",
   "metadata": {},
   "source": [
    "## Image Generation with DALL-E 3\n",
    "\n",
    "Let's create an image using OpenAI's DALL-E 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4887f121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-gpLJbCQWtORw077QTyeX1IVP/user-XdioBui0vo4j6lczE6AGRrxb/img-YEFfGvOuIUd7YZX9xyfXSkp9.png?st=2025-02-03T10%3A14%3A51Z&se=2025-02-03T12%3A14%3A51Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-02-03T00%3A26%3A01Z&ske=2025-02-04T00%3A26%3A01Z&sks=b&skv=2024-08-04&sig=uNP1Lv9s7TYCAw9ZruJcGvf6ck8IEF8viHfn7Z3IwJo%3D\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_image(prompt):\n",
    "    client = openai.OpenAI()\n",
    "    response = client.images.generate(\n",
    "        model=\"dall-e-3\",\n",
    "        prompt=prompt,\n",
    "        size=\"1024x1024\",\n",
    "        quality=\"standard\",\n",
    "        n=1,\n",
    "    )\n",
    "    return response.data[0].url\n",
    "\n",
    "# Example usage\n",
    "image_prompt = \"A futuristic quantum computer in a cyberpunk setting, digital art style\"\n",
    "image_url = generate_image(image_prompt)\n",
    "Image(url=image_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f03f5cb",
   "metadata": {},
   "source": [
    "## Audio Transcription with Whisper\n",
    "\n",
    "Let's transcribe audio using OpenAI's Whisper model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "feb9de62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"background-color: #ffffff; padding: 10px; margin: 5px; border-radius: 10px; color: #000000;\">\n",
       "        <strong>Transcription:</strong><br>\n",
       "        Welcome to this course about automating with Python and AI.\n",
       "\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transcribe_audio(file_path):\n",
    "    client = openai.OpenAI()\n",
    "    with open(file_path, \"rb\") as audio_file:\n",
    "        transcription = client.audio.transcriptions.create(\n",
    "            model=\"whisper-1\",\n",
    "            file=audio_file,\n",
    "            response_format=\"text\"\n",
    "        )\n",
    "    return transcription\n",
    "\n",
    "# Example usage (assuming you have an audio file)\n",
    "transcription = transcribe_audio(\"./assets-resources/audio-sample.mp3\")\n",
    "display_chat_message(\"Transcription\", transcription)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d31cb44",
   "metadata": {},
   "source": [
    "## Practice Exercise\n",
    "\n",
    "Write a simple script that\n",
    "1. Uses the OpenAI api with the model: `gpt-4o-mini` to suggest a text description for a creative image \n",
    "2. The suggestion should then be criticized by a different model (gpt-4o, claude, ollama etc...)\n",
    "3. The feedback should then be incorporated by the first llm into a new improved suggestion\n",
    "4. That suggestion should then be send to the openai api to create an image using the dalle3 api."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789e72f4",
   "metadata": {},
   "source": [
    "This notebook provides a comprehensive introduction to using different AI APIs. Some key takeaways:\n",
    "\n",
    "1. Each provider has its own authentication method and API structure\n",
    "2. Different models excel at different tasks\n",
    "3. Local models (like through Ollama) can be useful for privacy and offline use\n",
    "4. Multimodal capabilities (text, image, audio) are becoming increasingly accessible\n",
    "\n",
    "Remember to:\n",
    "- Keep your API keys secure\n",
    "- Handle rate limits and errors appropriately\n",
    "- Consider costs when making API calls\n",
    "- Choose the right model for your specific use case"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-automate-tasks",
   "language": "python",
   "name": "oreilly-automate-tasks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}


---
./notebooks/02-ai-apis/02-ai-tools-hands-on.ipynb
---
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Hacks\n",
    "\n",
    "## 1. AI Tools\n",
    "\n",
    "### General\n",
    "- ChatGPT\n",
    "- Claude\n",
    "- Gemini\n",
    "- Ollama/Llama Studio/Llamacpp\n",
    "- Google AI Studio\n",
    "- Deep Seek\n",
    "\n",
    "### Search Tools\n",
    "- Perplexity for search\n",
    "- ChatGPT + search\n",
    "- Gemini 1.5 Pro Deep Research\n",
    "\n",
    "### Development Tools\n",
    "- Claude/ChatGPT Projects\n",
    "- Artifacts in Claude/ChatGPT\n",
    "- ChatGPT Canvas\n",
    "\n",
    "## 2. Whiteboard Techniques\n",
    "- Prompt Templates\n",
    "- Chaining\n",
    "- Hybrid approach\n",
    "\n",
    "## Tips & Tricks\n",
    "- Let it see your screen - Gemini/ChatGPT desktop app\n",
    "- Paste code + error ask it to debug\n",
    "- When a task is simple but has many repeatable steps:\n",
    "  - AI to generate quick Python script in correct proper runnable format\n",
    "  - Copy - paste - run - finish\n",
    "- When AI makes a mistake save it for later as your own personal benchmark\n",
    "- Build app with AI that takes in data with a certain structure and outputs desirable output, format, etc.... then make a prompt template that produces the data into the format acceptable by that app (done) ‚Üí example my Quiz app.\n",
    "\n",
    "## Advanced Techniques\n",
    "- [Ask for full scripts with uv style package management](https://claude.ai/chat/cf3cb3d1-5b3e-4ea8-8584-5b6ceada7d84)\n",
    "  - [Another example with very little debugging](https://claude.ai/chat/3276e7df-0dcf-4159-a6c0-df0ff9601e85)\n",
    "- Show LLM how to call an API (in the prompt) then ask it to create something with that API\n",
    "- Writing Python code with Claude Projects + relevant documentation\n",
    "- Meta prompts\n",
    "- Context Building Workflow with LLMs\n",
    "- Test-Driven Development with AI (AI Writes Tests First)\n",
    "- Voice driven prompting\n",
    "- Treat AI models as a team of specialized workers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claude Projects instructions for python scripts\n",
    "\n",
    "```The user will input problems or Python script descriptions and you will output a single Python file with the inline metadata to run it standalone using uv, below are a few examples from the uv documentation:\n",
    "\n",
    "<example 1>\n",
    "example.py\n",
    "\n",
    "# /// script\n",
    "# dependencies = [\n",
    "#   \"requests<3\",\n",
    "#   \"rich\",\n",
    "# ]\n",
    "# ///\n",
    "\n",
    "import requests\n",
    "from rich.pretty import pprint\n",
    "\n",
    "resp = requests.get(\"https://peps.python.org/api/peps.json\")\n",
    "data = resp.json()\n",
    "pprint([(k, v[\"title\"]) for k, v in data.items()][:10])\n",
    "<example 1>\n",
    "\n",
    "<example 2>\n",
    "example2.py\n",
    "\n",
    "# /// script\n",
    "# requires-python = \">=3.12\"\n",
    "# dependencies = []\n",
    "# ///\n",
    "\n",
    "# Use some syntax added in Python 3.12\n",
    "type Point = tuple[float, float]\n",
    "print(Point)\n",
    "<example 2>\n",
    "\n",
    "<instructions>\n",
    "Remember to only output the Python file so I can copy paste and run with a uv run command as shown below:\n",
    "<instructions>\n",
    "uv run <python script name>.py```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}


---
./presentation/presentation.html
---
<!DOCTYPE html>
<html>
  <head>
    <title>Presentation</title>
    <meta charset="utf-8">
    <style>
      @import url(https://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);
      @import url(https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic);
      @import url(https://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);

      body { font-family: 'Droid Serif'; }
      h1, h2, h3 {
        font-family: 'Yanone Kaffeesatz';
        font-weight: normal;
      }
      .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }
    </style>
  </head>
  <body>
    <textarea id="source">
        class: center, middle

        # Using AI Tools and Python to Automate Tasks

        _A two-day, beginner-friendly journey to streamline workflows, boost productivity, and integrate AI into everyday tasks._

        ---

        # Goals

        1. **Understand the basics of Python scripting without prior programming experience**  

        --

        2. **Explore ways to leverage LLMs in combination with Python**  

        --

        3. **Learn how to automate tasks such as file organization and data entry**  

        --

        4. **Use Python scripts to integrate with external LLM APIs**  

        ---
        class: center, middle

        <h1>
        <span style="background-color: orange">
          Survey Question: Do you have a subscription for ChatGPT/Claude/Gemini?
        </span>
        </h1>
        
        ---
        class: center, middle

        # Why Learn to Automate?

        ---
        # Automation as a General Skill

        - **Automate Repetitive Tasks**
        
        --
        
        - **Increase Productivity**
            
        --
        
        - **Save Money**: 
            - Replace expensive subscription tools with your own scripts
        
        --
        
        - **Analyse Massive Amounts of Data** 
        
        ---

        class: center, middle

        # The Real Reason....

        ---
        class: center, middle

        # Writing code = the most general skill you can have!
        *It is a superpower! :)*

        ---
        class: center, middle
        # Scripting vs. Programming
        *An important distinction!*

        ---

        # Both are About Following Recipes

        <div style="text-align: center;">
          <img src="../notebooks/assets/2025-02-01-17-23-04.png" width="24%">
        </div>

        ---
        # Scripting

            
        - Writing code to full fill a set of pre-defined steps that accomplish a task

        --
        
        - Quick, targeted, and task-oriented  

        --
        
        - Typically used for automations, data manipulation, or utility tasks  

        --

        - Toy example -> Renaming multiple files

        ```python
          # Rename all .txt files in a directory to include today's date
          import os
          from datetime import date

          today = date.today().strftime("%Y-%m-%d")

          for filename in os.listdir("."):
              if filename.endswith(".txt"):
                  new_name = f"{today}_{filename}"
                  os.rename(filename, new_name)

        ```

        ---
        # Vibe Scripting?

        <div style="display: flex; align-items: center;">
          <div style="flex: 1;">
            <img src="../notebooks/assets/piramid-scripting.png" width="105%">
          </div>
          <div style="flex: 1;">
            <p style="margin-top: 20px; margin-left: 0;">
              <img src="" width="105%">
            </p>
          </div>
        </div>

        ---
        # Vibe Scripting?

        <div style="display: flex; align-items: center;">
          <div style="flex: 1;">
            <img src="../notebooks/assets/piramid-scripting.png" width="105%">
          </div>
          <div style="flex: 1;">
            <p style="margin-top: 20px; margin-left: 0;">
              <img src="../notebooks/assets/piramid-vibe-scripting.png" width="105%">  
            </p>
          </div>
        </div>
        
        ---
        # Why focus on scripting/vibe scripting?
        
        --

        - Much faster learning curve - *if it works don't change it*
        
        --
        
        - Immediate practical benefits - *makes your life better*  

        --
        
        - Ideal for nondevelopers who just want to get things done  

        --

        - I call it "The Ostrich Approach to Learning Python"
        
        <div style="text-align: center;">
            <img src="../notebooks/assets/2025-01-31-16-24-34.png" width="30%">
        </div>

        ---
        class: center, middle

        <div style="text-align: center;">
          <img src="../notebooks/assets/2025-01-31-16-20-25.png" width="100%">
        </div>

        ---
        class: center, middle

        # It's about Learning What We Need for Our Tasks!

        --
        
        *And purposefuly ignoring that which does not seem to have any effect on its
        success.*

        ---
        class: center, middle

        # Learning Python with AI
        *Your Personal Programming Tutor*

        ---

        # The Conversational Learning Approach

        - **Start with "I don't know Python, but I want to..."** and describe your goal

        --

        - **Ask for explanations**: "What does this line do?" or "Why do we use a for loop here?"

        --

        - **Request variations**: "Show me 3 different ways to do this" or "Make this simpler"

        --

        - **Build incrementally**: Start with tiny scripts, then ask "How do I add X to this?"

        --

        - **Example conversation starter**:

        ---
        class: center, middle

        <div style="display: flex; align-items: center; justify-content: center;">
            <h1 style="margin-right: 20px;">Why Python?</h1>
            <img src="../notebooks/assets/python-logo.svg" width="100px">
        </div>

        ---
        <div style="display: flex; align-items: left; ">
          <h1 style="margin-right: 20px;">Python is Easy and Everywhere</h1>
          <img src="../notebooks/assets/python-logo.svg" width="100px">
        </div>

        <div style="text-align: center;">
          <img src="../notebooks/assets/2025-02-01-16-12-52.png" width="70%">
        </div>

        ---

        <div style="display: flex; align-items: left; ">
          <h1 style="margin-right: 20px;">Python is Easy and Everywhere</h1>
          <img src="../notebooks/assets/python-logo.svg" width="100px">
        </div>

        - Python is a general purpose language (can be used for everything)

        --

        - Python is used across the board in AI from developing AI models to powering self-driving cars

        --

        - Python is super easy to learn due to its proximity with natural language

        ---
        class: center, middle

        # The Busy Person Guide to Python Basics
        

        ---
        # Python Things We Will Learn

        - **Basic Syntax**: Indentation, variable assignments, printing  

        --
        
        - **Common Data Types**: Strings, integers, floats, booleans  

        --

        - **Control Structures**: `if` statements, loops (`for`, `while`)  

        --

        - **Useful Libraries**: `os` for file operations, `csv` for handling CSVs, `requests` for making web requests  

        --

        - That is a lot! How can we manage?

        --

        - Use AI conversationally! Asking questions and clarifying what you don't know!

        ---
        # The "Just Ask AI" Naive Approach

        --

        <div style="display: flex; justify-content: center; align-items: center; margin-top: 150px;">
          <img src="../notebooks/assets/2025-02-01-16-37-14.png" width="100%">
        </div>

        ---
        # The "Just Ask AI" Naive Approach

        <div style="display: flex; justify-content: center; align-items: center; margin-top: 120px;margin-left: 50px;">
          <img src="../notebooks/assets/2025-02-01-16-47-17.png" width="125%">
        </div>

        ---
        class: center, middle

        <h1>
          <span style="background-color: lightgreen;">
           Demo - Setting Up Your Environment
          </span>
        </h1>
        (Installing Python, uv, Editor, Jupyter Notebook, AI chatbot)
        <div style="display: flex; justify-content: center; align-items: center; margin-top: 20px;">
          <img src="../notebooks/assets/qr-code-repo.png" width="200px">
        </div>

        ---
        

        # Data Types, Operations, Variables

        - Writing code is about writing text that changes or manipulates data in some way

        --

        -   <div style="display: flex; align-items: center;">
                <div> For that we need? ..... (drumbroll)</div>
                <div><img src="../notebooks/assets/2025-01-31-16-30-04.png" width="100px" style="margin-left: 10px;"></div>
            </div>
        
        - **Data!** Specifically a way to describe it, reference it, talk about it etc...

        --

        - In Python data can be of different **types** (like numbers, text, image etc...)

        --

        - The things we can do to it are called **operations** (like 5+5)

        --

        - To organize things, we use **variables** to define what each thing is

        ---

        # Data Types, Operations, Variables - Example
        
        - Here is a piece of code that defines a variable of some type
        and performs a simple operation on the data stored in the variable
        
            ```python
            # This is data of type string!
            name = "Lucas"
            
            # This is data of type integer!
            actual_age = 33

            # This is data of type integer!
            mental_age = 12

            # our operation
            average_age_between_actual_and_mental = (actual_age + mental_age) / 2

            # special function that displays what goes inside of it
            print(average_age_between_actual_and_mental)

            # this would be a float!
            # Output: 22.5

            ```
        
        ---
        class: center, middle

        <h1>
            <span style="background-color: lightgreen">
             Data Types; Operations; Variables - Demo
            </span>
        </h1>

        ---
        
        # Data Types, Operations, Variables 

        - **Core Data Types**: 

        --
          
            - **int**: whole nubmers like 1, 2, 3 ... 
        
        --
            - **float**: decimal numbers like 1.1, 1.0, etc... 

        --
            - **string**: text like `'Hello'`

        --
            - **bool**: logical booleans like True or False  
        
        --
        
        - **Operations**:

        --
            
            - **Arithmetic** `(`+`, `-`, `*`, `/`, `**`, `//`, `%`)`

        --
            - **String concatenation** (`'Lucas' + ' is' + ' wonderful' = 'Lucas is wonderful'`)

        --
            - **Logical operations** (`and`, `or`, `not`)

        --
            - **Comparison operations** (`>`, `<`, `>=`, `<=`, `==`, `!=`)
        
        ---
        
        - **Variables**: Storing data for reuse, assigning and reassigning values: 
            ```python
                a = 10
                b = 20
                print(a + b)
                # Output: 30
            ```
        ---
        class: center, middle

        <h1>
            <span style="background-color: lightgreen">
              Demo: Functions, Lists & Loops
            </span>
        </h1>
        ---

        # Functions

        --

        - Functions are a way to group code that performs a specific task

        --

        - Functions can take parameters and return values

        --

        - For example, a function that calculates the total cost of an item including tax

        --

        - We could do this by simply writing a script:

        --

        ```python
          # Arithmetic operation: multiplication of parameters
          tax = price * tax_rate
          # Arithmetic operation: addition of variables
          total = price + tax
        ```

        - But what if I want to re-use this code for different prices and tax rates?

        ---

        # Functions

        - Here is what it would look like if we define a function to do this:

        ```python
          def calculate_total(price, tax_rate):
              tax = price * tax_rate
              total = price + tax
              return total
        ```

        --

        - Now we can re-use the function for different prices and tax rates:

        ```python
          shirt_price = 10
          shirt_tax_rate = 0.05
          pants_price = 20
          pants_tax_rate = 0.1
          
          print(calculate_total(shirt_price, shirt_tax_rate)) 
          # Output: 10.5
          print(calculate_total(pants_price, pants_tax_rate))
          # Output: 22.0
        ```

        ---

        # Functions

        - **Why Functions?**: Reuse code and break tasks into smaller chunks  

        --

        - **Defining a Function**: `def function_name(parameters):`  

        --

        - **Return Values**: Make your functions flexible and reusable  

        --

        - **Best Practices**: Keep them short, descriptive, and single-purpose  

        ---
        # Lists & Loops

        - **Lists**: Python‚Äôs go-to data structure for ordered collections  

        --
        
        ```python
          # Define a list of tasks
          tasks = ["Buy groceries", "Finish project", "Call the bank"]
        ```

        - **Access Elements**: Indexing and slicing

        --

        ```python
          print(tasks[0])
          # Output: Buy groceries

          print(tasks[1])
          # Output: Finish project
        ```

        --

        - **Slice**: Get a range of elements  

        --

        ```python
          print(tasks[0:2])
          # Output: ['Buy groceries', 'Finish project']
        ```

        ---

        # Lists & Loops
        
        - **Loops**: `for` loops to iterate over items

        --

        ```python
        tasks = ["Buy groceries", "Finish project", "Call the bank"]

        for task in tasks:
            print(task)
        ```
        
        --

        - **Processing List Elements**: With `for` loops we can perform the same operation on each element of the list

        --

        ```python
        # Below we use an imaginary function that asks a robot to do a task
        for task in tasks:
            ask_robot_to_do(task)
        ```

        --

        **Common Uses**: Batch renaming files in a directory, processing data from tables, etc...

        ---
        class: center, middle

        <h1>
            <span style="background-color: lightgreen">
             Demo - Dictionaries, Tabular Data, Conditionals
            </span>
        </h1>

        ---
        # Dictionaries & Tabular Data

        - **Dictionaries**: Key-value pairs for storing related data

        --

        ```python
        # Dictionary of product prices
        prices = {
            "apple": 0.50,
            "banana": 0.75,
            "orange": 0.60
        }
        ```

        --

        - **Accessing Values**: Use keys to lookup values quickly

        --

        ```python
        print(prices["apple"])
        # Output: 0.50

        print(prices["banana"]) 
        # Output: 0.75
        ```

        --

        - **Common Uses**: Storing configurations, mapping relationships, caching data

        ---
        # Comparators & Conditionals

        - **Boolean Comparisons**: `==`, `!=`, `>`, `<`, `>=`, `<=`  

        --

        ```python
        # Example of a boolean comparison
        a = 10
        b = 20
        print(a == b)  # Output: False
        print(a != b)  # Output: True
        print(a > b)   # Output: False
        print(a < b)   # Output: True
        print(a >= b) # Output: False
        print(a <= b) # Output: True

        ```

        --
        
        - **Logical Operators**: `and`, `or`, `not`  

        --

        ```python
        # Example of a logical operator
        print(True and False)  # Output: False
        print(True or False)   # Output: True
        print(not True)         # Output: False
        ```

        ---
        # Comparators & Conditionals
        
        - **Conditionals**: Using conditionals `if/elif/else` to perform different actions based on data  

        --

        ```python
        # Example of an if statement
        if a > b:
            print("a is greater than b")
        ```

        --

        ```python
        # Example of an if/else statement
        if a > b:
            print("a is greater than b")
        else:
            print("a is less than or equal to b")
        ```

        --

        ```python
        # Example of an if/elif/else statement
        if a > b:
            print("a is greater than b")
        elif a == b:
            print("a is equal to b")
        else:
            print("a is less than b")
        ```

        ---
        class: center, middle

        <h1>
            <span style="background-color: lightgreen">
             Demo - Working with Data, APIs & Packages
            </span>
        </h1>

        ---
        # Reading/Writing

        - **Tabular Data**: Data that is organized in a table format

        --

        - **Common Formats**: `.csv`, `.json`, `.xlsx`, `.xls`  

        --

        - CSV Files store data in rows and columns via comma-separated values:

              ```text
              Name,Age,City
              John Smith,32,New York
              Jane Doe,28,San Francisco
              ```

        <table style="border-collapse: collapse; width: 80%; margin: 20px auto;">
            <tr style="background-color: #f2f2f2;">
                <th style="border: 1px solid #ddd; padding: 8px; text-align: left;">Name</th>
                <th style="border: 1px solid #ddd; padding: 8px; text-align: left;">Age</th>
                <th style="border: 1px solid #ddd; padding: 8px; text-align: left;">City</th>
            </tr>
            <tr>
                <td style="border: 1px solid #ddd; padding: 8px;">John Smith</td>
                <td style="border: 1px solid #ddd; padding: 8px;">32</td>
                <td style="border: 1px solid #ddd; padding: 8px;">New York</td>
            </tr>
            <tr style="background-color: #f2f2f2;">
                <td style="border: 1px solid #ddd; padding: 8px;">Jane Doe</td>
                <td style="border: 1px solid #ddd; padding: 8px;">28</td>
                <td style="border: 1px solid #ddd; padding: 8px;">San Francisco</td>
            </tr>
        </table>


        ---

        # APIs, Packages, and AI as an API

        - **APIs 101**: Application Programming Interface‚Äîsend a request, get a response  

        --
        
        - **Python Packages**: Example: `requests` library to make HTTP calls  

        --
        
        - **AI as an API**: Connect to services like OpenAI or Claude for text generation, content analysis, and more  

        ---
        class: center, middle

        <h1>
          <span style="background-color: lightgreen;">
           Demo - Vibe Scripting with UV + AI
          </span>
        </h1>

        ---
        class: center, middle

        # How to Use AI to Learn/Use Python
        
        *A quick detour to set up an AI toolkit to speed up our Automation skills *
        
        ---

        # A.R.U.F.S Framework

        --
        
        ## **A**sk,**R**un,**U**nderstand,**F**ix,Be **S**afe

        --

        - **A**sk ‚Üí how to ask effectively, give the right context

        --

        - **R**un ‚Üí how to run the code AI gives you

        --
        
        - **U**nderstand ‚Üí how to understand it/learn from it

        --
        
        - **F**ix ‚Üí how to fix it

        --
        
        - Be **S**afe ‚Üí pittfalls & security risks

        ---
        # Ask

        - Be **detailed**

        --

        - Use **context** (docs, articles, pdfs, ...)

        --

        - **Tools** to help with feeding data/repo into LLMs
          - https://github.com/yamadashy/repomix
          - gitingest
          - r.jina.ai
          - arxiv-txt.org
          - llms-txt
          - files-to-prompt

        - Use **meta-prompts**:
          ```
          I have this problem:
          {describe the problem}
          Help me write a good prompt that encapsulates this into a single Python script.
          ```
        
        ---
        # Ask

        - For tough problems use **reasoning models**

          - Claude + Extended Thinking
          - O-series models from OpenAI
          - Gemini 2.5 Pro
          - DeepSeek R1

        ---
        # Run/Understand/Fix

        - The pattern is:

        --
          
          - LLM generates the script
          - You run the script
          - You inspect the output
          - You ask the LLM to fix the script (if needed)

        --
        
        - Ask for **comments on the code**

        --

        - **Feed the output of the terminal** to the AI and ask to fix it

        ---
        # Be Safe

        - **Never hardcode credentials** - use environment variables or config files

        --

        - **Review AI-generated code** before running - understand what each line does

        --

        - **Test in isolated environments** first (separate folders, test data)

        --

        - **Don't share sensitive data** with AI models (personal info, API keys, proprietary data)

        --

        - **Backup important files** before running automation scripts

        --

        - **Check file paths** - ensure scripts won't delete important files

        --

        - **Add safeguards** for loops (break conditions, iteration limits)

        --

        - **Respect rate limits** and website terms of service when scraping

        --

        - **Quick Safety Checklist**: Read code ‚Üí Test with dummy data ‚Üí Have backups ‚Üí Use version control

        ---
        class: center, middle

        <h1>
            <span style="background-color: lightgreen">
             Demo - Implementing the A.R.U.F.S Framework
            </span>
        </h1>

        ---
        class: center, middle

        <h1>
            <span style="background-color: lightgreen">
             Demo - Automating Data Extraction
            </span>
        </h1>


        ---
        
        # Automating Data Extraction

        - **Target Websites or Documents**: Identify patterns or structures (tables, IDs, HTML tags)  

        --
        
        - **Techniques**: Using Beautiful Soup, Pandas, or request-response cycles  

        --
        
        - **Practical Examples**: Extracting data from a CSV, scraping a simple webpage for product listings  

        ---

        # Automating Basic Data Analysis

        - **Data Loading**: Reading CSV files, Excel sheets, or database tables with Pandas  

        --
        
        - **Basic Analysis**: Calculating averages, sums, or finding patterns in data  

        --
        
        - **Visualization**: Creating simple charts or graphs to represent findings  

        ---

        # Automating Slides

        - Effective data wrangling for high quality slides

        --
        
        - A Hybrid Approach: AI + Python Scripts

        --
        
        - Bulk Processing to save time

        ---

        # Automating the Browser

        - **Tools**: `selenium`, `playwright`  

        --
        
        - **Common Tasks**: Logging in to websites, navigating pages, clicking buttons, scraping dynamic elements  

        --
        
        - **Why Automate Browser Tasks?**: Speed up online research, data entry, or repetitive website interactions  

        ---

        # Automating Filling Out Forms

        - **Form Fields**: Identifying input boxes, radio buttons, checkboxes in HTML  

        --
        
        - **Scripts**: Using `selenium` to locate elements by ID/class/xpath and input data  

        --
        
        - **Real-World Use**: Automating repetitive website sign-up processes, survey completion, or internal data-entry forms  

        ---
        class: center, middle
        

        <h1>
        <span style="background-color: lightgreen">
          Demo - Prompts, Tips & Tricks
        </span>
        </h1>
        
        ---

        class: center, middle

        # Using AI != Slop

        ---

        # Using AI != Slop

        *Slop is using unreviewed output (like code) from AI models*

        <div style="text-align: center;">
          <img src="../notebooks/assets/2025-02-02-11-50-55.png" width="80%">
        </div>

        ---
        # Using AI != Slop

        1. Working with AI involves having a system for effectively reviewing high quality outputs
        
        --

        2. Means having good systems for generating good outputs on the first place

        --

        3. Then learning to put in place a procedure for effective review and feedback on top of the outputs you get

        ---
        

        
    </textarea>
    <script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
    <script>
      var slideshow = remark.create();
    </script>
  </body>
</html>

---
